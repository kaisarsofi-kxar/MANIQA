[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "timm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "timm",
        "description": "timm",
        "detail": "timm",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "timm",
        "description": "timm",
        "isExtraImport": true,
        "detail": "timm",
        "documentation": {}
    },
    {
        "label": "Block",
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "isExtraImport": true,
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "resize_pos_embed",
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "isExtraImport": true,
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "_create_vision_transformer",
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "isExtraImport": true,
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "SwinTransformer",
        "importPath": "models.swin",
        "description": "models.swin",
        "isExtraImport": true,
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "torch.utils.checkpoint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.checkpoint",
        "description": "torch.utils.checkpoint",
        "detail": "torch.utils.checkpoint",
        "documentation": {}
    },
    {
        "label": "DropPath",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "DropPath",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "_assert",
        "importPath": "timm.models.layers",
        "description": "timm.models.layers",
        "isExtraImport": true,
        "detail": "timm.models.layers",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "natural_key",
        "importPath": "timm.utils.misc",
        "description": "timm.utils.misc",
        "isExtraImport": true,
        "detail": "timm.utils.misc",
        "documentation": {}
    },
    {
        "label": "natural_key",
        "importPath": "timm.utils.misc",
        "description": "timm.utils.misc",
        "isExtraImport": true,
        "detail": "timm.utils.misc",
        "documentation": {}
    },
    {
        "label": "natural_key",
        "importPath": "timm.utils.misc",
        "description": "timm.utils.misc",
        "isExtraImport": true,
        "detail": "timm.utils.misc",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageChops",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "CIFAR100",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "CIFAR10",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "MNIST",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "QMNIST",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "KMNIST",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "FashionMNIST",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "ImageNet",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "ImageFolder",
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "isExtraImport": true,
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "isExtraImport": true,
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "isExtraImport": true,
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CROP_PCT",
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "isExtraImport": true,
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "rand_augment_transform",
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "isExtraImport": true,
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "augment_and_mix_transform",
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "isExtraImport": true,
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_transform",
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "isExtraImport": true,
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "str_to_interp_mode",
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "isExtraImport": true,
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "str_to_pil_interp",
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "isExtraImport": true,
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "RandomResizedCropAndInterpolation",
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "isExtraImport": true,
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "ToNumpy",
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "isExtraImport": true,
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "RandomErasing",
        "importPath": "timm.data.random_erasing",
        "description": "timm.data.random_erasing",
        "isExtraImport": true,
        "detail": "timm.data.random_erasing",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "collections.abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections.abc",
        "description": "collections.abc",
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "_calculate_fan_in_and_fan_out",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DPN_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DPN_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "importPath": "timm.data",
        "description": "timm.data",
        "isExtraImport": true,
        "detail": "timm.data",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "replace",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "register_model",
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "isExtraImport": true,
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "register_model",
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "isExtraImport": true,
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "torch.hub",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.hub",
        "description": "torch.hub",
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "load_state_dict_from_url",
        "importPath": "torch.hub",
        "description": "torch.hub",
        "isExtraImport": true,
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "HASH_REGEX",
        "importPath": "torch.hub",
        "description": "torch.hub",
        "isExtraImport": true,
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "download_url_to_file",
        "importPath": "torch.hub",
        "description": "torch.hub",
        "isExtraImport": true,
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "torch.hub",
        "description": "torch.hub",
        "isExtraImport": true,
        "detail": "torch.hub",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "torch.jit.annotations",
        "description": "torch.jit.annotations",
        "isExtraImport": true,
        "detail": "torch.jit.annotations",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "build_model_with_cfg",
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "isExtraImport": true,
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "isExtraImport": true,
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "required",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bisect",
        "description": "bisect",
        "detail": "bisect",
        "documentation": {}
    },
    {
        "label": "Scheduler",
        "importPath": "timm.scheduler.scheduler",
        "description": "timm.scheduler.scheduler",
        "isExtraImport": true,
        "detail": "timm.scheduler.scheduler",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "adaptive_clip_grad",
        "importPath": "timm.utils.agc",
        "description": "timm.utils.agc",
        "isExtraImport": true,
        "detail": "timm.utils.agc",
        "documentation": {}
    },
    {
        "label": "logging.handlers",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging.handlers",
        "description": "logging.handlers",
        "detail": "logging.handlers",
        "documentation": {}
    },
    {
        "label": "FrozenBatchNorm2d",
        "importPath": "torchvision.ops.misc",
        "description": "torchvision.ops.misc",
        "isExtraImport": true,
        "detail": "torchvision.ops.misc",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "five_point_crop",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "sort_file",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "isExtraImport": true,
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "PIPAL22",
        "importPath": "data.pipal22_test",
        "description": "data.pipal22_test",
        "isExtraImport": true,
        "detail": "data.pipal22_test",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "MANIQA",
        "importPath": "models.maniqa",
        "description": "models.maniqa",
        "isExtraImport": true,
        "detail": "models.maniqa",
        "documentation": {}
    },
    {
        "label": "MANIQA",
        "importPath": "models.maniqa",
        "description": "models.maniqa",
        "isExtraImport": true,
        "detail": "models.maniqa",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "RandCrop",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "five_point_crop",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_kadid10k",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_koniq10k",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "RandRotation",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "RandHorizontalFlip",
        "importPath": "utils.process",
        "description": "utils.process",
        "isExtraImport": true,
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "spearmanr",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "pearsonr",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "PIPAL",
        "kind": 6,
        "importPath": "data.PIPAL22.pipal",
        "description": "data.PIPAL22.pipal",
        "peekOfCode": "class PIPAL(torch.utils.data.Dataset):\n    def __init__(self, dis_path, txt_file_name, transform, keep_ratio):\n        super(PIPAL, self).__init__()\n        self.dis_path = dis_path\n        self.txt_file_name = txt_file_name\n        self.transform = transform\n        dis_files_data, score_data = [], []\n        name_type = {}\n        with open(self.txt_file_name, 'r') as listFile:\n            for line in listFile:",
        "detail": "data.PIPAL22.pipal",
        "documentation": {}
    },
    {
        "label": "PIPAL22",
        "kind": 6,
        "importPath": "data.PIPAL22.pipal22_test",
        "description": "data.PIPAL22.pipal22_test",
        "peekOfCode": "class PIPAL22(torch.utils.data.Dataset):\n    def __init__(self, dis_path, transform):\n        super(PIPAL22, self).__init__()\n        self.dis_path = dis_path\n        self.transform = transform\n        dis_files_data = []\n        for dis in os.listdir(dis_path):\n            dis_files_data.append(dis)\n        self.data_dict = {'d_img_list': dis_files_data}\n    def __len__(self):",
        "detail": "data.PIPAL22.pipal22_test",
        "documentation": {}
    },
    {
        "label": "Kadid10k",
        "kind": 6,
        "importPath": "data.kadid10k.kadid10k",
        "description": "data.kadid10k.kadid10k",
        "peekOfCode": "class Kadid10k(torch.utils.data.Dataset):\n    def __init__(self, dis_path, txt_file_name, list_name, transform, keep_ratio):\n        super(Kadid10k, self).__init__()\n        self.dis_path = dis_path\n        self.txt_file_name = txt_file_name\n        self.transform = transform\n        dis_files_data, score_data = [], []\n        with open(self.txt_file_name, 'r') as listFile:\n            for line in listFile:\n                dis, score = line.split()",
        "detail": "data.kadid10k.kadid10k",
        "documentation": {}
    },
    {
        "label": "Koniq10k",
        "kind": 6,
        "importPath": "data.koniq10k.koniq10k",
        "description": "data.koniq10k.koniq10k",
        "peekOfCode": "class Koniq10k(torch.utils.data.Dataset):\n    def __init__(self, dis_path, txt_file_name, list_name, transform, keep_ratio):\n        super(Koniq10k, self).__init__()\n        self.dis_path = dis_path\n        self.txt_file_name = txt_file_name\n        self.transform = transform\n        dis_files_data, score_data = [], []\n        with open(self.txt_file_name, 'r') as listFile:\n            for line in listFile:\n                dis, score = line.split()",
        "detail": "data.koniq10k.koniq10k",
        "documentation": {}
    },
    {
        "label": "TABlock",
        "kind": 6,
        "importPath": "models.maniqa",
        "description": "models.maniqa",
        "peekOfCode": "class TABlock(nn.Module):\n    def __init__(self, dim, drop=0.1):\n        super().__init__()\n        self.c_q = nn.Linear(dim, dim)\n        self.c_k = nn.Linear(dim, dim)\n        self.c_v = nn.Linear(dim, dim)\n        self.norm_fact = dim ** -0.5\n        self.softmax = nn.Softmax(dim=-1)\n        self.proj_drop = nn.Dropout(drop)\n    def forward(self, x):",
        "detail": "models.maniqa",
        "documentation": {}
    },
    {
        "label": "SaveOutput",
        "kind": 6,
        "importPath": "models.maniqa",
        "description": "models.maniqa",
        "peekOfCode": "class SaveOutput:\n    def __init__(self):\n        self.outputs = []\n    def __call__(self, module, module_in, module_out):\n        self.outputs.append(module_out)\n    def clear(self):\n        self.outputs = []\nclass MANIQA(nn.Module):\n    def __init__(self, embed_dim=72, num_outputs=1, patch_size=8, drop=0.1, \n                    depths=[2, 2], window_size=4, dim_mlp=768, num_heads=[4, 4],",
        "detail": "models.maniqa",
        "documentation": {}
    },
    {
        "label": "MANIQA",
        "kind": 6,
        "importPath": "models.maniqa",
        "description": "models.maniqa",
        "peekOfCode": "class MANIQA(nn.Module):\n    def __init__(self, embed_dim=72, num_outputs=1, patch_size=8, drop=0.1, \n                    depths=[2, 2], window_size=4, dim_mlp=768, num_heads=[4, 4],\n                    img_size=224, num_tab=2, scale=0.8, **kwargs):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.input_size = img_size // patch_size\n        self.patches_resolution = (img_size // patch_size, img_size // patch_size)\n        self.vit = timm.create_model('vit_base_patch8_224', pretrained=True)",
        "detail": "models.maniqa",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "kind": 6,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "class Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n    def forward(self, x):",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "WindowAttention",
        "kind": 6,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "class WindowAttention(nn.Module):\n    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n    It supports both of shifted and non-shifted window.\n    Args:\n        dim (int): Number of input channels.\n        window_size (tuple[int]): The height and width of the window.\n        num_heads (int): Number of attention heads.\n        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "SwinBlock",
        "kind": 6,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "class SwinBlock(nn.Module):\n    r\"\"\" Swin Transformer Block.\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resulotion.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "BasicLayer",
        "kind": 6,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "class BasicLayer(nn.Module):\n    \"\"\" A basic Swin Transformer layer for one stage.\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resolution.\n        depth (int): Number of blocks.\n        num_heads (int): Number of attention heads.\n        window_size (int): Local window size.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "SwinTransformer",
        "kind": 6,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "class SwinTransformer(nn.Module):\n    def __init__(self, patches_resolution, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n                 embed_dim=256, drop=0.1, drop_rate=0., drop_path_rate=0.1, dropout=0., window_size=7,\n                 dim_mlp=1024, qkv_bias=True, qk_scale=None, attn_drop_rate=0., norm_layer=nn.LayerNorm,\n                 downsample=None, use_checkpoint=False, scale=0.8, **kwargs):\n        super().__init__()\n        self.scale = scale\n        self.embed_dim = embed_dim\n        self.depths = depths\n        self.num_heads = num_heads",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "window_partition",
        "kind": 2,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "def window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "window_reverse",
        "kind": 2,
        "importPath": "models.swin",
        "description": "models.swin",
        "peekOfCode": "def window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"",
        "detail": "models.swin",
        "documentation": {}
    },
    {
        "label": "load_class_map",
        "kind": 2,
        "importPath": "timm.data.parsers.class_map",
        "description": "timm.data.parsers.class_map",
        "peekOfCode": "def load_class_map(map_or_filename, root=''):\n    if isinstance(map_or_filename, dict):\n        assert dict, 'class_map dict must be non-empty'\n        return map_or_filename\n    class_map_path = map_or_filename\n    if not os.path.exists(class_map_path):\n        class_map_path = os.path.join(root, class_map_path)\n        assert os.path.exists(class_map_path), 'Cannot locate specified class map file (%s)' % map_or_filename\n    class_map_ext = os.path.splitext(map_or_filename)[-1].lower()\n    if class_map_ext == '.txt':",
        "detail": "timm.data.parsers.class_map",
        "documentation": {}
    },
    {
        "label": "IMG_EXTENSIONS",
        "kind": 5,
        "importPath": "timm.data.parsers.constants",
        "description": "timm.data.parsers.constants",
        "peekOfCode": "IMG_EXTENSIONS = ('.png', '.jpg', '.jpeg')",
        "detail": "timm.data.parsers.constants",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "timm.data.parsers.parser",
        "description": "timm.data.parsers.parser",
        "peekOfCode": "class Parser:\n    def __init__(self):\n        pass\n    @abstractmethod\n    def _filename(self, index, basename=False, absolute=False):\n        pass\n    def filename(self, index, basename=False, absolute=False):\n        return self._filename(index, basename=basename, absolute=absolute)\n    def filenames(self, basename=False, absolute=False):\n        return [self._filename(index, basename=basename, absolute=absolute) for index in range(len(self))]",
        "detail": "timm.data.parsers.parser",
        "documentation": {}
    },
    {
        "label": "create_parser",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_factory",
        "description": "timm.data.parsers.parser_factory",
        "peekOfCode": "def create_parser(name, root, split='train', **kwargs):\n    name = name.lower()\n    name = name.split('/', 2)\n    prefix = ''\n    if len(name) > 1:\n        prefix = name[0]\n    name = name[-1]\n    # FIXME improve the selection right now just tfds prefix or fallback path, will need options to\n    # explicitly select other options shortly\n    if prefix == 'tfds':",
        "detail": "timm.data.parsers.parser_factory",
        "documentation": {}
    },
    {
        "label": "ParserImageFolder",
        "kind": 6,
        "importPath": "timm.data.parsers.parser_image_folder",
        "description": "timm.data.parsers.parser_image_folder",
        "peekOfCode": "class ParserImageFolder(Parser):\n    def __init__(\n            self,\n            root,\n            class_map=''):\n        super().__init__()\n        self.root = root\n        class_to_idx = None\n        if class_map:\n            class_to_idx = load_class_map(class_map, root)",
        "detail": "timm.data.parsers.parser_image_folder",
        "documentation": {}
    },
    {
        "label": "find_images_and_targets",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_image_folder",
        "description": "timm.data.parsers.parser_image_folder",
        "peekOfCode": "def find_images_and_targets(folder, types=IMG_EXTENSIONS, class_to_idx=None, leaf_name_only=True, sort=True):\n    labels = []\n    filenames = []\n    for root, subdirs, files in os.walk(folder, topdown=False, followlinks=True):\n        rel_path = os.path.relpath(root, folder) if (root != folder) else ''\n        label = os.path.basename(rel_path) if leaf_name_only else rel_path.replace(os.path.sep, '_')\n        for f in files:\n            base, ext = os.path.splitext(f)\n            if ext.lower() in types:\n                filenames.append(os.path.join(root, f))",
        "detail": "timm.data.parsers.parser_image_folder",
        "documentation": {}
    },
    {
        "label": "TarState",
        "kind": 6,
        "importPath": "timm.data.parsers.parser_image_in_tar",
        "description": "timm.data.parsers.parser_image_in_tar",
        "peekOfCode": "class TarState:\n    def __init__(self, tf: tarfile.TarFile = None, ti: tarfile.TarInfo = None):\n        self.tf: tarfile.TarFile = tf\n        self.ti: tarfile.TarInfo = ti\n        self.children: Dict[str, TarState] = {}  # child states (tars within tars)\n    def reset(self):\n        self.tf = None\ndef _extract_tarinfo(tf: tarfile.TarFile, parent_info: Dict, extensions=IMG_EXTENSIONS):\n    sample_count = 0\n    for i, ti in enumerate(tf):",
        "detail": "timm.data.parsers.parser_image_in_tar",
        "documentation": {}
    },
    {
        "label": "ParserImageInTar",
        "kind": 6,
        "importPath": "timm.data.parsers.parser_image_in_tar",
        "description": "timm.data.parsers.parser_image_in_tar",
        "peekOfCode": "class ParserImageInTar(Parser):\n    \"\"\" Multi-tarfile dataset parser where there is one .tar file per class\n    \"\"\"\n    def __init__(self, root, class_map='', cache_tarfiles=True, cache_tarinfo=None):\n        super().__init__()\n        class_name_to_idx = None\n        if class_map:\n            class_name_to_idx = load_class_map(class_map, root)\n        self.root = root\n        self.samples, self.targets, self.class_name_to_idx, tarfiles = extract_tarinfos(",
        "detail": "timm.data.parsers.parser_image_in_tar",
        "documentation": {}
    },
    {
        "label": "extract_tarinfos",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_image_in_tar",
        "description": "timm.data.parsers.parser_image_in_tar",
        "peekOfCode": "def extract_tarinfos(root, class_name_to_idx=None, cache_tarinfo=None, extensions=IMG_EXTENSIONS, sort=True):\n    root_is_tar = False\n    if os.path.isfile(root):\n        assert os.path.splitext(root)[-1].lower() == '.tar'\n        tar_filenames = [root]\n        root, root_name = os.path.split(root)\n        root_name = os.path.splitext(root_name)[0]\n        root_is_tar = True\n    else:\n        root_name = root.strip(os.path.sep).split(os.path.sep)[-1]",
        "detail": "timm.data.parsers.parser_image_in_tar",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.data.parsers.parser_image_in_tar",
        "description": "timm.data.parsers.parser_image_in_tar",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nCACHE_FILENAME_SUFFIX = '_tarinfos.pickle'\nclass TarState:\n    def __init__(self, tf: tarfile.TarFile = None, ti: tarfile.TarInfo = None):\n        self.tf: tarfile.TarFile = tf\n        self.ti: tarfile.TarInfo = ti\n        self.children: Dict[str, TarState] = {}  # child states (tars within tars)\n    def reset(self):\n        self.tf = None\ndef _extract_tarinfo(tf: tarfile.TarFile, parent_info: Dict, extensions=IMG_EXTENSIONS):",
        "detail": "timm.data.parsers.parser_image_in_tar",
        "documentation": {}
    },
    {
        "label": "CACHE_FILENAME_SUFFIX",
        "kind": 5,
        "importPath": "timm.data.parsers.parser_image_in_tar",
        "description": "timm.data.parsers.parser_image_in_tar",
        "peekOfCode": "CACHE_FILENAME_SUFFIX = '_tarinfos.pickle'\nclass TarState:\n    def __init__(self, tf: tarfile.TarFile = None, ti: tarfile.TarInfo = None):\n        self.tf: tarfile.TarFile = tf\n        self.ti: tarfile.TarInfo = ti\n        self.children: Dict[str, TarState] = {}  # child states (tars within tars)\n    def reset(self):\n        self.tf = None\ndef _extract_tarinfo(tf: tarfile.TarFile, parent_info: Dict, extensions=IMG_EXTENSIONS):\n    sample_count = 0",
        "detail": "timm.data.parsers.parser_image_in_tar",
        "documentation": {}
    },
    {
        "label": "ParserImageTar",
        "kind": 6,
        "importPath": "timm.data.parsers.parser_image_tar",
        "description": "timm.data.parsers.parser_image_tar",
        "peekOfCode": "class ParserImageTar(Parser):\n    \"\"\" Single tarfile dataset where classes are mapped to folders within tar\n    NOTE: This class is being deprecated in favour of the more capable ParserImageInTar that can\n    operate on folders of tars or tars in tars.\n    \"\"\"\n    def __init__(self, root, class_map=''):\n        super().__init__()\n        class_to_idx = None\n        if class_map:\n            class_to_idx = load_class_map(class_map, root)",
        "detail": "timm.data.parsers.parser_image_tar",
        "documentation": {}
    },
    {
        "label": "extract_tarinfo",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_image_tar",
        "description": "timm.data.parsers.parser_image_tar",
        "peekOfCode": "def extract_tarinfo(tarfile, class_to_idx=None, sort=True):\n    files = []\n    labels = []\n    for ti in tarfile.getmembers():\n        if not ti.isfile():\n            continue\n        dirname, basename = os.path.split(ti.path)\n        label = os.path.basename(dirname)\n        ext = os.path.splitext(basename)[1]\n        if ext.lower() in IMG_EXTENSIONS:",
        "detail": "timm.data.parsers.parser_image_tar",
        "documentation": {}
    },
    {
        "label": "ParserTfds",
        "kind": 6,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "class ParserTfds(Parser):\n    \"\"\" Wrap Tensorflow Datasets for use in PyTorch\n    There several things to be aware of:\n      * To prevent excessive examples being dropped per epoch w/ distributed training or multiplicity of\n         dataloader workers, the train iterator wraps to avoid returning partial batches that trigger drop_last\n         https://github.com/pytorch/pytorch/issues/33413\n      * With PyTorch IterableDatasets, each worker in each replica operates in isolation, the final batch\n        from each worker could be a different size. For training this is worked around by option above, for\n        validation extra examples are inserted iff distributed mode is enabled so that the batches being reduced\n        across replicas are of same size. This will slightly alter the results, distributed validation will not be",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "even_split_indices",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "def even_split_indices(split, n, num_examples):\n    partitions = [round(i * num_examples / n) for i in range(n + 1)]\n    return [f\"{split}[{partitions[i]}:{partitions[i + 1]}]\" for i in range(n)]\ndef get_class_labels(info):\n    if 'label' not in info.features:\n        return {}\n    class_label = info.features['label']\n    class_to_idx = {n: class_label.str2int(n) for n in class_label.names}\n    return class_to_idx\nclass ParserTfds(Parser):",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "get_class_labels",
        "kind": 2,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "def get_class_labels(info):\n    if 'label' not in info.features:\n        return {}\n    class_label = info.features['label']\n    class_to_idx = {n: class_label.str2int(n) for n in class_label.names}\n    return class_to_idx\nclass ParserTfds(Parser):\n    \"\"\" Wrap Tensorflow Datasets for use in PyTorch\n    There several things to be aware of:\n      * To prevent excessive examples being dropped per epoch w/ distributed training or multiplicity of",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "MAX_TP_SIZE",
        "kind": 5,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "MAX_TP_SIZE = 8  # maximum TF threadpool size, only doing jpeg decodes and queuing activities\nSHUFFLE_SIZE = 8192  # examples to shuffle in DS queue\nPREFETCH_SIZE = 2048  # examples to prefetch\ndef even_split_indices(split, n, num_examples):\n    partitions = [round(i * num_examples / n) for i in range(n + 1)]\n    return [f\"{split}[{partitions[i]}:{partitions[i + 1]}]\" for i in range(n)]\ndef get_class_labels(info):\n    if 'label' not in info.features:\n        return {}\n    class_label = info.features['label']",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "SHUFFLE_SIZE",
        "kind": 5,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "SHUFFLE_SIZE = 8192  # examples to shuffle in DS queue\nPREFETCH_SIZE = 2048  # examples to prefetch\ndef even_split_indices(split, n, num_examples):\n    partitions = [round(i * num_examples / n) for i in range(n + 1)]\n    return [f\"{split}[{partitions[i]}:{partitions[i + 1]}]\" for i in range(n)]\ndef get_class_labels(info):\n    if 'label' not in info.features:\n        return {}\n    class_label = info.features['label']\n    class_to_idx = {n: class_label.str2int(n) for n in class_label.names}",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "PREFETCH_SIZE",
        "kind": 5,
        "importPath": "timm.data.parsers.parser_tfds",
        "description": "timm.data.parsers.parser_tfds",
        "peekOfCode": "PREFETCH_SIZE = 2048  # examples to prefetch\ndef even_split_indices(split, n, num_examples):\n    partitions = [round(i * num_examples / n) for i in range(n + 1)]\n    return [f\"{split}[{partitions[i]}:{partitions[i + 1]}]\" for i in range(n)]\ndef get_class_labels(info):\n    if 'label' not in info.features:\n        return {}\n    class_label = info.features['label']\n    class_to_idx = {n: class_label.str2int(n) for n in class_label.names}\n    return class_to_idx",
        "detail": "timm.data.parsers.parser_tfds",
        "documentation": {}
    },
    {
        "label": "AugmentOp",
        "kind": 6,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "class AugmentOp:\n    def __init__(self, name, prob=0.5, magnitude=10, hparams=None):\n        hparams = hparams or _HPARAMS_DEFAULT\n        self.name = name\n        self.aug_fn = NAME_TO_OP[name]\n        self.level_fn = LEVEL_TO_ARG[name]\n        self.prob = prob\n        self.magnitude = magnitude\n        self.hparams = hparams.copy()\n        self.kwargs = dict(",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "AutoAugment",
        "kind": 6,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "class AutoAugment:\n    def __init__(self, policy):\n        self.policy = policy\n    def __call__(self, img):\n        sub_policy = random.choice(self.policy)\n        for op in sub_policy:\n            img = op(img)\n        return img\n    def __repr__(self):\n        fs = self.__class__.__name__ + f'(policy='",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "RandAugment",
        "kind": 6,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "class RandAugment:\n    def __init__(self, ops, num_layers=2, choice_weights=None):\n        self.ops = ops\n        self.num_layers = num_layers\n        self.choice_weights = choice_weights\n    def __call__(self, img):\n        # no replacement when using weighted choice\n        ops = np.random.choice(\n            self.ops, self.num_layers, replace=self.choice_weights is None, p=self.choice_weights)\n        for op in ops:",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "AugMixAugment",
        "kind": 6,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "class AugMixAugment:\n    \"\"\" AugMix Transform\n    Adapted and improved from impl here: https://github.com/google-research/augmix/blob/master/imagenet.py\n    From paper: 'AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty -\n    https://arxiv.org/abs/1912.02781\n    \"\"\"\n    def __init__(self, ops, alpha=1., width=3, depth=-1, blended=False):\n        self.ops = ops\n        self.alpha = alpha\n        self.width = width",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "shear_x",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def shear_x(img, factor, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, factor, 0, 0, 1, 0), **kwargs)\ndef shear_y(img, factor, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, factor, 1, 0), **kwargs)\ndef translate_x_rel(img, pct, **kwargs):\n    pixels = pct * img.size[0]\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "shear_y",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def shear_y(img, factor, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, factor, 1, 0), **kwargs)\ndef translate_x_rel(img, pct, **kwargs):\n    pixels = pct * img.size[0]\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\ndef translate_y_rel(img, pct, **kwargs):\n    pixels = pct * img.size[1]\n    _check_args_tf(kwargs)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "translate_x_rel",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def translate_x_rel(img, pct, **kwargs):\n    pixels = pct * img.size[0]\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\ndef translate_y_rel(img, pct, **kwargs):\n    pixels = pct * img.size[1]\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\ndef translate_x_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "translate_y_rel",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def translate_y_rel(img, pct, **kwargs):\n    pixels = pct * img.size[1]\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\ndef translate_x_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\ndef translate_y_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "translate_x_abs",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def translate_x_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, pixels, 0, 1, 0), **kwargs)\ndef translate_y_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\ndef rotate(img, degrees, **kwargs):\n    _check_args_tf(kwargs)\n    if _PIL_VER >= (5, 2):\n        return img.rotate(degrees, **kwargs)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "translate_y_abs",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def translate_y_abs(img, pixels, **kwargs):\n    _check_args_tf(kwargs)\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, pixels), **kwargs)\ndef rotate(img, degrees, **kwargs):\n    _check_args_tf(kwargs)\n    if _PIL_VER >= (5, 2):\n        return img.rotate(degrees, **kwargs)\n    elif _PIL_VER >= (5, 0):\n        w, h = img.size\n        post_trans = (0, 0)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "rotate",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def rotate(img, degrees, **kwargs):\n    _check_args_tf(kwargs)\n    if _PIL_VER >= (5, 2):\n        return img.rotate(degrees, **kwargs)\n    elif _PIL_VER >= (5, 0):\n        w, h = img.size\n        post_trans = (0, 0)\n        rotn_center = (w / 2.0, h / 2.0)\n        angle = -math.radians(degrees)\n        matrix = [",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_contrast",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_contrast(img, **__):\n    return ImageOps.autocontrast(img)\ndef invert(img, **__):\n    return ImageOps.invert(img)\ndef equalize(img, **__):\n    return ImageOps.equalize(img)\ndef solarize(img, thresh, **__):\n    return ImageOps.solarize(img, thresh)\ndef solarize_add(img, add, thresh=128, **__):\n    lut = []",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "invert",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def invert(img, **__):\n    return ImageOps.invert(img)\ndef equalize(img, **__):\n    return ImageOps.equalize(img)\ndef solarize(img, thresh, **__):\n    return ImageOps.solarize(img, thresh)\ndef solarize_add(img, add, thresh=128, **__):\n    lut = []\n    for i in range(256):\n        if i < thresh:",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "equalize",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def equalize(img, **__):\n    return ImageOps.equalize(img)\ndef solarize(img, thresh, **__):\n    return ImageOps.solarize(img, thresh)\ndef solarize_add(img, add, thresh=128, **__):\n    lut = []\n    for i in range(256):\n        if i < thresh:\n            lut.append(min(255, i + add))\n        else:",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "solarize",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def solarize(img, thresh, **__):\n    return ImageOps.solarize(img, thresh)\ndef solarize_add(img, add, thresh=128, **__):\n    lut = []\n    for i in range(256):\n        if i < thresh:\n            lut.append(min(255, i + add))\n        else:\n            lut.append(i)\n    if img.mode in (\"L\", \"RGB\"):",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "solarize_add",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def solarize_add(img, add, thresh=128, **__):\n    lut = []\n    for i in range(256):\n        if i < thresh:\n            lut.append(min(255, i + add))\n        else:\n            lut.append(i)\n    if img.mode in (\"L\", \"RGB\"):\n        if img.mode == \"RGB\" and len(lut) == 256:\n            lut = lut + lut + lut",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "posterize",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def posterize(img, bits_to_keep, **__):\n    if bits_to_keep >= 8:\n        return img\n    return ImageOps.posterize(img, bits_to_keep)\ndef contrast(img, factor, **__):\n    return ImageEnhance.Contrast(img).enhance(factor)\ndef color(img, factor, **__):\n    return ImageEnhance.Color(img).enhance(factor)\ndef brightness(img, factor, **__):\n    return ImageEnhance.Brightness(img).enhance(factor)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "contrast",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def contrast(img, factor, **__):\n    return ImageEnhance.Contrast(img).enhance(factor)\ndef color(img, factor, **__):\n    return ImageEnhance.Color(img).enhance(factor)\ndef brightness(img, factor, **__):\n    return ImageEnhance.Brightness(img).enhance(factor)\ndef sharpness(img, factor, **__):\n    return ImageEnhance.Sharpness(img).enhance(factor)\ndef _randomly_negate(v):\n    \"\"\"With 50% prob, negate the value\"\"\"",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "color",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def color(img, factor, **__):\n    return ImageEnhance.Color(img).enhance(factor)\ndef brightness(img, factor, **__):\n    return ImageEnhance.Brightness(img).enhance(factor)\ndef sharpness(img, factor, **__):\n    return ImageEnhance.Sharpness(img).enhance(factor)\ndef _randomly_negate(v):\n    \"\"\"With 50% prob, negate the value\"\"\"\n    return -v if random.random() > 0.5 else v\ndef _rotate_level_to_arg(level, _hparams):",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "brightness",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def brightness(img, factor, **__):\n    return ImageEnhance.Brightness(img).enhance(factor)\ndef sharpness(img, factor, **__):\n    return ImageEnhance.Sharpness(img).enhance(factor)\ndef _randomly_negate(v):\n    \"\"\"With 50% prob, negate the value\"\"\"\n    return -v if random.random() > 0.5 else v\ndef _rotate_level_to_arg(level, _hparams):\n    # range [-30, 30]\n    level = (level / _LEVEL_DENOM) * 30.",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "sharpness",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def sharpness(img, factor, **__):\n    return ImageEnhance.Sharpness(img).enhance(factor)\ndef _randomly_negate(v):\n    \"\"\"With 50% prob, negate the value\"\"\"\n    return -v if random.random() > 0.5 else v\ndef _rotate_level_to_arg(level, _hparams):\n    # range [-30, 30]\n    level = (level / _LEVEL_DENOM) * 30.\n    level = _randomly_negate(level)\n    return level,",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_policy_v0",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_policy_v0(hparams):\n    # ImageNet v0 policy from TPU EfficientNet impl, cannot find a paper reference.\n    policy = [\n        [('Equalize', 0.8, 1), ('ShearY', 0.8, 4)],\n        [('Color', 0.4, 9), ('Equalize', 0.6, 3)],\n        [('Color', 0.4, 1), ('Rotate', 0.6, 8)],\n        [('Solarize', 0.8, 3), ('Equalize', 0.4, 7)],\n        [('Solarize', 0.4, 2), ('Solarize', 0.6, 2)],\n        [('Color', 0.2, 0), ('Equalize', 0.8, 8)],\n        [('Equalize', 0.4, 8), ('SolarizeAdd', 0.8, 3)],",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_policy_v0r",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_policy_v0r(hparams):\n    # ImageNet v0 policy from TPU EfficientNet impl, with variation of Posterize used\n    # in Google research implementation (number of bits discarded increases with magnitude)\n    policy = [\n        [('Equalize', 0.8, 1), ('ShearY', 0.8, 4)],\n        [('Color', 0.4, 9), ('Equalize', 0.6, 3)],\n        [('Color', 0.4, 1), ('Rotate', 0.6, 8)],\n        [('Solarize', 0.8, 3), ('Equalize', 0.4, 7)],\n        [('Solarize', 0.4, 2), ('Solarize', 0.6, 2)],\n        [('Color', 0.2, 0), ('Equalize', 0.8, 8)],",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_policy_original",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_policy_original(hparams):\n    # ImageNet policy from https://arxiv.org/abs/1805.09501\n    policy = [\n        [('PosterizeOriginal', 0.4, 8), ('Rotate', 0.6, 9)],\n        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n        [('PosterizeOriginal', 0.6, 7), ('PosterizeOriginal', 0.6, 6)],\n        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n        [('Equalize', 0.4, 4), ('Rotate', 0.8, 8)],\n        [('Solarize', 0.6, 3), ('Equalize', 0.6, 7)],",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_policy_originalr",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_policy_originalr(hparams):\n    # ImageNet policy from https://arxiv.org/abs/1805.09501 with research posterize variation\n    policy = [\n        [('PosterizeIncreasing', 0.4, 8), ('Rotate', 0.6, 9)],\n        [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5)],\n        [('Equalize', 0.8, 8), ('Equalize', 0.6, 3)],\n        [('PosterizeIncreasing', 0.6, 7), ('PosterizeIncreasing', 0.6, 6)],\n        [('Equalize', 0.4, 7), ('Solarize', 0.2, 4)],\n        [('Equalize', 0.4, 4), ('Rotate', 0.8, 8)],\n        [('Solarize', 0.6, 3), ('Equalize', 0.6, 7)],",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_policy",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_policy(name='v0', hparams=None):\n    hparams = hparams or _HPARAMS_DEFAULT\n    if name == 'original':\n        return auto_augment_policy_original(hparams)\n    elif name == 'originalr':\n        return auto_augment_policy_originalr(hparams)\n    elif name == 'v0':\n        return auto_augment_policy_v0(hparams)\n    elif name == 'v0r':\n        return auto_augment_policy_v0r(hparams)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "auto_augment_transform",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def auto_augment_transform(config_str, hparams):\n    \"\"\"\n    Create a AutoAugment transform\n    :param config_str: String defining configuration of auto augmentation. Consists of multiple sections separated by\n    dashes ('-'). The first section defines the AutoAugment policy (one of 'v0', 'v0r', 'original', 'originalr').\n    The remaining sections, not order sepecific determine\n        'mstd' -  float std deviation of magnitude noise applied\n    Ex 'original-mstd0.5' results in AutoAugment with original policy, magnitude_std 0.5\n    :param hparams: Other hparams (kwargs) for the AutoAugmentation scheme\n    :return: A PyTorch compatible Transform",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "rand_augment_ops",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def rand_augment_ops(magnitude=10, hparams=None, transforms=None):\n    hparams = hparams or _HPARAMS_DEFAULT\n    transforms = transforms or _RAND_TRANSFORMS\n    return [AugmentOp(\n        name, prob=0.5, magnitude=magnitude, hparams=hparams) for name in transforms]\nclass RandAugment:\n    def __init__(self, ops, num_layers=2, choice_weights=None):\n        self.ops = ops\n        self.num_layers = num_layers\n        self.choice_weights = choice_weights",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "rand_augment_transform",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def rand_augment_transform(config_str, hparams):\n    \"\"\"\n    Create a RandAugment transform\n    :param config_str: String defining configuration of random augmentation. Consists of multiple sections separated by\n    dashes ('-'). The first section defines the specific variant of rand augment (currently only 'rand'). The remaining\n    sections, not order sepecific determine\n        'm' - integer magnitude of rand augment\n        'n' - integer num layers (number of transform ops selected per image)\n        'w' - integer probabiliy weight index (index of a set of weights to influence choice of op)\n        'mstd' -  float std deviation of magnitude noise applied, or uniform sampling if infinity (or > 100)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "augmix_ops",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def augmix_ops(magnitude=10, hparams=None, transforms=None):\n    hparams = hparams or _HPARAMS_DEFAULT\n    transforms = transforms or _AUGMIX_TRANSFORMS\n    return [AugmentOp(\n        name, prob=1.0, magnitude=magnitude, hparams=hparams) for name in transforms]\nclass AugMixAugment:\n    \"\"\" AugMix Transform\n    Adapted and improved from impl here: https://github.com/google-research/augmix/blob/master/imagenet.py\n    From paper: 'AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty -\n    https://arxiv.org/abs/1912.02781",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "augment_and_mix_transform",
        "kind": 2,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "def augment_and_mix_transform(config_str, hparams):\n    \"\"\" Create AugMix PyTorch transform\n    :param config_str: String defining configuration of random augmentation. Consists of multiple sections separated by\n    dashes ('-'). The first section defines the specific variant of rand augment (currently only 'rand'). The remaining\n    sections, not order sepecific determine\n        'm' - integer magnitude (severity) of augmentation mix (default: 3)\n        'w' - integer width of augmentation chain (default: 3)\n        'd' - integer depth of augmentation chain (-1 is random [1, 3], default: -1)\n        'b' - integer (bool), blend each branch of chain into end result without a final blend, less CPU (default: 0)\n        'mstd' -  float std deviation of magnitude noise applied (default: 0)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_PIL_VER",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_PIL_VER = tuple([int(x) for x in PIL.__version__.split('.')[:2]])\n_FILL = (128, 128, 128)\n_LEVEL_DENOM = 10.  # denominator for conversion from 'Mx' magnitude scale to fractional aug level for op arguments\n_HPARAMS_DEFAULT = dict(\n    translate_const=250,\n    img_mean=_FILL,\n)\n_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\ndef _interpolation(kwargs):\n    interpolation = kwargs.pop('resample', Image.BILINEAR)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_FILL",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_FILL = (128, 128, 128)\n_LEVEL_DENOM = 10.  # denominator for conversion from 'Mx' magnitude scale to fractional aug level for op arguments\n_HPARAMS_DEFAULT = dict(\n    translate_const=250,\n    img_mean=_FILL,\n)\n_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\ndef _interpolation(kwargs):\n    interpolation = kwargs.pop('resample', Image.BILINEAR)\n    if isinstance(interpolation, (list, tuple)):",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_LEVEL_DENOM",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_LEVEL_DENOM = 10.  # denominator for conversion from 'Mx' magnitude scale to fractional aug level for op arguments\n_HPARAMS_DEFAULT = dict(\n    translate_const=250,\n    img_mean=_FILL,\n)\n_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\ndef _interpolation(kwargs):\n    interpolation = kwargs.pop('resample', Image.BILINEAR)\n    if isinstance(interpolation, (list, tuple)):\n        return random.choice(interpolation)",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_HPARAMS_DEFAULT",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_HPARAMS_DEFAULT = dict(\n    translate_const=250,\n    img_mean=_FILL,\n)\n_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\ndef _interpolation(kwargs):\n    interpolation = kwargs.pop('resample', Image.BILINEAR)\n    if isinstance(interpolation, (list, tuple)):\n        return random.choice(interpolation)\n    else:",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_RANDOM_INTERPOLATION",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)\ndef _interpolation(kwargs):\n    interpolation = kwargs.pop('resample', Image.BILINEAR)\n    if isinstance(interpolation, (list, tuple)):\n        return random.choice(interpolation)\n    else:\n        return interpolation\ndef _check_args_tf(kwargs):\n    if 'fillcolor' in kwargs and _PIL_VER < (5, 0):\n        kwargs.pop('fillcolor')",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "LEVEL_TO_ARG",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "LEVEL_TO_ARG = {\n    'AutoContrast': None,\n    'Equalize': None,\n    'Invert': None,\n    'Rotate': _rotate_level_to_arg,\n    # There are several variations of the posterize level scaling in various Tensorflow/Google repositories/papers\n    'Posterize': _posterize_level_to_arg,\n    'PosterizeIncreasing': _posterize_increasing_level_to_arg,\n    'PosterizeOriginal': _posterize_original_level_to_arg,\n    'Solarize': _solarize_level_to_arg,",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "NAME_TO_OP",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "NAME_TO_OP = {\n    'AutoContrast': auto_contrast,\n    'Equalize': equalize,\n    'Invert': invert,\n    'Rotate': rotate,\n    'Posterize': posterize,\n    'PosterizeIncreasing': posterize,\n    'PosterizeOriginal': posterize,\n    'Solarize': solarize,\n    'SolarizeIncreasing': solarize,",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_RAND_TRANSFORMS",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_RAND_TRANSFORMS = [\n    'AutoContrast',\n    'Equalize',\n    'Invert',\n    'Rotate',\n    'Posterize',\n    'Solarize',\n    'SolarizeAdd',\n    'Color',\n    'Contrast',",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_RAND_INCREASING_TRANSFORMS",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_RAND_INCREASING_TRANSFORMS = [\n    'AutoContrast',\n    'Equalize',\n    'Invert',\n    'Rotate',\n    'PosterizeIncreasing',\n    'SolarizeIncreasing',\n    'SolarizeAdd',\n    'ColorIncreasing',\n    'ContrastIncreasing',",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_RAND_CHOICE_WEIGHTS_0",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_RAND_CHOICE_WEIGHTS_0 = {\n    'Rotate': 0.3,\n    'ShearX': 0.2,\n    'ShearY': 0.2,\n    'TranslateXRel': 0.1,\n    'TranslateYRel': 0.1,\n    'Color': .025,\n    'Sharpness': 0.025,\n    'AutoContrast': 0.025,\n    'Solarize': .005,",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "_AUGMIX_TRANSFORMS",
        "kind": 5,
        "importPath": "timm.data.auto_augment",
        "description": "timm.data.auto_augment",
        "peekOfCode": "_AUGMIX_TRANSFORMS = [\n    'AutoContrast',\n    'ColorIncreasing',  # not in paper\n    'ContrastIncreasing',  # not in paper\n    'BrightnessIncreasing',  # not in paper\n    'SharpnessIncreasing',  # not in paper\n    'Equalize',\n    'Rotate',\n    'PosterizeIncreasing',\n    'SolarizeIncreasing',",
        "detail": "timm.data.auto_augment",
        "documentation": {}
    },
    {
        "label": "resolve_data_config",
        "kind": 2,
        "importPath": "timm.data.config",
        "description": "timm.data.config",
        "peekOfCode": "def resolve_data_config(args, default_cfg={}, model=None, use_test_size=False, verbose=False):\n    new_config = {}\n    default_cfg = default_cfg\n    if not default_cfg and model is not None and hasattr(model, 'default_cfg'):\n        default_cfg = model.default_cfg\n    # Resolve input/image size\n    in_chans = 3\n    if 'chans' in args and args['chans'] is not None:\n        in_chans = args['chans']\n    input_size = (in_chans, 224, 224)",
        "detail": "timm.data.config",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.data.config",
        "description": "timm.data.config",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef resolve_data_config(args, default_cfg={}, model=None, use_test_size=False, verbose=False):\n    new_config = {}\n    default_cfg = default_cfg\n    if not default_cfg and model is not None and hasattr(model, 'default_cfg'):\n        default_cfg = model.default_cfg\n    # Resolve input/image size\n    in_chans = 3\n    if 'chans' in args and args['chans'] is not None:\n        in_chans = args['chans']",
        "detail": "timm.data.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CROP_PCT",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "DEFAULT_CROP_PCT = 0.875\nIMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\nIMAGENET_INCEPTION_MEAN = (0.5, 0.5, 0.5)\nIMAGENET_INCEPTION_STD = (0.5, 0.5, 0.5)\nIMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_MEAN",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\nIMAGENET_INCEPTION_MEAN = (0.5, 0.5, 0.5)\nIMAGENET_INCEPTION_STD = (0.5, 0.5, 0.5)\nIMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DEFAULT_STD",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\nIMAGENET_INCEPTION_MEAN = (0.5, 0.5, 0.5)\nIMAGENET_INCEPTION_STD = (0.5, 0.5, 0.5)\nIMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_MEAN",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_INCEPTION_MEAN = (0.5, 0.5, 0.5)\nIMAGENET_INCEPTION_STD = (0.5, 0.5, 0.5)\nIMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_INCEPTION_STD",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_INCEPTION_STD = (0.5, 0.5, 0.5)\nIMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DPN_MEAN",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_DPN_MEAN = (124 / 255, 117 / 255, 104 / 255)\nIMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "IMAGENET_DPN_STD",
        "kind": 5,
        "importPath": "timm.data.constants",
        "description": "timm.data.constants",
        "peekOfCode": "IMAGENET_DPN_STD = tuple([1 / (.0167 * 255)] * 3)",
        "detail": "timm.data.constants",
        "documentation": {}
    },
    {
        "label": "ImageDataset",
        "kind": 6,
        "importPath": "timm.data.dataset",
        "description": "timm.data.dataset",
        "peekOfCode": "class ImageDataset(data.Dataset):\n    def __init__(\n            self,\n            root,\n            parser=None,\n            class_map=None,\n            load_bytes=False,\n            transform=None,\n            target_transform=None,\n    ):",
        "detail": "timm.data.dataset",
        "documentation": {}
    },
    {
        "label": "IterableImageDataset",
        "kind": 6,
        "importPath": "timm.data.dataset",
        "description": "timm.data.dataset",
        "peekOfCode": "class IterableImageDataset(data.IterableDataset):\n    def __init__(\n            self,\n            root,\n            parser=None,\n            split='train',\n            is_training=False,\n            batch_size=None,\n            repeats=0,\n            download=False,",
        "detail": "timm.data.dataset",
        "documentation": {}
    },
    {
        "label": "AugMixDataset",
        "kind": 6,
        "importPath": "timm.data.dataset",
        "description": "timm.data.dataset",
        "peekOfCode": "class AugMixDataset(torch.utils.data.Dataset):\n    \"\"\"Dataset wrapper to perform AugMix or other clean/augmentation mixes\"\"\"\n    def __init__(self, dataset, num_splits=2):\n        self.augmentation = None\n        self.normalize = None\n        self.dataset = dataset\n        if self.dataset.transform is not None:\n            self._set_transforms(self.dataset.transform)\n        self.num_splits = num_splits\n    def _set_transforms(self, x):",
        "detail": "timm.data.dataset",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.data.dataset",
        "description": "timm.data.dataset",
        "peekOfCode": "_logger = logging.getLogger(__name__)\n_ERROR_RETRY = 50\nclass ImageDataset(data.Dataset):\n    def __init__(\n            self,\n            root,\n            parser=None,\n            class_map=None,\n            load_bytes=False,\n            transform=None,",
        "detail": "timm.data.dataset",
        "documentation": {}
    },
    {
        "label": "_ERROR_RETRY",
        "kind": 5,
        "importPath": "timm.data.dataset",
        "description": "timm.data.dataset",
        "peekOfCode": "_ERROR_RETRY = 50\nclass ImageDataset(data.Dataset):\n    def __init__(\n            self,\n            root,\n            parser=None,\n            class_map=None,\n            load_bytes=False,\n            transform=None,\n            target_transform=None,",
        "detail": "timm.data.dataset",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "timm.data.dataset_factory",
        "description": "timm.data.dataset_factory",
        "peekOfCode": "def create_dataset(\n        name,\n        root,\n        split='validation',\n        search_split=True,\n        class_map=None,\n        load_bytes=False,\n        is_training=False,\n        download=False,\n        batch_size=None,",
        "detail": "timm.data.dataset_factory",
        "documentation": {}
    },
    {
        "label": "_TORCH_BASIC_DS",
        "kind": 5,
        "importPath": "timm.data.dataset_factory",
        "description": "timm.data.dataset_factory",
        "peekOfCode": "_TORCH_BASIC_DS = dict(\n    cifar10=CIFAR10,\n    cifar100=CIFAR100,\n    mnist=MNIST,\n    qmist=QMNIST,\n    kmnist=KMNIST,\n    fashion_mnist=FashionMNIST,\n)\n_TRAIN_SYNONYM = {'train', 'training'}\n_EVAL_SYNONYM = {'val', 'valid', 'validation', 'eval', 'evaluation'}",
        "detail": "timm.data.dataset_factory",
        "documentation": {}
    },
    {
        "label": "_TRAIN_SYNONYM",
        "kind": 5,
        "importPath": "timm.data.dataset_factory",
        "description": "timm.data.dataset_factory",
        "peekOfCode": "_TRAIN_SYNONYM = {'train', 'training'}\n_EVAL_SYNONYM = {'val', 'valid', 'validation', 'eval', 'evaluation'}\ndef _search_split(root, split):\n    # look for sub-folder with name of split in root and use that if it exists\n    split_name = split.split('[')[0]\n    try_root = os.path.join(root, split_name)\n    if os.path.exists(try_root):\n        return try_root\n    def _try(syn):\n        for s in syn:",
        "detail": "timm.data.dataset_factory",
        "documentation": {}
    },
    {
        "label": "_EVAL_SYNONYM",
        "kind": 5,
        "importPath": "timm.data.dataset_factory",
        "description": "timm.data.dataset_factory",
        "peekOfCode": "_EVAL_SYNONYM = {'val', 'valid', 'validation', 'eval', 'evaluation'}\ndef _search_split(root, split):\n    # look for sub-folder with name of split in root and use that if it exists\n    split_name = split.split('[')[0]\n    try_root = os.path.join(root, split_name)\n    if os.path.exists(try_root):\n        return try_root\n    def _try(syn):\n        for s in syn:\n            try_root = os.path.join(root, s)",
        "detail": "timm.data.dataset_factory",
        "documentation": {}
    },
    {
        "label": "OrderedDistributedSampler",
        "kind": 6,
        "importPath": "timm.data.distributed_sampler",
        "description": "timm.data.distributed_sampler",
        "peekOfCode": "class OrderedDistributedSampler(Sampler):\n    \"\"\"Sampler that restricts data loading to a subset of the dataset.\n    It is especially useful in conjunction with\n    :class:`torch.nn.parallel.DistributedDataParallel`. In such case, each\n    process can pass a DistributedSampler instance as a DataLoader sampler,\n    and load a subset of the original dataset that is exclusive to it.\n    .. note::\n        Dataset is assumed to be of constant size.\n    Arguments:\n        dataset: Dataset used for sampling.",
        "detail": "timm.data.distributed_sampler",
        "documentation": {}
    },
    {
        "label": "RepeatAugSampler",
        "kind": 6,
        "importPath": "timm.data.distributed_sampler",
        "description": "timm.data.distributed_sampler",
        "peekOfCode": "class RepeatAugSampler(Sampler):\n    \"\"\"Sampler that restricts data loading to a subset of the dataset for distributed,\n    with repeated augmentation.\n    It ensures that different each augmented version of a sample will be visible to a\n    different process (GPU). Heavily based on torch.utils.data.DistributedSampler\n    This sampler was taken from https://github.com/facebookresearch/deit/blob/0c4b8f60/samplers.py\n    Used in\n    Copyright (c) 2015-present, Facebook, Inc.\n    \"\"\"\n    def __init__(",
        "detail": "timm.data.distributed_sampler",
        "documentation": {}
    },
    {
        "label": "PrefetchLoader",
        "kind": 6,
        "importPath": "timm.data.loader",
        "description": "timm.data.loader",
        "peekOfCode": "class PrefetchLoader:\n    def __init__(self,\n                 loader,\n                 mean=IMAGENET_DEFAULT_MEAN,\n                 std=IMAGENET_DEFAULT_STD,\n                 fp16=False,\n                 re_prob=0.,\n                 re_mode='const',\n                 re_count=1,\n                 re_num_splits=0):",
        "detail": "timm.data.loader",
        "documentation": {}
    },
    {
        "label": "MultiEpochsDataLoader",
        "kind": 6,
        "importPath": "timm.data.loader",
        "description": "timm.data.loader",
        "peekOfCode": "class MultiEpochsDataLoader(torch.utils.data.DataLoader):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._DataLoader__initialized = False\n        self.batch_sampler = _RepeatSampler(self.batch_sampler)\n        self._DataLoader__initialized = True\n        self.iterator = super().__iter__()\n    def __len__(self):\n        return len(self.batch_sampler.sampler)\n    def __iter__(self):",
        "detail": "timm.data.loader",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "timm.data.loader",
        "description": "timm.data.loader",
        "peekOfCode": "class _RepeatSampler(object):\n    \"\"\" Sampler that repeats forever.\n    Args:\n        sampler (Sampler)\n    \"\"\"\n    def __init__(self, sampler):\n        self.sampler = sampler\n    def __iter__(self):\n        while True:\n            yield from iter(self.sampler)",
        "detail": "timm.data.loader",
        "documentation": {}
    },
    {
        "label": "fast_collate",
        "kind": 2,
        "importPath": "timm.data.loader",
        "description": "timm.data.loader",
        "peekOfCode": "def fast_collate(batch):\n    \"\"\" A fast collation function optimized for uint8 images (np array or torch) and int64 targets (labels)\"\"\"\n    assert isinstance(batch[0], tuple)\n    batch_size = len(batch)\n    if isinstance(batch[0][0], tuple):\n        # This branch 'deinterleaves' and flattens tuples of input tensors into one tensor ordered by position\n        # such that all tuple of position n will end up in a torch.split(tensor, batch_size) in nth position\n        inner_tuple_size = len(batch[0][0])\n        flattened_batch_size = batch_size * inner_tuple_size\n        targets = torch.zeros(flattened_batch_size, dtype=torch.int64)",
        "detail": "timm.data.loader",
        "documentation": {}
    },
    {
        "label": "create_loader",
        "kind": 2,
        "importPath": "timm.data.loader",
        "description": "timm.data.loader",
        "peekOfCode": "def create_loader(\n        dataset,\n        input_size,\n        batch_size,\n        is_training=False,\n        use_prefetcher=True,\n        no_aug=False,\n        re_prob=0.,\n        re_mode='const',\n        re_count=1,",
        "detail": "timm.data.loader",
        "documentation": {}
    },
    {
        "label": "Mixup",
        "kind": 6,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "class Mixup:\n    \"\"\" Mixup/Cutmix that applies different params to each element or whole batch\n    Args:\n        mixup_alpha (float): mixup alpha value, mixup is active if > 0.\n        cutmix_alpha (float): cutmix alpha value, cutmix is active if > 0.\n        cutmix_minmax (List[float]): cutmix min/max image ratio, cutmix is active and uses this vs alpha if not None.\n        prob (float): probability of applying mixup or cutmix per batch or element\n        switch_prob (float): probability of switching to cutmix instead of mixup when both are active\n        mode (str): how to apply mixup/cutmix params (per 'batch', 'pair' (pair of elements), 'elem' (element)\n        correct_lam (bool): apply lambda correction when cutmix bbox clipped by image borders",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "FastCollateMixup",
        "kind": 6,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "class FastCollateMixup(Mixup):\n    \"\"\" Fast Collate w/ Mixup/Cutmix that applies different params to each element or whole batch\n    A Mixup impl that's performed while collating the batches.\n    \"\"\"\n    def _mix_elem_collate(self, output, batch, half=False):\n        batch_size = len(batch)\n        num_elem = batch_size // 2 if half else batch_size\n        assert len(output) == num_elem\n        lam_batch, use_cutmix = self._params_per_elem(num_elem)\n        for i in range(num_elem):",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "one_hot",
        "kind": 2,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "def one_hot(x, num_classes, on_value=1., off_value=0., device='cuda'):\n    x = x.long().view(-1, 1)\n    return torch.full((x.size()[0], num_classes), off_value, device=device).scatter_(1, x, on_value)\ndef mixup_target(target, num_classes, lam=1., smoothing=0.0, device='cuda'):\n    off_value = smoothing / num_classes\n    on_value = 1. - smoothing + off_value\n    y1 = one_hot(target, num_classes, on_value=on_value, off_value=off_value, device=device)\n    y2 = one_hot(target.flip(0), num_classes, on_value=on_value, off_value=off_value, device=device)\n    return y1 * lam + y2 * (1. - lam)\ndef rand_bbox(img_shape, lam, margin=0., count=None):",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "mixup_target",
        "kind": 2,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "def mixup_target(target, num_classes, lam=1., smoothing=0.0, device='cuda'):\n    off_value = smoothing / num_classes\n    on_value = 1. - smoothing + off_value\n    y1 = one_hot(target, num_classes, on_value=on_value, off_value=off_value, device=device)\n    y2 = one_hot(target.flip(0), num_classes, on_value=on_value, off_value=off_value, device=device)\n    return y1 * lam + y2 * (1. - lam)\ndef rand_bbox(img_shape, lam, margin=0., count=None):\n    \"\"\" Standard CutMix bounding-box\n    Generates a random square bbox based on lambda value. This impl includes\n    support for enforcing a border margin as percent of bbox dimensions.",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "rand_bbox",
        "kind": 2,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "def rand_bbox(img_shape, lam, margin=0., count=None):\n    \"\"\" Standard CutMix bounding-box\n    Generates a random square bbox based on lambda value. This impl includes\n    support for enforcing a border margin as percent of bbox dimensions.\n    Args:\n        img_shape (tuple): Image shape as tuple\n        lam (float): Cutmix lambda value\n        margin (float): Percentage of bbox dimension to enforce as margin (reduce amount of box outside image)\n        count (int): Number of bbox to generate\n    \"\"\"",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "rand_bbox_minmax",
        "kind": 2,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "def rand_bbox_minmax(img_shape, minmax, count=None):\n    \"\"\" Min-Max CutMix bounding-box\n    Inspired by Darknet cutmix impl, generates a random rectangular bbox\n    based on min/max percent values applied to each dimension of the input image.\n    Typical defaults for minmax are usually in the  .2-.3 for min and .8-.9 range for max.\n    Args:\n        img_shape (tuple): Image shape as tuple\n        minmax (tuple or list): Min and max bbox ratios (as percent of image size)\n        count (int): Number of bbox to generate\n    \"\"\"",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "cutmix_bbox_and_lam",
        "kind": 2,
        "importPath": "timm.data.mixup",
        "description": "timm.data.mixup",
        "peekOfCode": "def cutmix_bbox_and_lam(img_shape, lam, ratio_minmax=None, correct_lam=True, count=None):\n    \"\"\" Generate bbox and apply lambda correction.\n    \"\"\"\n    if ratio_minmax is not None:\n        yl, yu, xl, xu = rand_bbox_minmax(img_shape, ratio_minmax, count=count)\n    else:\n        yl, yu, xl, xu = rand_bbox(img_shape, lam, count=count)\n    if correct_lam or ratio_minmax is not None:\n        bbox_area = (yu - yl) * (xu - xl)\n        lam = 1. - bbox_area / float(img_shape[-2] * img_shape[-1])",
        "detail": "timm.data.mixup",
        "documentation": {}
    },
    {
        "label": "RandomErasing",
        "kind": 6,
        "importPath": "timm.data.random_erasing",
        "description": "timm.data.random_erasing",
        "peekOfCode": "class RandomErasing:\n    \"\"\" Randomly selects a rectangle region in an image and erases its pixels.\n        'Random Erasing Data Augmentation' by Zhong et al.\n        See https://arxiv.org/pdf/1708.04896.pdf\n        This variant of RandomErasing is intended to be applied to either a batch\n        or single image tensor after it has been normalized by dataset mean and std.\n    Args:\n         probability: Probability that the Random Erasing operation will be performed.\n         min_area: Minimum percentage of erased area wrt input image area.\n         max_area: Maximum percentage of erased area wrt input image area.",
        "detail": "timm.data.random_erasing",
        "documentation": {}
    },
    {
        "label": "RealLabelsImagenet",
        "kind": 6,
        "importPath": "timm.data.real_labels",
        "description": "timm.data.real_labels",
        "peekOfCode": "class RealLabelsImagenet:\n    def __init__(self, filenames, real_json='real.json', topk=(1, 5)):\n        with open(real_json) as real_labels:\n            real_labels = json.load(real_labels)\n            real_labels = {f'ILSVRC2012_val_{i + 1:08d}.JPEG': labels for i, labels in enumerate(real_labels)}\n        self.real_labels = real_labels\n        self.filenames = filenames\n        assert len(self.filenames) == len(self.real_labels)\n        self.topk = topk\n        self.is_correct = {k: [] for k in topk}",
        "detail": "timm.data.real_labels",
        "documentation": {}
    },
    {
        "label": "TfPreprocessTransform",
        "kind": 6,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "class TfPreprocessTransform:\n    def __init__(self, is_training=False, size=224, interpolation='bicubic'):\n        self.is_training = is_training\n        self.size = size[0] if isinstance(size, tuple) else size\n        self.interpolation = interpolation\n        self._image_bytes = None\n        self.process_image = self._build_tf_graph()\n        self.sess = None\n    def _build_tf_graph(self):\n        with tf.device('/cpu:0'):",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "distorted_bounding_box_crop",
        "kind": 2,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "def distorted_bounding_box_crop(image_bytes,\n                                bbox,\n                                min_object_covered=0.1,\n                                aspect_ratio_range=(0.75, 1.33),\n                                area_range=(0.05, 1.0),\n                                max_attempts=100,\n                                scope=None):\n    \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n    See `tf.image.sample_distorted_bounding_box` for more documentation.\n    Args:",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "preprocess_for_train",
        "kind": 2,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic'):\n    \"\"\"Preprocesses the given image for evaluation.\n    Args:\n      image_bytes: `Tensor` representing an image binary of arbitrary size.\n      use_bfloat16: `bool` for whether to use bfloat16.\n      image_size: image size.\n      interpolation: image interpolation method\n    Returns:\n      A preprocessed image `Tensor`.\n    \"\"\"",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "preprocess_for_eval",
        "kind": 2,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic'):\n    \"\"\"Preprocesses the given image for evaluation.\n    Args:\n      image_bytes: `Tensor` representing an image binary of arbitrary size.\n      use_bfloat16: `bool` for whether to use bfloat16.\n      image_size: image size.\n      interpolation: image interpolation method\n    Returns:\n      A preprocessed image `Tensor`.\n    \"\"\"",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "preprocess_image",
        "kind": 2,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "def preprocess_image(image_bytes,\n                     is_training=False,\n                     use_bfloat16=False,\n                     image_size=IMAGE_SIZE,\n                     interpolation='bicubic'):\n    \"\"\"Preprocesses the given image.\n    Args:\n      image_bytes: `Tensor` representing an image binary of arbitrary size.\n      is_training: `bool` for whether the preprocessing is for training.\n      use_bfloat16: `bool` for whether to use bfloat16.",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "IMAGE_SIZE = 224\nCROP_PADDING = 32\ndef distorted_bounding_box_crop(image_bytes,\n                                bbox,\n                                min_object_covered=0.1,\n                                aspect_ratio_range=(0.75, 1.33),\n                                area_range=(0.05, 1.0),\n                                max_attempts=100,\n                                scope=None):\n    \"\"\"Generates cropped_image using one of the bboxes randomly distorted.",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "CROP_PADDING",
        "kind": 5,
        "importPath": "timm.data.tf_preprocessing",
        "description": "timm.data.tf_preprocessing",
        "peekOfCode": "CROP_PADDING = 32\ndef distorted_bounding_box_crop(image_bytes,\n                                bbox,\n                                min_object_covered=0.1,\n                                aspect_ratio_range=(0.75, 1.33),\n                                area_range=(0.05, 1.0),\n                                max_attempts=100,\n                                scope=None):\n    \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n    See `tf.image.sample_distorted_bounding_box` for more documentation.",
        "detail": "timm.data.tf_preprocessing",
        "documentation": {}
    },
    {
        "label": "ToNumpy",
        "kind": 6,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "class ToNumpy:\n    def __call__(self, pil_img):\n        np_img = np.array(pil_img, dtype=np.uint8)\n        if np_img.ndim < 3:\n            np_img = np.expand_dims(np_img, axis=-1)\n        np_img = np.rollaxis(np_img, 2)  # HWC to CHW\n        return np_img\nclass ToTensor:\n    def __init__(self, dtype=torch.float32):\n        self.dtype = dtype",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "class ToTensor:\n    def __init__(self, dtype=torch.float32):\n        self.dtype = dtype\n    def __call__(self, pil_img):\n        np_img = np.array(pil_img, dtype=np.uint8)\n        if np_img.ndim < 3:\n            np_img = np.expand_dims(np_img, axis=-1)\n        np_img = np.rollaxis(np_img, 2)  # HWC to CHW\n        return torch.from_numpy(np_img).to(dtype=self.dtype)\n_pil_interpolation_to_str = {",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "RandomResizedCropAndInterpolation",
        "kind": 6,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "class RandomResizedCropAndInterpolation:\n    \"\"\"Crop the given PIL Image to random size and aspect ratio with random interpolation.\n    A crop of random size (default: of 0.08 to 1.0) of the original size and a random\n    aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop\n    is finally resized to given size.\n    This is popularly used to train the Inception networks.\n    Args:\n        size: expected output size of each edge\n        scale: range of size of the origin size cropped\n        ratio: range of aspect ratio of the origin aspect ratio cropped",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "str_to_pil_interp",
        "kind": 2,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "def str_to_pil_interp(mode_str):\n    return _str_to_pil_interpolation[mode_str]\ndef str_to_interp_mode(mode_str):\n    if has_interpolation_mode:\n        return _str_to_torch_interpolation[mode_str]\n    else:\n        return _str_to_pil_interpolation[mode_str]\ndef interp_mode_to_str(mode):\n    if has_interpolation_mode:\n        return _torch_interpolation_to_str[mode]",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "str_to_interp_mode",
        "kind": 2,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "def str_to_interp_mode(mode_str):\n    if has_interpolation_mode:\n        return _str_to_torch_interpolation[mode_str]\n    else:\n        return _str_to_pil_interpolation[mode_str]\ndef interp_mode_to_str(mode):\n    if has_interpolation_mode:\n        return _torch_interpolation_to_str[mode]\n    else:\n        return _pil_interpolation_to_str[mode]",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "interp_mode_to_str",
        "kind": 2,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "def interp_mode_to_str(mode):\n    if has_interpolation_mode:\n        return _torch_interpolation_to_str[mode]\n    else:\n        return _pil_interpolation_to_str[mode]\n_RANDOM_INTERPOLATION = (str_to_interp_mode('bilinear'), str_to_interp_mode('bicubic'))\nclass RandomResizedCropAndInterpolation:\n    \"\"\"Crop the given PIL Image to random size and aspect ratio with random interpolation.\n    A crop of random size (default: of 0.08 to 1.0) of the original size and a random\n    aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "_pil_interpolation_to_str",
        "kind": 5,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "_pil_interpolation_to_str = {\n    Image.NEAREST: 'nearest',\n    Image.BILINEAR: 'bilinear',\n    Image.BICUBIC: 'bicubic',\n    Image.BOX: 'box',\n    Image.HAMMING: 'hamming',\n    Image.LANCZOS: 'lanczos',\n}\n_str_to_pil_interpolation = {b: a for a, b in _pil_interpolation_to_str.items()}\nif has_interpolation_mode:",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "_str_to_pil_interpolation",
        "kind": 5,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "_str_to_pil_interpolation = {b: a for a, b in _pil_interpolation_to_str.items()}\nif has_interpolation_mode:\n    _torch_interpolation_to_str = {\n        InterpolationMode.NEAREST: 'nearest',\n        InterpolationMode.BILINEAR: 'bilinear',\n        InterpolationMode.BICUBIC: 'bicubic',\n        InterpolationMode.BOX: 'box',\n        InterpolationMode.HAMMING: 'hamming',\n        InterpolationMode.LANCZOS: 'lanczos',\n    }",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "_RANDOM_INTERPOLATION",
        "kind": 5,
        "importPath": "timm.data.transforms",
        "description": "timm.data.transforms",
        "peekOfCode": "_RANDOM_INTERPOLATION = (str_to_interp_mode('bilinear'), str_to_interp_mode('bicubic'))\nclass RandomResizedCropAndInterpolation:\n    \"\"\"Crop the given PIL Image to random size and aspect ratio with random interpolation.\n    A crop of random size (default: of 0.08 to 1.0) of the original size and a random\n    aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop\n    is finally resized to given size.\n    This is popularly used to train the Inception networks.\n    Args:\n        size: expected output size of each edge\n        scale: range of size of the origin size cropped",
        "detail": "timm.data.transforms",
        "documentation": {}
    },
    {
        "label": "transforms_noaug_train",
        "kind": 2,
        "importPath": "timm.data.transforms_factory",
        "description": "timm.data.transforms_factory",
        "peekOfCode": "def transforms_noaug_train(\n        img_size=224,\n        interpolation='bilinear',\n        use_prefetcher=False,\n        mean=IMAGENET_DEFAULT_MEAN,\n        std=IMAGENET_DEFAULT_STD,\n):\n    if interpolation == 'random':\n        # random interpolation not supported with no-aug\n        interpolation = 'bilinear'",
        "detail": "timm.data.transforms_factory",
        "documentation": {}
    },
    {
        "label": "transforms_imagenet_train",
        "kind": 2,
        "importPath": "timm.data.transforms_factory",
        "description": "timm.data.transforms_factory",
        "peekOfCode": "def transforms_imagenet_train(\n        img_size=224,\n        scale=None,\n        ratio=None,\n        hflip=0.5,\n        vflip=0.,\n        color_jitter=0.4,\n        auto_augment=None,\n        interpolation='random',\n        use_prefetcher=False,",
        "detail": "timm.data.transforms_factory",
        "documentation": {}
    },
    {
        "label": "transforms_imagenet_eval",
        "kind": 2,
        "importPath": "timm.data.transforms_factory",
        "description": "timm.data.transforms_factory",
        "peekOfCode": "def transforms_imagenet_eval(\n        img_size=224,\n        crop_pct=None,\n        interpolation='bilinear',\n        use_prefetcher=False,\n        mean=IMAGENET_DEFAULT_MEAN,\n        std=IMAGENET_DEFAULT_STD):\n    crop_pct = crop_pct or DEFAULT_CROP_PCT\n    if isinstance(img_size, (tuple, list)):\n        assert len(img_size) == 2",
        "detail": "timm.data.transforms_factory",
        "documentation": {}
    },
    {
        "label": "create_transform",
        "kind": 2,
        "importPath": "timm.data.transforms_factory",
        "description": "timm.data.transforms_factory",
        "peekOfCode": "def create_transform(\n        input_size,\n        is_training=False,\n        use_prefetcher=False,\n        no_aug=False,\n        scale=None,\n        ratio=None,\n        hflip=0.5,\n        vflip=0.,\n        color_jitter=0.4,",
        "detail": "timm.data.transforms_factory",
        "documentation": {}
    },
    {
        "label": "AsymmetricLossMultiLabel",
        "kind": 6,
        "importPath": "timm.loss.asymmetric_loss",
        "description": "timm.loss.asymmetric_loss",
        "peekOfCode": "class AsymmetricLossMultiLabel(nn.Module):\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n        super(AsymmetricLossMultiLabel, self).__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n        self.eps = eps\n    def forward(self, x, y):\n        \"\"\"\"",
        "detail": "timm.loss.asymmetric_loss",
        "documentation": {}
    },
    {
        "label": "AsymmetricLossSingleLabel",
        "kind": 6,
        "importPath": "timm.loss.asymmetric_loss",
        "description": "timm.loss.asymmetric_loss",
        "peekOfCode": "class AsymmetricLossSingleLabel(nn.Module):\n    def __init__(self, gamma_pos=1, gamma_neg=4, eps: float = 0.1, reduction='mean'):\n        super(AsymmetricLossSingleLabel, self).__init__()\n        self.eps = eps\n        self.logsoftmax = nn.LogSoftmax(dim=-1)\n        self.targets_classes = []  # prevent gpu repeated memory allocation\n        self.gamma_pos = gamma_pos\n        self.gamma_neg = gamma_neg\n        self.reduction = reduction\n    def forward(self, inputs, target, reduction=None):",
        "detail": "timm.loss.asymmetric_loss",
        "documentation": {}
    },
    {
        "label": "BinaryCrossEntropy",
        "kind": 6,
        "importPath": "timm.loss.binary_cross_entropy",
        "description": "timm.loss.binary_cross_entropy",
        "peekOfCode": "class BinaryCrossEntropy(nn.Module):\n    \"\"\" BCE with optional one-hot from dense targets, label smoothing, thresholding\n    NOTE for experiments comparing CE to BCE /w label smoothing, may remove\n    \"\"\"\n    def __init__(\n            self, smoothing=0.1, target_threshold: Optional[float] = None, weight: Optional[torch.Tensor] = None,\n            reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None):\n        super(BinaryCrossEntropy, self).__init__()\n        assert 0. <= smoothing < 1.0\n        self.smoothing = smoothing",
        "detail": "timm.loss.binary_cross_entropy",
        "documentation": {}
    },
    {
        "label": "LabelSmoothingCrossEntropy",
        "kind": 6,
        "importPath": "timm.loss.cross_entropy",
        "description": "timm.loss.cross_entropy",
        "peekOfCode": "class LabelSmoothingCrossEntropy(nn.Module):\n    \"\"\" NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.1):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        assert smoothing < 1.0\n        self.smoothing = smoothing\n        self.confidence = 1. - smoothing\n    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        logprobs = F.log_softmax(x, dim=-1)",
        "detail": "timm.loss.cross_entropy",
        "documentation": {}
    },
    {
        "label": "SoftTargetCrossEntropy",
        "kind": 6,
        "importPath": "timm.loss.cross_entropy",
        "description": "timm.loss.cross_entropy",
        "peekOfCode": "class SoftTargetCrossEntropy(nn.Module):\n    def __init__(self):\n        super(SoftTargetCrossEntropy, self).__init__()\n    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        loss = torch.sum(-target * F.log_softmax(x, dim=-1), dim=-1)\n        return loss.mean()",
        "detail": "timm.loss.cross_entropy",
        "documentation": {}
    },
    {
        "label": "JsdCrossEntropy",
        "kind": 6,
        "importPath": "timm.loss.jsd",
        "description": "timm.loss.jsd",
        "peekOfCode": "class JsdCrossEntropy(nn.Module):\n    \"\"\" Jensen-Shannon Divergence + Cross-Entropy Loss\n    Based on impl here: https://github.com/google-research/augmix/blob/master/imagenet.py\n    From paper: 'AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty -\n    https://arxiv.org/abs/1912.02781\n    Hacked together by / Copyright 2020 Ross Wightman\n    \"\"\"\n    def __init__(self, num_splits=3, alpha=12, smoothing=0.1):\n        super().__init__()\n        self.num_splits = num_splits",
        "detail": "timm.loss.jsd",
        "documentation": {}
    },
    {
        "label": "Swish",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class Swish(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Swish, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return swish(x, self.inplace)\ndef mish(x, inplace: bool = False):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    NOTE: I don't have a working inplace variant\n    \"\"\"",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "Mish",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class Mish(nn.Module):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    \"\"\"\n    def __init__(self, inplace: bool = False):\n        super(Mish, self).__init__()\n    def forward(self, x):\n        return mish(x)\ndef sigmoid(x, inplace: bool = False):\n    return x.sigmoid_() if inplace else x.sigmoid()\n# PyTorch has this, but not with a consistent inplace argmument interface",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "Sigmoid",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class Sigmoid(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Sigmoid, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return x.sigmoid_() if self.inplace else x.sigmoid()\ndef tanh(x, inplace: bool = False):\n    return x.tanh_() if inplace else x.tanh()\n# PyTorch has this, but not with a consistent inplace argmument interface\nclass Tanh(nn.Module):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "Tanh",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class Tanh(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Tanh, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return x.tanh_() if self.inplace else x.tanh()\ndef hard_swish(x, inplace: bool = False):\n    inner = F.relu6(x + 3.).div_(6.)\n    return x.mul_(inner) if inplace else x.mul(inner)\nclass HardSwish(nn.Module):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "HardSwish",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class HardSwish(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwish, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return hard_swish(x, self.inplace)\ndef hard_sigmoid(x, inplace: bool = False):\n    if inplace:\n        return x.add_(3.).clamp_(0., 6.).div_(6.)\n    else:",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "HardSigmoid",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class HardSigmoid(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoid, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return hard_sigmoid(x, self.inplace)\ndef hard_mish(x, inplace: bool = False):\n    \"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "HardMish",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class HardMish(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardMish, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return hard_mish(x, self.inplace)\nclass PReLU(nn.PReLU):\n    \"\"\"Applies PReLU (w/ dummy inplace arg)\n    \"\"\"\n    def __init__(self, num_parameters: int = 1, init: float = 0.25, inplace: bool = False) -> None:",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "PReLU",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class PReLU(nn.PReLU):\n    \"\"\"Applies PReLU (w/ dummy inplace arg)\n    \"\"\"\n    def __init__(self, num_parameters: int = 1, init: float = 0.25, inplace: bool = False) -> None:\n        super(PReLU, self).__init__(num_parameters=num_parameters, init=init)\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return F.prelu(input, self.weight)\ndef gelu(x: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n    return F.gelu(x)\nclass GELU(nn.Module):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "GELU",
        "kind": 6,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "class GELU(nn.Module):\n    \"\"\"Applies the Gaussian Error Linear Units function (w/ dummy inplace arg)\n    \"\"\"\n    def __init__(self, inplace: bool = False):\n        super(GELU, self).__init__()\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return F.gelu(input)",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "swish",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def swish(x, inplace: bool = False):\n    \"\"\"Swish - Described in: https://arxiv.org/abs/1710.05941\n    \"\"\"\n    return x.mul_(x.sigmoid()) if inplace else x.mul(x.sigmoid())\nclass Swish(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Swish, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return swish(x, self.inplace)",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "mish",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def mish(x, inplace: bool = False):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    NOTE: I don't have a working inplace variant\n    \"\"\"\n    return x.mul(F.softplus(x).tanh())\nclass Mish(nn.Module):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    \"\"\"\n    def __init__(self, inplace: bool = False):\n        super(Mish, self).__init__()",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "sigmoid",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def sigmoid(x, inplace: bool = False):\n    return x.sigmoid_() if inplace else x.sigmoid()\n# PyTorch has this, but not with a consistent inplace argmument interface\nclass Sigmoid(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Sigmoid, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return x.sigmoid_() if self.inplace else x.sigmoid()\ndef tanh(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "tanh",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def tanh(x, inplace: bool = False):\n    return x.tanh_() if inplace else x.tanh()\n# PyTorch has this, but not with a consistent inplace argmument interface\nclass Tanh(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(Tanh, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return x.tanh_() if self.inplace else x.tanh()\ndef hard_swish(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "hard_swish",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def hard_swish(x, inplace: bool = False):\n    inner = F.relu6(x + 3.).div_(6.)\n    return x.mul_(inner) if inplace else x.mul(inner)\nclass HardSwish(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwish, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return hard_swish(x, self.inplace)\ndef hard_sigmoid(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "hard_sigmoid",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def hard_sigmoid(x, inplace: bool = False):\n    if inplace:\n        return x.add_(3.).clamp_(0., 6.).div_(6.)\n    else:\n        return F.relu6(x + 3.) / 6.\nclass HardSigmoid(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoid, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "hard_mish",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def hard_mish(x, inplace: bool = False):\n    \"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"\n    if inplace:\n        return x.mul_(0.5 * (x + 2).clamp(min=0, max=2))\n    else:\n        return 0.5 * x * (x + 2).clamp(min=0, max=2)\nclass HardMish(nn.Module):",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "gelu",
        "kind": 2,
        "importPath": "timm.models.layers.activations",
        "description": "timm.models.layers.activations",
        "peekOfCode": "def gelu(x: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n    return F.gelu(x)\nclass GELU(nn.Module):\n    \"\"\"Applies the Gaussian Error Linear Units function (w/ dummy inplace arg)\n    \"\"\"\n    def __init__(self, inplace: bool = False):\n        super(GELU, self).__init__()\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return F.gelu(input)",
        "detail": "timm.models.layers.activations",
        "documentation": {}
    },
    {
        "label": "SwishJit",
        "kind": 6,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "class SwishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(SwishJit, self).__init__()\n    def forward(self, x):\n        return swish_jit(x)\nclass MishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(MishJit, self).__init__()\n    def forward(self, x):\n        return mish_jit(x)",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "MishJit",
        "kind": 6,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "class MishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(MishJit, self).__init__()\n    def forward(self, x):\n        return mish_jit(x)\n@torch.jit.script\ndef hard_sigmoid_jit(x, inplace: bool = False):\n    # return F.relu6(x + 3.) / 6.\n    return (x + 3).clamp(min=0, max=6).div(6.)  # clamp seems ever so slightly faster?\nclass HardSigmoidJit(nn.Module):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "HardSigmoidJit",
        "kind": 6,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "class HardSigmoidJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoidJit, self).__init__()\n    def forward(self, x):\n        return hard_sigmoid_jit(x)\n@torch.jit.script\ndef hard_swish_jit(x, inplace: bool = False):\n    # return x * (F.relu6(x + 3.) / 6)\n    return x * (x + 3).clamp(min=0, max=6).div(6.)  # clamp seems ever so slightly faster?\nclass HardSwishJit(nn.Module):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "HardSwishJit",
        "kind": 6,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "class HardSwishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwishJit, self).__init__()\n    def forward(self, x):\n        return hard_swish_jit(x)\n@torch.jit.script\ndef hard_mish_jit(x, inplace: bool = False):\n    \"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "HardMishJit",
        "kind": 6,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "class HardMishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardMishJit, self).__init__()\n    def forward(self, x):\n        return hard_mish_jit(x)",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "swish_jit",
        "kind": 2,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "def swish_jit(x, inplace: bool = False):\n    \"\"\"Swish - Described in: https://arxiv.org/abs/1710.05941\n    \"\"\"\n    return x.mul(x.sigmoid())\n@torch.jit.script\ndef mish_jit(x, _inplace: bool = False):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    \"\"\"\n    return x.mul(F.softplus(x).tanh())\nclass SwishJit(nn.Module):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "mish_jit",
        "kind": 2,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "def mish_jit(x, _inplace: bool = False):\n    \"\"\"Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    \"\"\"\n    return x.mul(F.softplus(x).tanh())\nclass SwishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(SwishJit, self).__init__()\n    def forward(self, x):\n        return swish_jit(x)\nclass MishJit(nn.Module):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "hard_sigmoid_jit",
        "kind": 2,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "def hard_sigmoid_jit(x, inplace: bool = False):\n    # return F.relu6(x + 3.) / 6.\n    return (x + 3).clamp(min=0, max=6).div(6.)  # clamp seems ever so slightly faster?\nclass HardSigmoidJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoidJit, self).__init__()\n    def forward(self, x):\n        return hard_sigmoid_jit(x)\n@torch.jit.script\ndef hard_swish_jit(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "hard_swish_jit",
        "kind": 2,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "def hard_swish_jit(x, inplace: bool = False):\n    # return x * (F.relu6(x + 3.) / 6)\n    return x * (x + 3).clamp(min=0, max=6).div(6.)  # clamp seems ever so slightly faster?\nclass HardSwishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwishJit, self).__init__()\n    def forward(self, x):\n        return hard_swish_jit(x)\n@torch.jit.script\ndef hard_mish_jit(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "hard_mish_jit",
        "kind": 2,
        "importPath": "timm.models.layers.activations_jit",
        "description": "timm.models.layers.activations_jit",
        "peekOfCode": "def hard_mish_jit(x, inplace: bool = False):\n    \"\"\" Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"\n    return 0.5 * x * (x + 2).clamp(min=0, max=2)\nclass HardMishJit(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardMishJit, self).__init__()\n    def forward(self, x):",
        "detail": "timm.models.layers.activations_jit",
        "documentation": {}
    },
    {
        "label": "SwishJitAutoFn",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class SwishJitAutoFn(torch.autograd.Function):\n    \"\"\" torch.jit.script optimised Swish w/ memory-efficient checkpoint\n    Inspired by conversation btw Jeremy Howard & Adam Pazske\n    https://twitter.com/jeremyphoward/status/1188251041835315200\n    \"\"\"\n    @staticmethod\n    def symbolic(g, x):\n        return g.op(\"Mul\", x, g.op(\"Sigmoid\", x))\n    @staticmethod\n    def forward(ctx, x):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "SwishMe",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class SwishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(SwishMe, self).__init__()\n    def forward(self, x):\n        return SwishJitAutoFn.apply(x)\n@torch.jit.script\ndef mish_jit_fwd(x):\n    return x.mul(torch.tanh(F.softplus(x)))\n@torch.jit.script\ndef mish_jit_bwd(x, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "MishJitAutoFn",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class MishJitAutoFn(torch.autograd.Function):\n    \"\"\" Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    A memory efficient, jit scripted variant of Mish\n    \"\"\"\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return mish_jit_fwd(x)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "MishMe",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class MishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(MishMe, self).__init__()\n    def forward(self, x):\n        return MishJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_sigmoid_jit_fwd(x, inplace: bool = False):\n    return (x + 3).clamp(min=0, max=6).div(6.)\n@torch.jit.script\ndef hard_sigmoid_jit_bwd(x, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardSigmoidJitAutoFn",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardSigmoidJitAutoFn(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return hard_sigmoid_jit_fwd(x)\n    @staticmethod\n    def backward(ctx, grad_output):\n        x = ctx.saved_tensors[0]\n        return hard_sigmoid_jit_bwd(x, grad_output)\ndef hard_sigmoid_me(x, inplace: bool = False):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardSigmoidMe",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardSigmoidMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoidMe, self).__init__()\n    def forward(self, x):\n        return HardSigmoidJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_swish_jit_fwd(x):\n    return x * (x + 3).clamp(min=0, max=6).div(6.)\n@torch.jit.script\ndef hard_swish_jit_bwd(x, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardSwishJitAutoFn",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardSwishJitAutoFn(torch.autograd.Function):\n    \"\"\"A memory efficient, jit-scripted HardSwish activation\"\"\"\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return hard_swish_jit_fwd(x)\n    @staticmethod\n    def backward(ctx, grad_output):\n        x = ctx.saved_tensors[0]\n        return hard_swish_jit_bwd(x, grad_output)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardSwishMe",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardSwishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwishMe, self).__init__()\n    def forward(self, x):\n        return HardSwishJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_mish_jit_fwd(x):\n    return 0.5 * x * (x + 2).clamp(min=0, max=2)\n@torch.jit.script\ndef hard_mish_jit_bwd(x, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardMishJitAutoFn",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardMishJitAutoFn(torch.autograd.Function):\n    \"\"\" A memory efficient, jit scripted variant of Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return hard_mish_jit_fwd(x)\n    @staticmethod",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "HardMishMe",
        "kind": 6,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "class HardMishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardMishMe, self).__init__()\n    def forward(self, x):\n        return HardMishJitAutoFn.apply(x)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "swish_jit_fwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def swish_jit_fwd(x):\n    return x.mul(torch.sigmoid(x))\n@torch.jit.script\ndef swish_jit_bwd(x, grad_output):\n    x_sigmoid = torch.sigmoid(x)\n    return grad_output * (x_sigmoid * (1 + x * (1 - x_sigmoid)))\nclass SwishJitAutoFn(torch.autograd.Function):\n    \"\"\" torch.jit.script optimised Swish w/ memory-efficient checkpoint\n    Inspired by conversation btw Jeremy Howard & Adam Pazske\n    https://twitter.com/jeremyphoward/status/1188251041835315200",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "swish_jit_bwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def swish_jit_bwd(x, grad_output):\n    x_sigmoid = torch.sigmoid(x)\n    return grad_output * (x_sigmoid * (1 + x * (1 - x_sigmoid)))\nclass SwishJitAutoFn(torch.autograd.Function):\n    \"\"\" torch.jit.script optimised Swish w/ memory-efficient checkpoint\n    Inspired by conversation btw Jeremy Howard & Adam Pazske\n    https://twitter.com/jeremyphoward/status/1188251041835315200\n    \"\"\"\n    @staticmethod\n    def symbolic(g, x):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "swish_me",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def swish_me(x, inplace=False):\n    return SwishJitAutoFn.apply(x)\nclass SwishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(SwishMe, self).__init__()\n    def forward(self, x):\n        return SwishJitAutoFn.apply(x)\n@torch.jit.script\ndef mish_jit_fwd(x):\n    return x.mul(torch.tanh(F.softplus(x)))",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "mish_jit_fwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def mish_jit_fwd(x):\n    return x.mul(torch.tanh(F.softplus(x)))\n@torch.jit.script\ndef mish_jit_bwd(x, grad_output):\n    x_sigmoid = torch.sigmoid(x)\n    x_tanh_sp = F.softplus(x).tanh()\n    return grad_output.mul(x_tanh_sp + x * x_sigmoid * (1 - x_tanh_sp * x_tanh_sp))\nclass MishJitAutoFn(torch.autograd.Function):\n    \"\"\" Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    A memory efficient, jit scripted variant of Mish",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "mish_jit_bwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def mish_jit_bwd(x, grad_output):\n    x_sigmoid = torch.sigmoid(x)\n    x_tanh_sp = F.softplus(x).tanh()\n    return grad_output.mul(x_tanh_sp + x * x_sigmoid * (1 - x_tanh_sp * x_tanh_sp))\nclass MishJitAutoFn(torch.autograd.Function):\n    \"\"\" Mish: A Self Regularized Non-Monotonic Neural Activation Function - https://arxiv.org/abs/1908.08681\n    A memory efficient, jit scripted variant of Mish\n    \"\"\"\n    @staticmethod\n    def forward(ctx, x):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "mish_me",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def mish_me(x, inplace=False):\n    return MishJitAutoFn.apply(x)\nclass MishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(MishMe, self).__init__()\n    def forward(self, x):\n        return MishJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_sigmoid_jit_fwd(x, inplace: bool = False):\n    return (x + 3).clamp(min=0, max=6).div(6.)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_sigmoid_jit_fwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_sigmoid_jit_fwd(x, inplace: bool = False):\n    return (x + 3).clamp(min=0, max=6).div(6.)\n@torch.jit.script\ndef hard_sigmoid_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * ((x >= -3.) & (x <= 3.)) / 6.\n    return grad_output * m\nclass HardSigmoidJitAutoFn(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_sigmoid_jit_bwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_sigmoid_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * ((x >= -3.) & (x <= 3.)) / 6.\n    return grad_output * m\nclass HardSigmoidJitAutoFn(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return hard_sigmoid_jit_fwd(x)\n    @staticmethod\n    def backward(ctx, grad_output):",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_sigmoid_me",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_sigmoid_me(x, inplace: bool = False):\n    return HardSigmoidJitAutoFn.apply(x)\nclass HardSigmoidMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSigmoidMe, self).__init__()\n    def forward(self, x):\n        return HardSigmoidJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_swish_jit_fwd(x):\n    return x * (x + 3).clamp(min=0, max=6).div(6.)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_swish_jit_fwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_swish_jit_fwd(x):\n    return x * (x + 3).clamp(min=0, max=6).div(6.)\n@torch.jit.script\ndef hard_swish_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * (x >= 3.)\n    m = torch.where((x >= -3.) & (x <= 3.),  x / 3. + .5, m)\n    return grad_output * m\nclass HardSwishJitAutoFn(torch.autograd.Function):\n    \"\"\"A memory efficient, jit-scripted HardSwish activation\"\"\"\n    @staticmethod",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_swish_jit_bwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_swish_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * (x >= 3.)\n    m = torch.where((x >= -3.) & (x <= 3.),  x / 3. + .5, m)\n    return grad_output * m\nclass HardSwishJitAutoFn(torch.autograd.Function):\n    \"\"\"A memory efficient, jit-scripted HardSwish activation\"\"\"\n    @staticmethod\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return hard_swish_jit_fwd(x)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_swish_me",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_swish_me(x, inplace=False):\n    return HardSwishJitAutoFn.apply(x)\nclass HardSwishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardSwishMe, self).__init__()\n    def forward(self, x):\n        return HardSwishJitAutoFn.apply(x)\n@torch.jit.script\ndef hard_mish_jit_fwd(x):\n    return 0.5 * x * (x + 2).clamp(min=0, max=2)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_mish_jit_fwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_mish_jit_fwd(x):\n    return 0.5 * x * (x + 2).clamp(min=0, max=2)\n@torch.jit.script\ndef hard_mish_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * (x >= -2.)\n    m = torch.where((x >= -2.) & (x <= 0.), x + 1., m)\n    return grad_output * m\nclass HardMishJitAutoFn(torch.autograd.Function):\n    \"\"\" A memory efficient, jit scripted variant of Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_mish_jit_bwd",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_mish_jit_bwd(x, grad_output):\n    m = torch.ones_like(x) * (x >= -2.)\n    m = torch.where((x >= -2.) & (x <= 0.), x + 1., m)\n    return grad_output * m\nclass HardMishJitAutoFn(torch.autograd.Function):\n    \"\"\" A memory efficient, jit scripted variant of Hard Mish\n    Experimental, based on notes by Mish author Diganta Misra at\n      https://github.com/digantamisra98/H-Mish/blob/0da20d4bc58e696b6803f2523c58d3c8a82782d0/README.md\n    \"\"\"\n    @staticmethod",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "hard_mish_me",
        "kind": 2,
        "importPath": "timm.models.layers.activations_me",
        "description": "timm.models.layers.activations_me",
        "peekOfCode": "def hard_mish_me(x, inplace: bool = False):\n    return HardMishJitAutoFn.apply(x)\nclass HardMishMe(nn.Module):\n    def __init__(self, inplace: bool = False):\n        super(HardMishMe, self).__init__()\n    def forward(self, x):\n        return HardMishJitAutoFn.apply(x)",
        "detail": "timm.models.layers.activations_me",
        "documentation": {}
    },
    {
        "label": "FastAdaptiveAvgPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "class FastAdaptiveAvgPool2d(nn.Module):\n    def __init__(self, flatten=False):\n        super(FastAdaptiveAvgPool2d, self).__init__()\n        self.flatten = flatten\n    def forward(self, x):\n        return x.mean((2, 3), keepdim=not self.flatten)\nclass AdaptiveAvgMaxPool2d(nn.Module):\n    def __init__(self, output_size=1):\n        super(AdaptiveAvgMaxPool2d, self).__init__()\n        self.output_size = output_size",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "AdaptiveAvgMaxPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "class AdaptiveAvgMaxPool2d(nn.Module):\n    def __init__(self, output_size=1):\n        super(AdaptiveAvgMaxPool2d, self).__init__()\n        self.output_size = output_size\n    def forward(self, x):\n        return adaptive_avgmax_pool2d(x, self.output_size)\nclass AdaptiveCatAvgMaxPool2d(nn.Module):\n    def __init__(self, output_size=1):\n        super(AdaptiveCatAvgMaxPool2d, self).__init__()\n        self.output_size = output_size",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "AdaptiveCatAvgMaxPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "class AdaptiveCatAvgMaxPool2d(nn.Module):\n    def __init__(self, output_size=1):\n        super(AdaptiveCatAvgMaxPool2d, self).__init__()\n        self.output_size = output_size\n    def forward(self, x):\n        return adaptive_catavgmax_pool2d(x, self.output_size)\nclass SelectAdaptivePool2d(nn.Module):\n    \"\"\"Selectable global pooling layer with dynamic input kernel size\n    \"\"\"\n    def __init__(self, output_size=1, pool_type='fast', flatten=False):",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "SelectAdaptivePool2d",
        "kind": 6,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "class SelectAdaptivePool2d(nn.Module):\n    \"\"\"Selectable global pooling layer with dynamic input kernel size\n    \"\"\"\n    def __init__(self, output_size=1, pool_type='fast', flatten=False):\n        super(SelectAdaptivePool2d, self).__init__()\n        self.pool_type = pool_type or ''  # convert other falsy values to empty string for consistent TS typing\n        self.flatten = nn.Flatten(1) if flatten else nn.Identity()\n        if pool_type == '':\n            self.pool = nn.Identity()  # pass through\n        elif pool_type == 'fast':",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "adaptive_pool_feat_mult",
        "kind": 2,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "def adaptive_pool_feat_mult(pool_type='avg'):\n    if pool_type == 'catavgmax':\n        return 2\n    else:\n        return 1\ndef adaptive_avgmax_pool2d(x, output_size=1):\n    x_avg = F.adaptive_avg_pool2d(x, output_size)\n    x_max = F.adaptive_max_pool2d(x, output_size)\n    return 0.5 * (x_avg + x_max)\ndef adaptive_catavgmax_pool2d(x, output_size=1):",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "adaptive_avgmax_pool2d",
        "kind": 2,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "def adaptive_avgmax_pool2d(x, output_size=1):\n    x_avg = F.adaptive_avg_pool2d(x, output_size)\n    x_max = F.adaptive_max_pool2d(x, output_size)\n    return 0.5 * (x_avg + x_max)\ndef adaptive_catavgmax_pool2d(x, output_size=1):\n    x_avg = F.adaptive_avg_pool2d(x, output_size)\n    x_max = F.adaptive_max_pool2d(x, output_size)\n    return torch.cat((x_avg, x_max), 1)\ndef select_adaptive_pool2d(x, pool_type='avg', output_size=1):\n    \"\"\"Selectable global pooling function with dynamic input kernel size",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "adaptive_catavgmax_pool2d",
        "kind": 2,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "def adaptive_catavgmax_pool2d(x, output_size=1):\n    x_avg = F.adaptive_avg_pool2d(x, output_size)\n    x_max = F.adaptive_max_pool2d(x, output_size)\n    return torch.cat((x_avg, x_max), 1)\ndef select_adaptive_pool2d(x, pool_type='avg', output_size=1):\n    \"\"\"Selectable global pooling function with dynamic input kernel size\n    \"\"\"\n    if pool_type == 'avg':\n        x = F.adaptive_avg_pool2d(x, output_size)\n    elif pool_type == 'avgmax':",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "select_adaptive_pool2d",
        "kind": 2,
        "importPath": "timm.models.layers.adaptive_avgmax_pool",
        "description": "timm.models.layers.adaptive_avgmax_pool",
        "peekOfCode": "def select_adaptive_pool2d(x, pool_type='avg', output_size=1):\n    \"\"\"Selectable global pooling function with dynamic input kernel size\n    \"\"\"\n    if pool_type == 'avg':\n        x = F.adaptive_avg_pool2d(x, output_size)\n    elif pool_type == 'avgmax':\n        x = adaptive_avgmax_pool2d(x, output_size)\n    elif pool_type == 'catavgmax':\n        x = adaptive_catavgmax_pool2d(x, output_size)\n    elif pool_type == 'max':",
        "detail": "timm.models.layers.adaptive_avgmax_pool",
        "documentation": {}
    },
    {
        "label": "RotaryEmbedding",
        "kind": 6,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "class RotaryEmbedding(nn.Module):\n    \"\"\" Rotary position embedding\n    NOTE: This is my initial attempt at impl rotary embedding for spatial use, it has not\n    been well tested, and will likely change. It will be moved to its own file.\n    The following impl/resources were referenced for this impl:\n    * https://github.com/lucidrains/vit-pytorch/blob/6f3a5fcf0bca1c5ec33a35ef48d97213709df4ba/vit_pytorch/rvt.py\n    * https://blog.eleuther.ai/rotary-embeddings/\n    \"\"\"\n    def __init__(self, dim, max_freq=4):\n        super().__init__()",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "RotAttentionPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "class RotAttentionPool2d(nn.Module):\n    \"\"\" Attention based 2D feature pooling w/ rotary (relative) pos embedding.\n    This is a multi-head attention based replacement for (spatial) average pooling in NN architectures.\n    Adapted from the AttentionPool2d in CLIP w/ rotary embedding instead of learned embed.\n    https://github.com/openai/CLIP/blob/3b473b0e682c091a9e53623eebc1ca1657385717/clip/model.py\n    NOTE: While this impl does not require a fixed feature size, performance at differeing resolutions from\n    train varies widely and falls off dramatically. I'm not sure if there is a way around this... -RW\n    \"\"\"\n    def __init__(\n            self,",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "AttentionPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "class AttentionPool2d(nn.Module):\n    \"\"\" Attention based 2D feature pooling w/ learned (absolute) pos embedding.\n    This is a multi-head attention based replacement for (spatial) average pooling in NN architectures.\n    It was based on impl in CLIP by OpenAI\n    https://github.com/openai/CLIP/blob/3b473b0e682c091a9e53623eebc1ca1657385717/clip/model.py\n    NOTE: This requires feature size upon construction and well prevent adaptive sizing of the network.\n    \"\"\"\n    def __init__(\n            self,\n            in_features: int,",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "rot",
        "kind": 2,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "def rot(x):\n    return torch.stack([-x[..., 1::2], x[..., ::2]], -1).reshape(x.shape)\ndef apply_rot_embed(x: torch.Tensor, sin_emb, cos_emb):\n    return x * cos_emb + rot(x) * sin_emb\ndef apply_rot_embed_list(x: List[torch.Tensor], sin_emb, cos_emb):\n    if isinstance(x, torch.Tensor):\n        x = [x]\n    return [t * cos_emb + rot(t) * sin_emb for t in x]\nclass RotaryEmbedding(nn.Module):\n    \"\"\" Rotary position embedding",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "apply_rot_embed",
        "kind": 2,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "def apply_rot_embed(x: torch.Tensor, sin_emb, cos_emb):\n    return x * cos_emb + rot(x) * sin_emb\ndef apply_rot_embed_list(x: List[torch.Tensor], sin_emb, cos_emb):\n    if isinstance(x, torch.Tensor):\n        x = [x]\n    return [t * cos_emb + rot(t) * sin_emb for t in x]\nclass RotaryEmbedding(nn.Module):\n    \"\"\" Rotary position embedding\n    NOTE: This is my initial attempt at impl rotary embedding for spatial use, it has not\n    been well tested, and will likely change. It will be moved to its own file.",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "apply_rot_embed_list",
        "kind": 2,
        "importPath": "timm.models.layers.attention_pool2d",
        "description": "timm.models.layers.attention_pool2d",
        "peekOfCode": "def apply_rot_embed_list(x: List[torch.Tensor], sin_emb, cos_emb):\n    if isinstance(x, torch.Tensor):\n        x = [x]\n    return [t * cos_emb + rot(t) * sin_emb for t in x]\nclass RotaryEmbedding(nn.Module):\n    \"\"\" Rotary position embedding\n    NOTE: This is my initial attempt at impl rotary embedding for spatial use, it has not\n    been well tested, and will likely change. It will be moved to its own file.\n    The following impl/resources were referenced for this impl:\n    * https://github.com/lucidrains/vit-pytorch/blob/6f3a5fcf0bca1c5ec33a35ef48d97213709df4ba/vit_pytorch/rvt.py",
        "detail": "timm.models.layers.attention_pool2d",
        "documentation": {}
    },
    {
        "label": "BlurPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.blur_pool",
        "description": "timm.models.layers.blur_pool",
        "peekOfCode": "class BlurPool2d(nn.Module):\n    r\"\"\"Creates a module that computes blurs and downsample a given feature map.\n    See :cite:`zhang2019shiftinvar` for more details.\n    Corresponds to the Downsample class, which does blurring and subsampling\n    Args:\n        channels = Number of input channels\n        filt_size (int): binomial filter size for blurring. currently supports 3 (default) and 5.\n        stride (int): downsampling filter stride\n    Returns:\n        torch.Tensor: the transformed tensor.",
        "detail": "timm.models.layers.blur_pool",
        "documentation": {}
    },
    {
        "label": "PosEmbedRel",
        "kind": 6,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "class PosEmbedRel(nn.Module):\n    \"\"\" Relative Position Embedding\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n    \"\"\"\n    def __init__(self, feat_size, dim_head, scale):\n        super().__init__()\n        self.height, self.width = to_2tuple(feat_size)\n        self.dim_head = dim_head\n        self.height_rel = nn.Parameter(torch.randn(self.height * 2 - 1, dim_head) * scale)",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "BottleneckAttn",
        "kind": 6,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "class BottleneckAttn(nn.Module):\n    \"\"\" Bottleneck Attention\n    Paper: `Bottleneck Transformers for Visual Recognition` - https://arxiv.org/abs/2101.11605\n    The internal dimensions of the attention module are controlled by the interaction of several arguments.\n      * the output dimension of the module is specified by dim_out, which falls back to input dim if not set\n      * the value (v) dimension is set to dim_out // num_heads, the v projection determines the output dim\n      * the query and key (qk) dimensions are determined by\n        * num_heads * dim_head if dim_head is not None\n        * num_heads * (dim_out * attn_ratio // num_heads) if dim_head is None\n      * as seen above, attn_ratio determines the ratio of q and k relative to the output if dim_head not used",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "rel_logits_1d",
        "kind": 2,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "def rel_logits_1d(q, rel_k, permute_mask: List[int]):\n    \"\"\" Compute relative logits along one dimension\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n    Args:\n        q: (batch, heads, height, width, dim)\n        rel_k: (2 * width - 1, dim)\n        permute_mask: permute output dim according to this\n    \"\"\"\n    B, H, W, dim = q.shape",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "Author",
        "kind": 5,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "Author = {Aravind Srinivas and Tsung-Yi Lin and Niki Parmar and Jonathon Shlens and Pieter Abbeel and Ashish Vaswani},\nTitle = {Bottleneck Transformers for Visual Recognition},\nYear = {2021},\n}\nBased on ref gist at: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\nThis impl is a WIP but given that it is based on the ref gist likely not too far off.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"\nfrom typing import List\nimport torch",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "Title",
        "kind": 5,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "Title = {Bottleneck Transformers for Visual Recognition},\nYear = {2021},\n}\nBased on ref gist at: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\nThis impl is a WIP but given that it is based on the ref gist likely not too far off.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"\nfrom typing import List\nimport torch\nimport torch.nn as nn",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "Year",
        "kind": 5,
        "importPath": "timm.models.layers.bottleneck_attn",
        "description": "timm.models.layers.bottleneck_attn",
        "peekOfCode": "Year = {2021},\n}\nBased on ref gist at: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\nThis impl is a WIP but given that it is based on the ref gist likely not too far off.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"\nfrom typing import List\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F",
        "detail": "timm.models.layers.bottleneck_attn",
        "documentation": {}
    },
    {
        "label": "ChannelAttn",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class ChannelAttn(nn.Module):\n    \"\"\" Original CBAM channel attention module, currently avg + max pool variant only.\n    \"\"\"\n    def __init__(\n            self, channels, rd_ratio=1./16, rd_channels=None, rd_divisor=1,\n            act_layer=nn.ReLU, gate_layer='sigmoid', mlp_bias=False):\n        super(ChannelAttn, self).__init__()\n        if not rd_channels:\n            rd_channels = make_divisible(channels * rd_ratio, rd_divisor, round_limit=0.)\n        self.fc1 = nn.Conv2d(channels, rd_channels, 1, bias=mlp_bias)",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "LightChannelAttn",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class LightChannelAttn(ChannelAttn):\n    \"\"\"An experimental 'lightweight' that sums avg + max pool first\n    \"\"\"\n    def __init__(\n            self, channels, rd_ratio=1./16, rd_channels=None, rd_divisor=1,\n            act_layer=nn.ReLU, gate_layer='sigmoid', mlp_bias=False):\n        super(LightChannelAttn, self).__init__(\n            channels, rd_ratio, rd_channels, rd_divisor, act_layer, gate_layer, mlp_bias)\n    def forward(self, x):\n        x_pool = 0.5 * x.mean((2, 3), keepdim=True) + 0.5 * x.amax((2, 3), keepdim=True)",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "SpatialAttn",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class SpatialAttn(nn.Module):\n    \"\"\" Original CBAM spatial attention module\n    \"\"\"\n    def __init__(self, kernel_size=7, gate_layer='sigmoid'):\n        super(SpatialAttn, self).__init__()\n        self.conv = ConvBnAct(2, 1, kernel_size, act_layer=None)\n        self.gate = create_act_layer(gate_layer)\n    def forward(self, x):\n        x_attn = torch.cat([x.mean(dim=1, keepdim=True), x.amax(dim=1, keepdim=True)], dim=1)\n        x_attn = self.conv(x_attn)",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "LightSpatialAttn",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class LightSpatialAttn(nn.Module):\n    \"\"\"An experimental 'lightweight' variant that sums avg_pool and max_pool results.\n    \"\"\"\n    def __init__(self, kernel_size=7, gate_layer='sigmoid'):\n        super(LightSpatialAttn, self).__init__()\n        self.conv = ConvBnAct(1, 1, kernel_size, act_layer=None)\n        self.gate = create_act_layer(gate_layer)\n    def forward(self, x):\n        x_attn = 0.5 * x.mean(dim=1, keepdim=True) + 0.5 * x.amax(dim=1, keepdim=True)\n        x_attn = self.conv(x_attn)",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "CbamModule",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class CbamModule(nn.Module):\n    def __init__(\n            self, channels, rd_ratio=1./16, rd_channels=None, rd_divisor=1,\n            spatial_kernel_size=7, act_layer=nn.ReLU, gate_layer='sigmoid', mlp_bias=False):\n        super(CbamModule, self).__init__()\n        self.channel = ChannelAttn(\n            channels, rd_ratio=rd_ratio, rd_channels=rd_channels,\n            rd_divisor=rd_divisor, act_layer=act_layer, gate_layer=gate_layer, mlp_bias=mlp_bias)\n        self.spatial = SpatialAttn(spatial_kernel_size, gate_layer=gate_layer)\n    def forward(self, x):",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "LightCbamModule",
        "kind": 6,
        "importPath": "timm.models.layers.cbam",
        "description": "timm.models.layers.cbam",
        "peekOfCode": "class LightCbamModule(nn.Module):\n    def __init__(\n            self, channels, rd_ratio=1./16, rd_channels=None, rd_divisor=1,\n            spatial_kernel_size=7, act_layer=nn.ReLU, gate_layer='sigmoid', mlp_bias=False):\n        super(LightCbamModule, self).__init__()\n        self.channel = LightChannelAttn(\n            channels, rd_ratio=rd_ratio, rd_channels=rd_channels,\n            rd_divisor=rd_divisor, act_layer=act_layer, gate_layer=gate_layer, mlp_bias=mlp_bias)\n        self.spatial = LightSpatialAttn(spatial_kernel_size)\n    def forward(self, x):",
        "detail": "timm.models.layers.cbam",
        "documentation": {}
    },
    {
        "label": "ClassifierHead",
        "kind": 6,
        "importPath": "timm.models.layers.classifier",
        "description": "timm.models.layers.classifier",
        "peekOfCode": "class ClassifierHead(nn.Module):\n    \"\"\"Classifier head w/ configurable global pooling and dropout.\"\"\"\n    def __init__(self, in_chs, num_classes, pool_type='avg', drop_rate=0., use_conv=False):\n        super(ClassifierHead, self).__init__()\n        self.drop_rate = drop_rate\n        self.global_pool, num_pooled_features = _create_pool(in_chs, num_classes, pool_type, use_conv=use_conv)\n        self.fc = _create_fc(num_pooled_features, num_classes, use_conv=use_conv)\n        self.flatten = nn.Flatten(1) if use_conv and pool_type else nn.Identity()\n    def forward(self, x):\n        x = self.global_pool(x)",
        "detail": "timm.models.layers.classifier",
        "documentation": {}
    },
    {
        "label": "create_classifier",
        "kind": 2,
        "importPath": "timm.models.layers.classifier",
        "description": "timm.models.layers.classifier",
        "peekOfCode": "def create_classifier(num_features, num_classes, pool_type='avg', use_conv=False):\n    global_pool, num_pooled_features = _create_pool(num_features, num_classes, pool_type, use_conv=use_conv)\n    fc = _create_fc(num_pooled_features, num_classes, use_conv=use_conv)\n    return global_pool, fc\nclass ClassifierHead(nn.Module):\n    \"\"\"Classifier head w/ configurable global pooling and dropout.\"\"\"\n    def __init__(self, in_chs, num_classes, pool_type='avg', drop_rate=0., use_conv=False):\n        super(ClassifierHead, self).__init__()\n        self.drop_rate = drop_rate\n        self.global_pool, num_pooled_features = _create_pool(in_chs, num_classes, pool_type, use_conv=use_conv)",
        "detail": "timm.models.layers.classifier",
        "documentation": {}
    },
    {
        "label": "CondConv2d",
        "kind": 6,
        "importPath": "timm.models.layers.cond_conv2d",
        "description": "timm.models.layers.cond_conv2d",
        "peekOfCode": "class CondConv2d(nn.Module):\n    \"\"\" Conditionally Parameterized Convolution\n    Inspired by: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/condconv/condconv_layers.py\n    Grouped convolution hackery for parallel execution of the per-sample kernel filters inspired by this discussion:\n    https://github.com/pytorch/pytorch/issues/17983\n    \"\"\"\n    __constants__ = ['in_channels', 'out_channels', 'dynamic_padding']\n    def __init__(self, in_channels, out_channels, kernel_size=3,\n                 stride=1, padding='', dilation=1, groups=1, bias=False, num_experts=4):\n        super(CondConv2d, self).__init__()",
        "detail": "timm.models.layers.cond_conv2d",
        "documentation": {}
    },
    {
        "label": "get_condconv_initializer",
        "kind": 2,
        "importPath": "timm.models.layers.cond_conv2d",
        "description": "timm.models.layers.cond_conv2d",
        "peekOfCode": "def get_condconv_initializer(initializer, num_experts, expert_shape):\n    def condconv_initializer(weight):\n        \"\"\"CondConv initializer function.\"\"\"\n        num_params = np.prod(expert_shape)\n        if (len(weight.shape) != 2 or weight.shape[0] != num_experts or\n                weight.shape[1] != num_params):\n            raise (ValueError(\n                'CondConv variables must have shape [num_experts, num_params]'))\n        for i in range(num_experts):\n            initializer(weight[i].view(expert_shape))",
        "detail": "timm.models.layers.cond_conv2d",
        "documentation": {}
    },
    {
        "label": "set_no_jit",
        "kind": 6,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "class set_no_jit:\n    def __init__(self, mode: bool) -> None:\n        global _NO_JIT\n        self.prev = _NO_JIT\n        _NO_JIT = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:\n        global _NO_JIT\n        _NO_JIT = self.prev",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "set_exportable",
        "kind": 6,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "class set_exportable:\n    def __init__(self, mode: bool) -> None:\n        global _EXPORTABLE\n        self.prev = _EXPORTABLE\n        _EXPORTABLE = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:\n        global _EXPORTABLE\n        _EXPORTABLE = self.prev",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "set_scriptable",
        "kind": 6,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "class set_scriptable:\n    def __init__(self, mode: bool) -> None:\n        global _SCRIPTABLE\n        self.prev = _SCRIPTABLE\n        _SCRIPTABLE = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:\n        global _SCRIPTABLE\n        _SCRIPTABLE = self.prev",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "set_layer_config",
        "kind": 6,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "class set_layer_config:\n    \"\"\" Layer config context manager that allows setting all layer config flags at once.\n    If a flag arg is None, it will not change the current value.\n    \"\"\"\n    def __init__(\n            self,\n            scriptable: Optional[bool] = None,\n            exportable: Optional[bool] = None,\n            no_jit: Optional[bool] = None,\n            no_activation_jit: Optional[bool] = None):",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "is_no_jit",
        "kind": 2,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "def is_no_jit():\n    return _NO_JIT\nclass set_no_jit:\n    def __init__(self, mode: bool) -> None:\n        global _NO_JIT\n        self.prev = _NO_JIT\n        _NO_JIT = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "is_exportable",
        "kind": 2,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "def is_exportable():\n    return _EXPORTABLE\nclass set_exportable:\n    def __init__(self, mode: bool) -> None:\n        global _EXPORTABLE\n        self.prev = _EXPORTABLE\n        _EXPORTABLE = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "is_scriptable",
        "kind": 2,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "def is_scriptable():\n    return _SCRIPTABLE\nclass set_scriptable:\n    def __init__(self, mode: bool) -> None:\n        global _SCRIPTABLE\n        self.prev = _SCRIPTABLE\n        _SCRIPTABLE = mode\n    def __enter__(self) -> None:\n        pass\n    def __exit__(self, *args: Any) -> bool:",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "__all__ = [\n    'is_exportable', 'is_scriptable', 'is_no_jit',\n    'set_exportable', 'set_scriptable', 'set_no_jit', 'set_layer_config'\n]\n# Set to True if prefer to have layers with no jit optimization (includes activations)\n_NO_JIT = False\n# Set to True if prefer to have activation layers with no jit optimization\n# NOTE not currently used as no difference between no_jit and no_activation jit as only layers obeying\n# the jit flags so far are activations. This will change as more layers are updated and/or added.\n_NO_ACTIVATION_JIT = False",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "_NO_JIT",
        "kind": 5,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "_NO_JIT = False\n# Set to True if prefer to have activation layers with no jit optimization\n# NOTE not currently used as no difference between no_jit and no_activation jit as only layers obeying\n# the jit flags so far are activations. This will change as more layers are updated and/or added.\n_NO_ACTIVATION_JIT = False\n# Set to True if exporting a model with Same padding via ONNX\n_EXPORTABLE = False\n# Set to True if wanting to use torch.jit.script on a model\n_SCRIPTABLE = False\ndef is_no_jit():",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "_NO_ACTIVATION_JIT",
        "kind": 5,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "_NO_ACTIVATION_JIT = False\n# Set to True if exporting a model with Same padding via ONNX\n_EXPORTABLE = False\n# Set to True if wanting to use torch.jit.script on a model\n_SCRIPTABLE = False\ndef is_no_jit():\n    return _NO_JIT\nclass set_no_jit:\n    def __init__(self, mode: bool) -> None:\n        global _NO_JIT",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "_EXPORTABLE",
        "kind": 5,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "_EXPORTABLE = False\n# Set to True if wanting to use torch.jit.script on a model\n_SCRIPTABLE = False\ndef is_no_jit():\n    return _NO_JIT\nclass set_no_jit:\n    def __init__(self, mode: bool) -> None:\n        global _NO_JIT\n        self.prev = _NO_JIT\n        _NO_JIT = mode",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "_SCRIPTABLE",
        "kind": 5,
        "importPath": "timm.models.layers.config",
        "description": "timm.models.layers.config",
        "peekOfCode": "_SCRIPTABLE = False\ndef is_no_jit():\n    return _NO_JIT\nclass set_no_jit:\n    def __init__(self, mode: bool) -> None:\n        global _NO_JIT\n        self.prev = _NO_JIT\n        _NO_JIT = mode\n    def __enter__(self) -> None:\n        pass",
        "detail": "timm.models.layers.config",
        "documentation": {}
    },
    {
        "label": "Conv2dSame",
        "kind": 6,
        "importPath": "timm.models.layers.conv2d_same",
        "description": "timm.models.layers.conv2d_same",
        "peekOfCode": "class Conv2dSame(nn.Conv2d):\n    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, bias=True):\n        super(Conv2dSame, self).__init__(\n            in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n    def forward(self, x):\n        return conv2d_same(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\ndef create_conv2d_pad(in_chs, out_chs, kernel_size, **kwargs):",
        "detail": "timm.models.layers.conv2d_same",
        "documentation": {}
    },
    {
        "label": "conv2d_same",
        "kind": 2,
        "importPath": "timm.models.layers.conv2d_same",
        "description": "timm.models.layers.conv2d_same",
        "peekOfCode": "def conv2d_same(\n        x, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, stride: Tuple[int, int] = (1, 1),\n        padding: Tuple[int, int] = (0, 0), dilation: Tuple[int, int] = (1, 1), groups: int = 1):\n    x = pad_same(x, weight.shape[-2:], stride, dilation)\n    return F.conv2d(x, weight, bias, stride, (0, 0), dilation, groups)\nclass Conv2dSame(nn.Conv2d):\n    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, bias=True):",
        "detail": "timm.models.layers.conv2d_same",
        "documentation": {}
    },
    {
        "label": "create_conv2d_pad",
        "kind": 2,
        "importPath": "timm.models.layers.conv2d_same",
        "description": "timm.models.layers.conv2d_same",
        "peekOfCode": "def create_conv2d_pad(in_chs, out_chs, kernel_size, **kwargs):\n    padding = kwargs.pop('padding', '')\n    kwargs.setdefault('bias', False)\n    padding, is_dynamic = get_padding_value(padding, kernel_size, **kwargs)\n    if is_dynamic:\n        return Conv2dSame(in_chs, out_chs, kernel_size, **kwargs)\n    else:\n        return nn.Conv2d(in_chs, out_chs, kernel_size, padding=padding, **kwargs)",
        "detail": "timm.models.layers.conv2d_same",
        "documentation": {}
    },
    {
        "label": "ConvBnAct",
        "kind": 6,
        "importPath": "timm.models.layers.conv_bn_act",
        "description": "timm.models.layers.conv_bn_act",
        "peekOfCode": "class ConvBnAct(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding='', dilation=1, groups=1,\n                 bias=False, apply_act=True, norm_layer=nn.BatchNorm2d, act_layer=nn.ReLU, aa_layer=None,\n                 drop_block=None):\n        super(ConvBnAct, self).__init__()\n        use_aa = aa_layer is not None\n        self.conv = create_conv2d(\n            in_channels, out_channels, kernel_size, stride=1 if use_aa else stride,\n            padding=padding, dilation=dilation, groups=groups, bias=bias)\n        # NOTE for backwards compatibility with models that use separate norm and act layer definitions",
        "detail": "timm.models.layers.conv_bn_act",
        "documentation": {}
    },
    {
        "label": "get_act_fn",
        "kind": 2,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "def get_act_fn(name: Union[Callable, str] = 'relu'):\n    \"\"\" Activation Function Factory\n    Fetching activation fns by name with this function allows export or torch script friendly\n    functions to be returned dynamically based on current config.\n    \"\"\"\n    if not name:\n        return None\n    if isinstance(name, Callable):\n        return name\n    if not (is_no_jit() or is_exportable() or is_scriptable()):",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "get_act_layer",
        "kind": 2,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "def get_act_layer(name: Union[Type[nn.Module], str] = 'relu'):\n    \"\"\" Activation Layer Factory\n    Fetching activation layers by name with this function allows export or torch script friendly\n    functions to be returned dynamically based on current config.\n    \"\"\"\n    if not name:\n        return None\n    if isinstance(name, type):\n        return name\n    if not (is_no_jit() or is_exportable() or is_scriptable()):",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "create_act_layer",
        "kind": 2,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "def create_act_layer(name: Union[nn.Module, str], inplace=None, **kwargs):\n    act_layer = get_act_layer(name)\n    if act_layer is None:\n        return None\n    return act_layer(**kwargs) if inplace is None else act_layer(inplace=inplace, **kwargs)",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_has_silu",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_has_silu = 'silu' in dir(torch.nn.functional)\n_has_hardswish = 'hardswish' in dir(torch.nn.functional)\n_has_hardsigmoid = 'hardsigmoid' in dir(torch.nn.functional)\n_has_mish = 'mish' in dir(torch.nn.functional)\n_ACT_FN_DEFAULT = dict(\n    silu=F.silu if _has_silu else swish,\n    swish=F.silu if _has_silu else swish,\n    mish=F.mish if _has_mish else mish,\n    relu=F.relu,\n    relu6=F.relu6,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_has_hardswish",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_has_hardswish = 'hardswish' in dir(torch.nn.functional)\n_has_hardsigmoid = 'hardsigmoid' in dir(torch.nn.functional)\n_has_mish = 'mish' in dir(torch.nn.functional)\n_ACT_FN_DEFAULT = dict(\n    silu=F.silu if _has_silu else swish,\n    swish=F.silu if _has_silu else swish,\n    mish=F.mish if _has_mish else mish,\n    relu=F.relu,\n    relu6=F.relu6,\n    leaky_relu=F.leaky_relu,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_has_hardsigmoid",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_has_hardsigmoid = 'hardsigmoid' in dir(torch.nn.functional)\n_has_mish = 'mish' in dir(torch.nn.functional)\n_ACT_FN_DEFAULT = dict(\n    silu=F.silu if _has_silu else swish,\n    swish=F.silu if _has_silu else swish,\n    mish=F.mish if _has_mish else mish,\n    relu=F.relu,\n    relu6=F.relu6,\n    leaky_relu=F.leaky_relu,\n    elu=F.elu,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_has_mish",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_has_mish = 'mish' in dir(torch.nn.functional)\n_ACT_FN_DEFAULT = dict(\n    silu=F.silu if _has_silu else swish,\n    swish=F.silu if _has_silu else swish,\n    mish=F.mish if _has_mish else mish,\n    relu=F.relu,\n    relu6=F.relu6,\n    leaky_relu=F.leaky_relu,\n    elu=F.elu,\n    celu=F.celu,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_FN_DEFAULT",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_FN_DEFAULT = dict(\n    silu=F.silu if _has_silu else swish,\n    swish=F.silu if _has_silu else swish,\n    mish=F.mish if _has_mish else mish,\n    relu=F.relu,\n    relu6=F.relu6,\n    leaky_relu=F.leaky_relu,\n    elu=F.elu,\n    celu=F.celu,\n    selu=F.selu,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_FN_JIT",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_FN_JIT = dict(\n    silu=F.silu if _has_silu else swish_jit,\n    swish=F.silu if _has_silu else swish_jit,\n    mish=F.mish if _has_mish else mish_jit,\n    hard_sigmoid=F.hardsigmoid if _has_hardsigmoid else hard_sigmoid_jit,\n    hard_swish=F.hardswish if _has_hardswish else hard_swish_jit,\n    hard_mish=hard_mish_jit\n)\n_ACT_FN_ME = dict(\n    silu=F.silu if _has_silu else swish_me,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_FN_ME",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_FN_ME = dict(\n    silu=F.silu if _has_silu else swish_me,\n    swish=F.silu if _has_silu else swish_me,\n    mish=F.mish if _has_mish else mish_me,\n    hard_sigmoid=F.hardsigmoid if _has_hardsigmoid else hard_sigmoid_me,\n    hard_swish=F.hardswish if _has_hardswish else hard_swish_me,\n    hard_mish=hard_mish_me,\n)\n_ACT_FNS = (_ACT_FN_ME, _ACT_FN_JIT, _ACT_FN_DEFAULT)\nfor a in _ACT_FNS:",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_FNS",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_FNS = (_ACT_FN_ME, _ACT_FN_JIT, _ACT_FN_DEFAULT)\nfor a in _ACT_FNS:\n    a.setdefault('hardsigmoid', a.get('hard_sigmoid'))\n    a.setdefault('hardswish', a.get('hard_swish'))\n_ACT_LAYER_DEFAULT = dict(\n    silu=nn.SiLU if _has_silu else Swish,\n    swish=nn.SiLU if _has_silu else Swish,\n    mish=nn.Mish if _has_mish else Mish,\n    relu=nn.ReLU,\n    relu6=nn.ReLU6,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_LAYER_DEFAULT",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_LAYER_DEFAULT = dict(\n    silu=nn.SiLU if _has_silu else Swish,\n    swish=nn.SiLU if _has_silu else Swish,\n    mish=nn.Mish if _has_mish else Mish,\n    relu=nn.ReLU,\n    relu6=nn.ReLU6,\n    leaky_relu=nn.LeakyReLU,\n    elu=nn.ELU,\n    prelu=PReLU,\n    celu=nn.CELU,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_LAYER_JIT",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_LAYER_JIT = dict(\n    silu=nn.SiLU if _has_silu else SwishJit,\n    swish=nn.SiLU if _has_silu else SwishJit,\n    mish=nn.Mish if _has_mish else MishJit,\n    hard_sigmoid=nn.Hardsigmoid if _has_hardsigmoid else HardSigmoidJit,\n    hard_swish=nn.Hardswish if _has_hardswish else HardSwishJit,\n    hard_mish=HardMishJit\n)\n_ACT_LAYER_ME = dict(\n    silu=nn.SiLU if _has_silu else SwishMe,",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_LAYER_ME",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_LAYER_ME = dict(\n    silu=nn.SiLU if _has_silu else SwishMe,\n    swish=nn.SiLU if _has_silu else SwishMe,\n    mish=nn.Mish if _has_mish else MishMe,\n    hard_sigmoid=nn.Hardsigmoid if _has_hardsigmoid else HardSigmoidMe,\n    hard_swish=nn.Hardswish if _has_hardswish else HardSwishMe,\n    hard_mish=HardMishMe,\n)\n_ACT_LAYERS = (_ACT_LAYER_ME, _ACT_LAYER_JIT, _ACT_LAYER_DEFAULT)\nfor a in _ACT_LAYERS:",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "_ACT_LAYERS",
        "kind": 5,
        "importPath": "timm.models.layers.create_act",
        "description": "timm.models.layers.create_act",
        "peekOfCode": "_ACT_LAYERS = (_ACT_LAYER_ME, _ACT_LAYER_JIT, _ACT_LAYER_DEFAULT)\nfor a in _ACT_LAYERS:\n    a.setdefault('hardsigmoid', a.get('hard_sigmoid'))\n    a.setdefault('hardswish', a.get('hard_swish'))\ndef get_act_fn(name: Union[Callable, str] = 'relu'):\n    \"\"\" Activation Function Factory\n    Fetching activation fns by name with this function allows export or torch script friendly\n    functions to be returned dynamically based on current config.\n    \"\"\"\n    if not name:",
        "detail": "timm.models.layers.create_act",
        "documentation": {}
    },
    {
        "label": "get_attn",
        "kind": 2,
        "importPath": "timm.models.layers.create_attn",
        "description": "timm.models.layers.create_attn",
        "peekOfCode": "def get_attn(attn_type):\n    if isinstance(attn_type, torch.nn.Module):\n        return attn_type\n    module_cls = None\n    if attn_type is not None:\n        if isinstance(attn_type, str):\n            attn_type = attn_type.lower()\n            # Lightweight attention modules (channel and/or coarse spatial).\n            # Typically added to existing network architecture blocks in addition to existing convolutions.\n            if attn_type == 'se':",
        "detail": "timm.models.layers.create_attn",
        "documentation": {}
    },
    {
        "label": "create_attn",
        "kind": 2,
        "importPath": "timm.models.layers.create_attn",
        "description": "timm.models.layers.create_attn",
        "peekOfCode": "def create_attn(attn_type, channels, **kwargs):\n    module_cls = get_attn(attn_type)\n    if module_cls is not None:\n        # NOTE: it's expected the first (positional) argument of all attention layers is the # input channels\n        return module_cls(channels, **kwargs)\n    return None",
        "detail": "timm.models.layers.create_attn",
        "documentation": {}
    },
    {
        "label": "create_conv2d",
        "kind": 2,
        "importPath": "timm.models.layers.create_conv2d",
        "description": "timm.models.layers.create_conv2d",
        "peekOfCode": "def create_conv2d(in_channels, out_channels, kernel_size, **kwargs):\n    \"\"\" Select a 2d convolution implementation based on arguments\n    Creates and returns one of torch.nn.Conv2d, Conv2dSame, MixedConv2d, or CondConv2d.\n    Used extensively by EfficientNet, MobileNetv3 and related networks.\n    \"\"\"\n    if isinstance(kernel_size, list):\n        assert 'num_experts' not in kwargs  # MixNet + CondConv combo not supported currently\n        assert 'groups' not in kwargs  # MixedConv groups are defined by kernel list\n        # We're going to use only lists for defining the MixedConv2d kernel groups,\n        # ints, tuples, other iterables will continue to pass to normal conv and specify h, w.",
        "detail": "timm.models.layers.create_conv2d",
        "documentation": {}
    },
    {
        "label": "get_norm_act_layer",
        "kind": 2,
        "importPath": "timm.models.layers.create_norm_act",
        "description": "timm.models.layers.create_norm_act",
        "peekOfCode": "def get_norm_act_layer(layer_class):\n    layer_class = layer_class.replace('_', '').lower()\n    if layer_class.startswith(\"batchnorm\"):\n        layer = BatchNormAct2d\n    elif layer_class.startswith(\"groupnorm\"):\n        layer = GroupNormAct\n    elif layer_class == \"evonormbatch\":\n        layer = EvoNormBatch2d\n    elif layer_class == \"evonormsample\":\n        layer = EvoNormSample2d",
        "detail": "timm.models.layers.create_norm_act",
        "documentation": {}
    },
    {
        "label": "create_norm_act",
        "kind": 2,
        "importPath": "timm.models.layers.create_norm_act",
        "description": "timm.models.layers.create_norm_act",
        "peekOfCode": "def create_norm_act(layer_type, num_features, apply_act=True, jit=False, **kwargs):\n    layer_parts = layer_type.split('-')  # e.g. batchnorm-leaky_relu\n    assert len(layer_parts) in (1, 2)\n    layer = get_norm_act_layer(layer_parts[0])\n    #activation_class = layer_parts[1].lower() if len(layer_parts) > 1 else ''   # FIXME support string act selection?\n    layer_instance = layer(num_features, apply_act=apply_act, **kwargs)\n    if jit:\n        layer_instance = torch.jit.script(layer_instance)\n    return layer_instance\ndef convert_norm_act(norm_layer, act_layer):",
        "detail": "timm.models.layers.create_norm_act",
        "documentation": {}
    },
    {
        "label": "convert_norm_act",
        "kind": 2,
        "importPath": "timm.models.layers.create_norm_act",
        "description": "timm.models.layers.create_norm_act",
        "peekOfCode": "def convert_norm_act(norm_layer, act_layer):\n    assert isinstance(norm_layer, (type, str,  types.FunctionType, functools.partial))\n    assert act_layer is None or isinstance(act_layer, (type, str, types.FunctionType, functools.partial))\n    norm_act_kwargs = {}\n    # unbind partial fn, so args can be rebound later\n    if isinstance(norm_layer, functools.partial):\n        norm_act_kwargs.update(norm_layer.keywords)\n        norm_layer = norm_layer.func\n    if isinstance(norm_layer, str):\n        norm_act_layer = get_norm_act_layer(norm_layer)",
        "detail": "timm.models.layers.create_norm_act",
        "documentation": {}
    },
    {
        "label": "_NORM_ACT_TYPES",
        "kind": 5,
        "importPath": "timm.models.layers.create_norm_act",
        "description": "timm.models.layers.create_norm_act",
        "peekOfCode": "_NORM_ACT_TYPES = {BatchNormAct2d, GroupNormAct, EvoNormBatch2d, EvoNormSample2d, InplaceAbn}\n_NORM_ACT_REQUIRES_ARG = {BatchNormAct2d, GroupNormAct, InplaceAbn}  # requires act_layer arg to define act type\ndef get_norm_act_layer(layer_class):\n    layer_class = layer_class.replace('_', '').lower()\n    if layer_class.startswith(\"batchnorm\"):\n        layer = BatchNormAct2d\n    elif layer_class.startswith(\"groupnorm\"):\n        layer = GroupNormAct\n    elif layer_class == \"evonormbatch\":\n        layer = EvoNormBatch2d",
        "detail": "timm.models.layers.create_norm_act",
        "documentation": {}
    },
    {
        "label": "_NORM_ACT_REQUIRES_ARG",
        "kind": 5,
        "importPath": "timm.models.layers.create_norm_act",
        "description": "timm.models.layers.create_norm_act",
        "peekOfCode": "_NORM_ACT_REQUIRES_ARG = {BatchNormAct2d, GroupNormAct, InplaceAbn}  # requires act_layer arg to define act type\ndef get_norm_act_layer(layer_class):\n    layer_class = layer_class.replace('_', '').lower()\n    if layer_class.startswith(\"batchnorm\"):\n        layer = BatchNormAct2d\n    elif layer_class.startswith(\"groupnorm\"):\n        layer = GroupNormAct\n    elif layer_class == \"evonormbatch\":\n        layer = EvoNormBatch2d\n    elif layer_class == \"evonormsample\":",
        "detail": "timm.models.layers.create_norm_act",
        "documentation": {}
    },
    {
        "label": "DropBlock2d",
        "kind": 6,
        "importPath": "timm.models.layers.drop",
        "description": "timm.models.layers.drop",
        "peekOfCode": "class DropBlock2d(nn.Module):\n    \"\"\" DropBlock. See https://arxiv.org/pdf/1810.12890.pdf\n    \"\"\"\n    def __init__(self,\n                 drop_prob=0.1,\n                 block_size=7,\n                 gamma_scale=1.0,\n                 with_noise=False,\n                 inplace=False,\n                 batchwise=False,",
        "detail": "timm.models.layers.drop",
        "documentation": {}
    },
    {
        "label": "DropPath",
        "kind": 6,
        "importPath": "timm.models.layers.drop",
        "description": "timm.models.layers.drop",
        "peekOfCode": "class DropPath(nn.Module):\n    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n    \"\"\"\n    def __init__(self, drop_prob=None, scale_by_keep=True):\n        super(DropPath, self).__init__()\n        self.drop_prob = drop_prob\n        self.scale_by_keep = scale_by_keep\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)",
        "detail": "timm.models.layers.drop",
        "documentation": {}
    },
    {
        "label": "drop_block_2d",
        "kind": 2,
        "importPath": "timm.models.layers.drop",
        "description": "timm.models.layers.drop",
        "peekOfCode": "def drop_block_2d(\n        x, drop_prob: float = 0.1, block_size: int = 7,  gamma_scale: float = 1.0,\n        with_noise: bool = False, inplace: bool = False, batchwise: bool = False):\n    \"\"\" DropBlock. See https://arxiv.org/pdf/1810.12890.pdf\n    DropBlock with an experimental gaussian noise option. This layer has been tested on a few training\n    runs with success, but needs further validation and possibly optimization for lower runtime impact.\n    \"\"\"\n    B, C, H, W = x.shape\n    total_size = W * H\n    clipped_block_size = min(block_size, min(W, H))",
        "detail": "timm.models.layers.drop",
        "documentation": {}
    },
    {
        "label": "drop_block_fast_2d",
        "kind": 2,
        "importPath": "timm.models.layers.drop",
        "description": "timm.models.layers.drop",
        "peekOfCode": "def drop_block_fast_2d(\n        x: torch.Tensor, drop_prob: float = 0.1, block_size: int = 7,\n        gamma_scale: float = 1.0, with_noise: bool = False, inplace: bool = False):\n    \"\"\" DropBlock. See https://arxiv.org/pdf/1810.12890.pdf\n    DropBlock with an experimental gaussian noise option. Simplied from above without concern for valid\n    block mask at edges.\n    \"\"\"\n    B, C, H, W = x.shape\n    total_size = W * H\n    clipped_block_size = min(block_size, min(W, H))",
        "detail": "timm.models.layers.drop",
        "documentation": {}
    },
    {
        "label": "drop_path",
        "kind": 2,
        "importPath": "timm.models.layers.drop",
        "description": "timm.models.layers.drop",
        "peekOfCode": "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n    'survival rate' as the argument.\n    \"\"\"\n    if drop_prob == 0. or not training:\n        return x",
        "detail": "timm.models.layers.drop",
        "documentation": {}
    },
    {
        "label": "EcaModule",
        "kind": 6,
        "importPath": "timm.models.layers.eca",
        "description": "timm.models.layers.eca",
        "peekOfCode": "class EcaModule(nn.Module):\n    \"\"\"Constructs an ECA module.\n    Args:\n        channels: Number of channels of the input feature map for use in adaptive kernel sizes\n            for actual calculations according to channel.\n            gamma, beta: when channel is given parameters of mapping function\n            refer to original paper https://arxiv.org/pdf/1910.03151.pdf\n            (default=None. if channel size not given, use k_size given for kernel size.)\n        kernel_size: Adaptive selection of kernel size (default=3)\n        gamm: used in kernel_size calc, see above",
        "detail": "timm.models.layers.eca",
        "documentation": {}
    },
    {
        "label": "CecaModule",
        "kind": 6,
        "importPath": "timm.models.layers.eca",
        "description": "timm.models.layers.eca",
        "peekOfCode": "class CecaModule(nn.Module):\n    \"\"\"Constructs a circular ECA module.\n    ECA module where the conv uses circular padding rather than zero padding.\n    Unlike the spatial dimension, the channels do not have inherent ordering nor\n    locality. Although this module in essence, applies such an assumption, it is unnecessary\n    to limit the channels on either \"edge\" from being circularly adapted to each other.\n    This will fundamentally increase connectivity and possibly increase performance metrics\n    (accuracy, robustness), without significantly impacting resource metrics\n    (parameter size, throughput,latency, etc)\n    Args:",
        "detail": "timm.models.layers.eca",
        "documentation": {}
    },
    {
        "label": "EfficientChannelAttn",
        "kind": 5,
        "importPath": "timm.models.layers.eca",
        "description": "timm.models.layers.eca",
        "peekOfCode": "EfficientChannelAttn = EcaModule  # alias\nclass CecaModule(nn.Module):\n    \"\"\"Constructs a circular ECA module.\n    ECA module where the conv uses circular padding rather than zero padding.\n    Unlike the spatial dimension, the channels do not have inherent ordering nor\n    locality. Although this module in essence, applies such an assumption, it is unnecessary\n    to limit the channels on either \"edge\" from being circularly adapted to each other.\n    This will fundamentally increase connectivity and possibly increase performance metrics\n    (accuracy, robustness), without significantly impacting resource metrics\n    (parameter size, throughput,latency, etc)",
        "detail": "timm.models.layers.eca",
        "documentation": {}
    },
    {
        "label": "CircularEfficientChannelAttn",
        "kind": 5,
        "importPath": "timm.models.layers.eca",
        "description": "timm.models.layers.eca",
        "peekOfCode": "CircularEfficientChannelAttn = CecaModule",
        "detail": "timm.models.layers.eca",
        "documentation": {}
    },
    {
        "label": "EvoNormBatch2d",
        "kind": 6,
        "importPath": "timm.models.layers.evo_norm",
        "description": "timm.models.layers.evo_norm",
        "peekOfCode": "class EvoNormBatch2d(nn.Module):\n    def __init__(self, num_features, apply_act=True, momentum=0.1, eps=1e-5, drop_block=None):\n        super(EvoNormBatch2d, self).__init__()\n        self.apply_act = apply_act  # apply activation (non-linearity)\n        self.momentum = momentum\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(num_features), requires_grad=True)\n        self.bias = nn.Parameter(torch.zeros(num_features), requires_grad=True)\n        self.v = nn.Parameter(torch.ones(num_features), requires_grad=True) if apply_act else None\n        self.register_buffer('running_var', torch.ones(num_features))",
        "detail": "timm.models.layers.evo_norm",
        "documentation": {}
    },
    {
        "label": "EvoNormSample2d",
        "kind": 6,
        "importPath": "timm.models.layers.evo_norm",
        "description": "timm.models.layers.evo_norm",
        "peekOfCode": "class EvoNormSample2d(nn.Module):\n    def __init__(self, num_features, apply_act=True, groups=32, eps=1e-5, drop_block=None):\n        super(EvoNormSample2d, self).__init__()\n        self.apply_act = apply_act  # apply activation (non-linearity)\n        self.groups = groups\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(num_features), requires_grad=True)\n        self.bias = nn.Parameter(torch.zeros(num_features), requires_grad=True)\n        self.v = nn.Parameter(torch.ones(num_features), requires_grad=True) if apply_act else None\n        self.reset_parameters()",
        "detail": "timm.models.layers.evo_norm",
        "documentation": {}
    },
    {
        "label": "GatherExcite",
        "kind": 6,
        "importPath": "timm.models.layers.gather_excite",
        "description": "timm.models.layers.gather_excite",
        "peekOfCode": "class GatherExcite(nn.Module):\n    \"\"\" Gather-Excite Attention Module\n    \"\"\"\n    def __init__(\n            self, channels, feat_size=None, extra_params=False, extent=0, use_mlp=True,\n            rd_ratio=1./16, rd_channels=None,  rd_divisor=1, add_maxpool=False,\n            act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, gate_layer='sigmoid'):\n        super(GatherExcite, self).__init__()\n        self.add_maxpool = add_maxpool\n        act_layer = get_act_layer(act_layer)",
        "detail": "timm.models.layers.gather_excite",
        "documentation": {}
    },
    {
        "label": "GlobalContext",
        "kind": 6,
        "importPath": "timm.models.layers.global_context",
        "description": "timm.models.layers.global_context",
        "peekOfCode": "class GlobalContext(nn.Module):\n    def __init__(self, channels, use_attn=True, fuse_add=False, fuse_scale=True, init_last_zero=False,\n                 rd_ratio=1./8, rd_channels=None, rd_divisor=1, act_layer=nn.ReLU, gate_layer='sigmoid'):\n        super(GlobalContext, self).__init__()\n        act_layer = get_act_layer(act_layer)\n        self.conv_attn = nn.Conv2d(channels, 1, kernel_size=1, bias=True) if use_attn else None\n        if rd_channels is None:\n            rd_channels = make_divisible(channels * rd_ratio, rd_divisor, round_limit=0.)\n        if fuse_add:\n            self.mlp_add = ConvMlp(channels, rd_channels, act_layer=act_layer, norm_layer=LayerNorm2d)",
        "detail": "timm.models.layers.global_context",
        "documentation": {}
    },
    {
        "label": "PosEmbedRel",
        "kind": 6,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "class PosEmbedRel(nn.Module):\n    \"\"\" Relative Position Embedding\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n    \"\"\"\n    def __init__(self, block_size, win_size, dim_head, scale):\n        \"\"\"\n        Args:\n            block_size (int): block size\n            win_size (int): neighbourhood window size",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "HaloAttn",
        "kind": 6,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "class HaloAttn(nn.Module):\n    \"\"\" Halo Attention\n    Paper: `Scaling Local Self-Attention for Parameter Efficient Visual Backbones`\n        - https://arxiv.org/abs/2103.12731\n    The internal dimensions of the attention module are controlled by the interaction of several arguments.\n      * the output dimension of the module is specified by dim_out, which falls back to input dim if not set\n      * the value (v) dimension is set to dim_out // num_heads, the v projection determines the output dim\n      * the query and key (qk) dimensions are determined by\n        * num_heads * dim_head if dim_head is not None\n        * num_heads * (dim_out * attn_ratio // num_heads) if dim_head is None",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "rel_logits_1d",
        "kind": 2,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "def rel_logits_1d(q, rel_k, permute_mask: List[int]):\n    \"\"\" Compute relative logits along one dimension\n    As per: https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\n    Originally from: `Attention Augmented Convolutional Networks` - https://arxiv.org/abs/1904.09925\n    Args:\n        q: (batch, height, width, dim)\n        rel_k: (2 * window - 1, dim)\n        permute_mask: permute output dim according to this\n    \"\"\"\n    B, H, W, dim = q.shape",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "Author",
        "kind": 5,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "Author = {Ashish Vaswani and Prajit Ramachandran and Aravind Srinivas and Niki Parmar and Blake Hechtman and\n    Jonathon Shlens},\nTitle = {Scaling Local Self-Attention for Parameter Efficient Visual Backbones},\nYear = {2021},\n}\nStatus:\nThis impl is a WIP, there is no official ref impl and some details in paper weren't clear to me.\nThe attention mechanism works but it's slow as implemented.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "Title",
        "kind": 5,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "Title = {Scaling Local Self-Attention for Parameter Efficient Visual Backbones},\nYear = {2021},\n}\nStatus:\nThis impl is a WIP, there is no official ref impl and some details in paper weren't clear to me.\nThe attention mechanism works but it's slow as implemented.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"\nfrom typing import List\nimport torch",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "Year",
        "kind": 5,
        "importPath": "timm.models.layers.halo_attn",
        "description": "timm.models.layers.halo_attn",
        "peekOfCode": "Year = {2021},\n}\nStatus:\nThis impl is a WIP, there is no official ref impl and some details in paper weren't clear to me.\nThe attention mechanism works but it's slow as implemented.\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"\nfrom typing import List\nimport torch\nfrom torch import nn",
        "detail": "timm.models.layers.halo_attn",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "def make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:\n        new_v += divisor\n    return new_v",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "to_1tuple",
        "kind": 5,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "to_1tuple = _ntuple(1)\nto_2tuple = _ntuple(2)\nto_3tuple = _ntuple(3)\nto_4tuple = _ntuple(4)\nto_ntuple = _ntuple\ndef make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "kind": 5,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "to_2tuple = _ntuple(2)\nto_3tuple = _ntuple(3)\nto_4tuple = _ntuple(4)\nto_ntuple = _ntuple\ndef make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:\n        new_v += divisor",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "to_3tuple",
        "kind": 5,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "to_3tuple = _ntuple(3)\nto_4tuple = _ntuple(4)\nto_ntuple = _ntuple\ndef make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:\n        new_v += divisor\n    return new_v",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "to_4tuple",
        "kind": 5,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "to_4tuple = _ntuple(4)\nto_ntuple = _ntuple\ndef make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:\n        new_v += divisor\n    return new_v",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "to_ntuple",
        "kind": 5,
        "importPath": "timm.models.layers.helpers",
        "description": "timm.models.layers.helpers",
        "peekOfCode": "to_ntuple = _ntuple\ndef make_divisible(v, divisor=8, min_value=None, round_limit=.9):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < round_limit * v:\n        new_v += divisor\n    return new_v",
        "detail": "timm.models.layers.helpers",
        "documentation": {}
    },
    {
        "label": "InplaceAbn",
        "kind": 6,
        "importPath": "timm.models.layers.inplace_abn",
        "description": "timm.models.layers.inplace_abn",
        "peekOfCode": "class InplaceAbn(nn.Module):\n    \"\"\"Activated Batch Normalization\n    This gathers a BatchNorm and an activation function in a single module\n    Parameters\n    ----------\n    num_features : int\n        Number of feature channels in the input and output.\n    eps : float\n        Small constant to prevent numerical issues.\n    momentum : float",
        "detail": "timm.models.layers.inplace_abn",
        "documentation": {}
    },
    {
        "label": "LambdaLayer",
        "kind": 6,
        "importPath": "timm.models.layers.lambda_layer",
        "description": "timm.models.layers.lambda_layer",
        "peekOfCode": "class LambdaLayer(nn.Module):\n    \"\"\"Lambda Layer\n    Paper: `LambdaNetworks: Modeling Long-Range Interactions Without Attention`\n        - https://arxiv.org/abs/2102.08602\n    NOTE: intra-depth parameter 'u' is fixed at 1. It did not appear worth the complexity to add.\n    The internal dimensions of the lambda module are controlled via the interaction of several arguments.\n      * the output dimension of the module is specified by dim_out, which falls back to input dim if not set\n      * the value (v) dimension is set to dim_out // num_heads, the v projection determines the output dim\n      * the query (q) and key (k) dimension are determined by\n        * dim_head = (dim_out * attn_ratio // num_heads) if dim_head is None",
        "detail": "timm.models.layers.lambda_layer",
        "documentation": {}
    },
    {
        "label": "rel_pos_indices",
        "kind": 2,
        "importPath": "timm.models.layers.lambda_layer",
        "description": "timm.models.layers.lambda_layer",
        "peekOfCode": "def rel_pos_indices(size):\n    size = to_2tuple(size)\n    pos = torch.stack(torch.meshgrid(torch.arange(size[0]), torch.arange(size[1]))).flatten(1)\n    rel_pos = pos[:, None, :] - pos[:, :, None]\n    rel_pos[0] += size[0] - 1\n    rel_pos[1] += size[1] - 1\n    return rel_pos  # 2, H * W, H * W\nclass LambdaLayer(nn.Module):\n    \"\"\"Lambda Layer\n    Paper: `LambdaNetworks: Modeling Long-Range Interactions Without Attention`",
        "detail": "timm.models.layers.lambda_layer",
        "documentation": {}
    },
    {
        "label": "Author",
        "kind": 5,
        "importPath": "timm.models.layers.lambda_layer",
        "description": "timm.models.layers.lambda_layer",
        "peekOfCode": "Author = {Irwan Bello},\nTitle = {LambdaNetworks: Modeling Long-Range Interactions Without Attention},\nYear = {2021},\n}\nStatus:\nThis impl is a WIP. Code snippets in the paper were used as reference but\ngood chance some details are missing/wrong.\nI've only implemented local lambda conv based pos embeddings.\nFor a PyTorch impl that includes other embedding options checkout\nhttps://github.com/lucidrains/lambda-networks",
        "detail": "timm.models.layers.lambda_layer",
        "documentation": {}
    },
    {
        "label": "Title",
        "kind": 5,
        "importPath": "timm.models.layers.lambda_layer",
        "description": "timm.models.layers.lambda_layer",
        "peekOfCode": "Title = {LambdaNetworks: Modeling Long-Range Interactions Without Attention},\nYear = {2021},\n}\nStatus:\nThis impl is a WIP. Code snippets in the paper were used as reference but\ngood chance some details are missing/wrong.\nI've only implemented local lambda conv based pos embeddings.\nFor a PyTorch impl that includes other embedding options checkout\nhttps://github.com/lucidrains/lambda-networks\nHacked together by / Copyright 2021 Ross Wightman",
        "detail": "timm.models.layers.lambda_layer",
        "documentation": {}
    },
    {
        "label": "Year",
        "kind": 5,
        "importPath": "timm.models.layers.lambda_layer",
        "description": "timm.models.layers.lambda_layer",
        "peekOfCode": "Year = {2021},\n}\nStatus:\nThis impl is a WIP. Code snippets in the paper were used as reference but\ngood chance some details are missing/wrong.\nI've only implemented local lambda conv based pos embeddings.\nFor a PyTorch impl that includes other embedding options checkout\nhttps://github.com/lucidrains/lambda-networks\nHacked together by / Copyright 2021 Ross Wightman\n\"\"\"",
        "detail": "timm.models.layers.lambda_layer",
        "documentation": {}
    },
    {
        "label": "Linear",
        "kind": 6,
        "importPath": "timm.models.layers.linear",
        "description": "timm.models.layers.linear",
        "peekOfCode": "class Linear(nn.Linear):\n    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n    Wraps torch.nn.Linear to support AMP + torchscript usage by manually casting\n    weight & bias to input.dtype to work around an issue w/ torch.addmm in this use case.\n    \"\"\"\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        if torch.jit.is_scripting():\n            bias = self.bias.to(dtype=input.dtype) if self.bias is not None else None\n            return F.linear(input, self.weight.to(dtype=input.dtype), bias=bias)\n        else:",
        "detail": "timm.models.layers.linear",
        "documentation": {}
    },
    {
        "label": "MedianPool2d",
        "kind": 6,
        "importPath": "timm.models.layers.median_pool",
        "description": "timm.models.layers.median_pool",
        "peekOfCode": "class MedianPool2d(nn.Module):\n    \"\"\" Median pool (usable as median filter when stride=1) module.\n    Args:\n         kernel_size: size of pooling kernel, int or 2-tuple\n         stride: pool stride, int or 2-tuple\n         padding: pool padding, int or 4-tuple (l, r, t, b) as in pytorch F.pad\n         same: override padding and enforce same padding, boolean\n    \"\"\"\n    def __init__(self, kernel_size=3, stride=1, padding=0, same=False):\n        super(MedianPool2d, self).__init__()",
        "detail": "timm.models.layers.median_pool",
        "documentation": {}
    },
    {
        "label": "MixedConv2d",
        "kind": 6,
        "importPath": "timm.models.layers.mixed_conv2d",
        "description": "timm.models.layers.mixed_conv2d",
        "peekOfCode": "class MixedConv2d(nn.ModuleDict):\n    \"\"\" Mixed Grouped Convolution\n    Based on MDConv and GroupedConv in MixNet impl:\n      https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mixnet/custom_layers.py\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size=3,\n                 stride=1, padding='', dilation=1, depthwise=False, **kwargs):\n        super(MixedConv2d, self).__init__()\n        kernel_size = kernel_size if isinstance(kernel_size, list) else [kernel_size]\n        num_groups = len(kernel_size)",
        "detail": "timm.models.layers.mixed_conv2d",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "kind": 6,
        "importPath": "timm.models.layers.mlp",
        "description": "timm.models.layers.mlp",
        "peekOfCode": "class Mlp(nn.Module):\n    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n    \"\"\"\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        drop_probs = to_2tuple(drop)\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()",
        "detail": "timm.models.layers.mlp",
        "documentation": {}
    },
    {
        "label": "GluMlp",
        "kind": 6,
        "importPath": "timm.models.layers.mlp",
        "description": "timm.models.layers.mlp",
        "peekOfCode": "class GluMlp(nn.Module):\n    \"\"\" MLP w/ GLU style gating\n    See: https://arxiv.org/abs/1612.08083, https://arxiv.org/abs/2002.05202\n    \"\"\"\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.Sigmoid, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        assert hidden_features % 2 == 0\n        drop_probs = to_2tuple(drop)",
        "detail": "timm.models.layers.mlp",
        "documentation": {}
    },
    {
        "label": "GatedMlp",
        "kind": 6,
        "importPath": "timm.models.layers.mlp",
        "description": "timm.models.layers.mlp",
        "peekOfCode": "class GatedMlp(nn.Module):\n    \"\"\" MLP as used in gMLP\n    \"\"\"\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU,\n                 gate_layer=None, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        drop_probs = to_2tuple(drop)\n        self.fc1 = nn.Linear(in_features, hidden_features)",
        "detail": "timm.models.layers.mlp",
        "documentation": {}
    },
    {
        "label": "ConvMlp",
        "kind": 6,
        "importPath": "timm.models.layers.mlp",
        "description": "timm.models.layers.mlp",
        "peekOfCode": "class ConvMlp(nn.Module):\n    \"\"\" MLP using 1x1 convs that keeps spatial dims\n    \"\"\"\n    def __init__(\n            self, in_features, hidden_features=None, out_features=None, act_layer=nn.ReLU, norm_layer=None, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Conv2d(in_features, hidden_features, kernel_size=1, bias=True)\n        self.norm = norm_layer(hidden_features) if norm_layer else nn.Identity()",
        "detail": "timm.models.layers.mlp",
        "documentation": {}
    },
    {
        "label": "NonLocalAttn",
        "kind": 6,
        "importPath": "timm.models.layers.non_local_attn",
        "description": "timm.models.layers.non_local_attn",
        "peekOfCode": "class NonLocalAttn(nn.Module):\n    \"\"\"Spatial NL block for image classification.\n    This was adapted from https://github.com/BA-Transform/BAT-Image-Classification\n    Their NonLocal impl inspired by https://github.com/facebookresearch/video-nonlocal-net.\n    \"\"\"\n    def __init__(self, in_channels, use_scale=True,  rd_ratio=1/8, rd_channels=None, rd_divisor=8, **kwargs):\n        super(NonLocalAttn, self).__init__()\n        if rd_channels is None:\n            rd_channels = make_divisible(in_channels * rd_ratio, divisor=rd_divisor)\n        self.scale = in_channels ** -0.5 if use_scale else 1.0",
        "detail": "timm.models.layers.non_local_attn",
        "documentation": {}
    },
    {
        "label": "BilinearAttnTransform",
        "kind": 6,
        "importPath": "timm.models.layers.non_local_attn",
        "description": "timm.models.layers.non_local_attn",
        "peekOfCode": "class BilinearAttnTransform(nn.Module):\n    def __init__(self, in_channels, block_size, groups, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d):\n        super(BilinearAttnTransform, self).__init__()\n        self.conv1 = ConvBnAct(in_channels, groups, 1, act_layer=act_layer, norm_layer=norm_layer)\n        self.conv_p = nn.Conv2d(groups, block_size * block_size * groups, kernel_size=(block_size, 1))\n        self.conv_q = nn.Conv2d(groups, block_size * block_size * groups, kernel_size=(1, block_size))\n        self.conv2 = ConvBnAct(in_channels, in_channels, 1, act_layer=act_layer, norm_layer=norm_layer)\n        self.block_size = block_size\n        self.groups = groups\n        self.in_channels = in_channels",
        "detail": "timm.models.layers.non_local_attn",
        "documentation": {}
    },
    {
        "label": "BatNonLocalAttn",
        "kind": 6,
        "importPath": "timm.models.layers.non_local_attn",
        "description": "timm.models.layers.non_local_attn",
        "peekOfCode": "class BatNonLocalAttn(nn.Module):\n    \"\"\" BAT\n    Adapted from: https://github.com/BA-Transform/BAT-Image-Classification\n    \"\"\"\n    def __init__(\n            self, in_channels, block_size=7, groups=2, rd_ratio=0.25, rd_channels=None, rd_divisor=8,\n            drop_rate=0.2, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, **_):\n        super().__init__()\n        if rd_channels is None:\n            rd_channels = make_divisible(in_channels * rd_ratio, divisor=rd_divisor)",
        "detail": "timm.models.layers.non_local_attn",
        "documentation": {}
    },
    {
        "label": "GroupNorm",
        "kind": 6,
        "importPath": "timm.models.layers.norm",
        "description": "timm.models.layers.norm",
        "peekOfCode": "class GroupNorm(nn.GroupNorm):\n    def __init__(self, num_channels, num_groups=32, eps=1e-5, affine=True):\n        # NOTE num_channels is swapped to first arg for consistency in swapping norm layers with BN\n        super().__init__(num_groups, num_channels, eps=eps, affine=affine)\n    def forward(self, x):\n        return F.group_norm(x, self.num_groups, self.weight, self.bias, self.eps)\nclass LayerNorm2d(nn.LayerNorm):\n    \"\"\" LayerNorm for channels of '2D' spatial BCHW tensors \"\"\"\n    def __init__(self, num_channels):\n        super().__init__(num_channels)",
        "detail": "timm.models.layers.norm",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "kind": 6,
        "importPath": "timm.models.layers.norm",
        "description": "timm.models.layers.norm",
        "peekOfCode": "class LayerNorm2d(nn.LayerNorm):\n    \"\"\" LayerNorm for channels of '2D' spatial BCHW tensors \"\"\"\n    def __init__(self, num_channels):\n        super().__init__(num_channels)\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return F.layer_norm(\n            x.permute(0, 2, 3, 1), self.normalized_shape, self.weight, self.bias, self.eps).permute(0, 3, 1, 2)",
        "detail": "timm.models.layers.norm",
        "documentation": {}
    },
    {
        "label": "BatchNormAct2d",
        "kind": 6,
        "importPath": "timm.models.layers.norm_act",
        "description": "timm.models.layers.norm_act",
        "peekOfCode": "class BatchNormAct2d(nn.BatchNorm2d):\n    \"\"\"BatchNorm + Activation\n    This module performs BatchNorm + Activation in a manner that will remain backwards\n    compatible with weights trained with separate bn, act. This is why we inherit from BN\n    instead of composing it as a .bn member.\n    \"\"\"\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True,\n                 apply_act=True, act_layer=nn.ReLU, inplace=True, drop_block=None):\n        super(BatchNormAct2d, self).__init__(\n            num_features, eps=eps, momentum=momentum, affine=affine, track_running_stats=track_running_stats)",
        "detail": "timm.models.layers.norm_act",
        "documentation": {}
    },
    {
        "label": "GroupNormAct",
        "kind": 6,
        "importPath": "timm.models.layers.norm_act",
        "description": "timm.models.layers.norm_act",
        "peekOfCode": "class GroupNormAct(nn.GroupNorm):\n    # NOTE num_channel and num_groups order flipped for easier layer swaps / binding of fixed args\n    def __init__(self, num_channels, num_groups=32, eps=1e-5, affine=True,\n                 apply_act=True, act_layer=nn.ReLU, inplace=True, drop_block=None):\n        super(GroupNormAct, self).__init__(num_groups, num_channels, eps=eps, affine=affine)\n        if isinstance(act_layer, str):\n            act_layer = get_act_layer(act_layer)\n        if act_layer is not None and apply_act:\n            act_args = dict(inplace=True) if inplace else {}\n            self.act = act_layer(**act_args)",
        "detail": "timm.models.layers.norm_act",
        "documentation": {}
    },
    {
        "label": "get_padding",
        "kind": 2,
        "importPath": "timm.models.layers.padding",
        "description": "timm.models.layers.padding",
        "peekOfCode": "def get_padding(kernel_size: int, stride: int = 1, dilation: int = 1, **_) -> int:\n    padding = ((stride - 1) + dilation * (kernel_size - 1)) // 2\n    return padding\n# Calculate asymmetric TensorFlow-like 'SAME' padding for a convolution\ndef get_same_padding(x: int, k: int, s: int, d: int):\n    return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n# Can SAME padding for given args be done statically?\ndef is_static_pad(kernel_size: int, stride: int = 1, dilation: int = 1, **_):\n    return stride == 1 and (dilation * (kernel_size - 1)) % 2 == 0\n# Dynamically pad input x with 'SAME' padding for conv with specified args",
        "detail": "timm.models.layers.padding",
        "documentation": {}
    },
    {
        "label": "get_same_padding",
        "kind": 2,
        "importPath": "timm.models.layers.padding",
        "description": "timm.models.layers.padding",
        "peekOfCode": "def get_same_padding(x: int, k: int, s: int, d: int):\n    return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n# Can SAME padding for given args be done statically?\ndef is_static_pad(kernel_size: int, stride: int = 1, dilation: int = 1, **_):\n    return stride == 1 and (dilation * (kernel_size - 1)) % 2 == 0\n# Dynamically pad input x with 'SAME' padding for conv with specified args\ndef pad_same(x, k: List[int], s: List[int], d: List[int] = (1, 1), value: float = 0):\n    ih, iw = x.size()[-2:]\n    pad_h, pad_w = get_same_padding(ih, k[0], s[0], d[0]), get_same_padding(iw, k[1], s[1], d[1])\n    if pad_h > 0 or pad_w > 0:",
        "detail": "timm.models.layers.padding",
        "documentation": {}
    },
    {
        "label": "is_static_pad",
        "kind": 2,
        "importPath": "timm.models.layers.padding",
        "description": "timm.models.layers.padding",
        "peekOfCode": "def is_static_pad(kernel_size: int, stride: int = 1, dilation: int = 1, **_):\n    return stride == 1 and (dilation * (kernel_size - 1)) % 2 == 0\n# Dynamically pad input x with 'SAME' padding for conv with specified args\ndef pad_same(x, k: List[int], s: List[int], d: List[int] = (1, 1), value: float = 0):\n    ih, iw = x.size()[-2:]\n    pad_h, pad_w = get_same_padding(ih, k[0], s[0], d[0]), get_same_padding(iw, k[1], s[1], d[1])\n    if pad_h > 0 or pad_w > 0:\n        x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n    return x\ndef get_padding_value(padding, kernel_size, **kwargs) -> Tuple[Tuple, bool]:",
        "detail": "timm.models.layers.padding",
        "documentation": {}
    },
    {
        "label": "pad_same",
        "kind": 2,
        "importPath": "timm.models.layers.padding",
        "description": "timm.models.layers.padding",
        "peekOfCode": "def pad_same(x, k: List[int], s: List[int], d: List[int] = (1, 1), value: float = 0):\n    ih, iw = x.size()[-2:]\n    pad_h, pad_w = get_same_padding(ih, k[0], s[0], d[0]), get_same_padding(iw, k[1], s[1], d[1])\n    if pad_h > 0 or pad_w > 0:\n        x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n    return x\ndef get_padding_value(padding, kernel_size, **kwargs) -> Tuple[Tuple, bool]:\n    dynamic = False\n    if isinstance(padding, str):\n        # for any string padding, the padding will be calculated for you, one of three ways",
        "detail": "timm.models.layers.padding",
        "documentation": {}
    },
    {
        "label": "get_padding_value",
        "kind": 2,
        "importPath": "timm.models.layers.padding",
        "description": "timm.models.layers.padding",
        "peekOfCode": "def get_padding_value(padding, kernel_size, **kwargs) -> Tuple[Tuple, bool]:\n    dynamic = False\n    if isinstance(padding, str):\n        # for any string padding, the padding will be calculated for you, one of three ways\n        padding = padding.lower()\n        if padding == 'same':\n            # TF compatible 'SAME' padding, has a performance and GPU memory allocation impact\n            if is_static_pad(kernel_size, **kwargs):\n                # static case, no extra overhead\n                padding = get_padding(kernel_size, **kwargs)",
        "detail": "timm.models.layers.padding",
        "documentation": {}
    },
    {
        "label": "PatchEmbed",
        "kind": 6,
        "importPath": "timm.models.layers.patch_embed",
        "description": "timm.models.layers.patch_embed",
        "peekOfCode": "class PatchEmbed(nn.Module):\n    \"\"\" 2D Image to Patch Embedding\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])",
        "detail": "timm.models.layers.patch_embed",
        "documentation": {}
    },
    {
        "label": "AvgPool2dSame",
        "kind": 6,
        "importPath": "timm.models.layers.pool2d_same",
        "description": "timm.models.layers.pool2d_same",
        "peekOfCode": "class AvgPool2dSame(nn.AvgPool2d):\n    \"\"\" Tensorflow like 'SAME' wrapper for 2D average pooling\n    \"\"\"\n    def __init__(self, kernel_size: int, stride=None, padding=0, ceil_mode=False, count_include_pad=True):\n        kernel_size = to_2tuple(kernel_size)\n        stride = to_2tuple(stride)\n        super(AvgPool2dSame, self).__init__(kernel_size, stride, (0, 0), ceil_mode, count_include_pad)\n    def forward(self, x):\n        x = pad_same(x, self.kernel_size, self.stride)\n        return F.avg_pool2d(",
        "detail": "timm.models.layers.pool2d_same",
        "documentation": {}
    },
    {
        "label": "MaxPool2dSame",
        "kind": 6,
        "importPath": "timm.models.layers.pool2d_same",
        "description": "timm.models.layers.pool2d_same",
        "peekOfCode": "class MaxPool2dSame(nn.MaxPool2d):\n    \"\"\" Tensorflow like 'SAME' wrapper for 2D max pooling\n    \"\"\"\n    def __init__(self, kernel_size: int, stride=None, padding=0, dilation=1, ceil_mode=False):\n        kernel_size = to_2tuple(kernel_size)\n        stride = to_2tuple(stride)\n        dilation = to_2tuple(dilation)\n        super(MaxPool2dSame, self).__init__(kernel_size, stride, (0, 0), dilation, ceil_mode)\n    def forward(self, x):\n        x = pad_same(x, self.kernel_size, self.stride, value=-float('inf'))",
        "detail": "timm.models.layers.pool2d_same",
        "documentation": {}
    },
    {
        "label": "avg_pool2d_same",
        "kind": 2,
        "importPath": "timm.models.layers.pool2d_same",
        "description": "timm.models.layers.pool2d_same",
        "peekOfCode": "def avg_pool2d_same(x, kernel_size: List[int], stride: List[int], padding: List[int] = (0, 0),\n                    ceil_mode: bool = False, count_include_pad: bool = True):\n    # FIXME how to deal with count_include_pad vs not for external padding?\n    x = pad_same(x, kernel_size, stride)\n    return F.avg_pool2d(x, kernel_size, stride, (0, 0), ceil_mode, count_include_pad)\nclass AvgPool2dSame(nn.AvgPool2d):\n    \"\"\" Tensorflow like 'SAME' wrapper for 2D average pooling\n    \"\"\"\n    def __init__(self, kernel_size: int, stride=None, padding=0, ceil_mode=False, count_include_pad=True):\n        kernel_size = to_2tuple(kernel_size)",
        "detail": "timm.models.layers.pool2d_same",
        "documentation": {}
    },
    {
        "label": "max_pool2d_same",
        "kind": 2,
        "importPath": "timm.models.layers.pool2d_same",
        "description": "timm.models.layers.pool2d_same",
        "peekOfCode": "def max_pool2d_same(\n        x, kernel_size: List[int], stride: List[int], padding: List[int] = (0, 0),\n        dilation: List[int] = (1, 1), ceil_mode: bool = False):\n    x = pad_same(x, kernel_size, stride, value=-float('inf'))\n    return F.max_pool2d(x, kernel_size, stride, (0, 0), dilation, ceil_mode)\nclass MaxPool2dSame(nn.MaxPool2d):\n    \"\"\" Tensorflow like 'SAME' wrapper for 2D max pooling\n    \"\"\"\n    def __init__(self, kernel_size: int, stride=None, padding=0, dilation=1, ceil_mode=False):\n        kernel_size = to_2tuple(kernel_size)",
        "detail": "timm.models.layers.pool2d_same",
        "documentation": {}
    },
    {
        "label": "create_pool2d",
        "kind": 2,
        "importPath": "timm.models.layers.pool2d_same",
        "description": "timm.models.layers.pool2d_same",
        "peekOfCode": "def create_pool2d(pool_type, kernel_size, stride=None, **kwargs):\n    stride = stride or kernel_size\n    padding = kwargs.pop('padding', '')\n    padding, is_dynamic = get_padding_value(padding, kernel_size, stride=stride, **kwargs)\n    if is_dynamic:\n        if pool_type == 'avg':\n            return AvgPool2dSame(kernel_size, stride=stride, **kwargs)\n        elif pool_type == 'max':\n            return MaxPool2dSame(kernel_size, stride=stride, **kwargs)\n        else:",
        "detail": "timm.models.layers.pool2d_same",
        "documentation": {}
    },
    {
        "label": "SelectiveKernelAttn",
        "kind": 6,
        "importPath": "timm.models.layers.selective_kernel",
        "description": "timm.models.layers.selective_kernel",
        "peekOfCode": "class SelectiveKernelAttn(nn.Module):\n    def __init__(self, channels, num_paths=2, attn_channels=32,\n                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d):\n        \"\"\" Selective Kernel Attention Module\n        Selective Kernel attention mechanism factored out into its own module.\n        \"\"\"\n        super(SelectiveKernelAttn, self).__init__()\n        self.num_paths = num_paths\n        self.fc_reduce = nn.Conv2d(channels, attn_channels, kernel_size=1, bias=False)\n        self.bn = norm_layer(attn_channels)",
        "detail": "timm.models.layers.selective_kernel",
        "documentation": {}
    },
    {
        "label": "SelectiveKernel",
        "kind": 6,
        "importPath": "timm.models.layers.selective_kernel",
        "description": "timm.models.layers.selective_kernel",
        "peekOfCode": "class SelectiveKernel(nn.Module):\n    def __init__(self, in_channels, out_channels=None, kernel_size=None, stride=1, dilation=1, groups=1,\n                 rd_ratio=1./16, rd_channels=None, rd_divisor=8, keep_3x3=True, split_input=True,\n                 drop_block=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, aa_layer=None):\n        \"\"\" Selective Kernel Convolution Module\n        As described in Selective Kernel Networks (https://arxiv.org/abs/1903.06586) with some modifications.\n        Largest change is the input split, which divides the input channels across each convolution path, this can\n        be viewed as a grouping of sorts, but the output channel counts expand to the module level value. This keeps\n        the parameter count from ballooning when the convolutions themselves don't have groups, but still provides\n        a noteworthy increase in performance over similar param count models without this attention layer. -Ross W",
        "detail": "timm.models.layers.selective_kernel",
        "documentation": {}
    },
    {
        "label": "SeparableConvBnAct",
        "kind": 6,
        "importPath": "timm.models.layers.separable_conv",
        "description": "timm.models.layers.separable_conv",
        "peekOfCode": "class SeparableConvBnAct(nn.Module):\n    \"\"\" Separable Conv w/ trailing Norm and Activation\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, padding='', bias=False,\n                 channel_multiplier=1.0, pw_kernel_size=1, norm_layer=nn.BatchNorm2d, act_layer=nn.ReLU,\n                 apply_act=True, drop_block=None):\n        super(SeparableConvBnAct, self).__init__()\n        self.conv_dw = create_conv2d(\n            in_channels, int(in_channels * channel_multiplier), kernel_size,\n            stride=stride, dilation=dilation, padding=padding, depthwise=True)",
        "detail": "timm.models.layers.separable_conv",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.layers.separable_conv",
        "description": "timm.models.layers.separable_conv",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    \"\"\" Separable Conv\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, padding='', bias=False,\n                 channel_multiplier=1.0, pw_kernel_size=1):\n        super(SeparableConv2d, self).__init__()\n        self.conv_dw = create_conv2d(\n            in_channels, int(in_channels * channel_multiplier), kernel_size,\n            stride=stride, dilation=dilation, padding=padding, depthwise=True)\n        self.conv_pw = create_conv2d(",
        "detail": "timm.models.layers.separable_conv",
        "documentation": {}
    },
    {
        "label": "SpaceToDepth",
        "kind": 6,
        "importPath": "timm.models.layers.space_to_depth",
        "description": "timm.models.layers.space_to_depth",
        "peekOfCode": "class SpaceToDepth(nn.Module):\n    def __init__(self, block_size=4):\n        super().__init__()\n        assert block_size == 4\n        self.bs = block_size\n    def forward(self, x):\n        N, C, H, W = x.size()\n        x = x.view(N, C, H // self.bs, self.bs, W // self.bs, self.bs)  # (N, C, H//bs, bs, W//bs, bs)\n        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # (N, bs, bs, C, H//bs, W//bs)\n        x = x.view(N, C * (self.bs ** 2), H // self.bs, W // self.bs)  # (N, C*bs^2, H//bs, W//bs)",
        "detail": "timm.models.layers.space_to_depth",
        "documentation": {}
    },
    {
        "label": "SpaceToDepthJit",
        "kind": 6,
        "importPath": "timm.models.layers.space_to_depth",
        "description": "timm.models.layers.space_to_depth",
        "peekOfCode": "class SpaceToDepthJit(object):\n    def __call__(self, x: torch.Tensor):\n        # assuming hard-coded that block_size==4 for acceleration\n        N, C, H, W = x.size()\n        x = x.view(N, C, H // 4, 4, W // 4, 4)  # (N, C, H//bs, bs, W//bs, bs)\n        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # (N, bs, bs, C, H//bs, W//bs)\n        x = x.view(N, C * 16, H // 4, W // 4)  # (N, C*bs^2, H//bs, W//bs)\n        return x\nclass SpaceToDepthModule(nn.Module):\n    def __init__(self, no_jit=False):",
        "detail": "timm.models.layers.space_to_depth",
        "documentation": {}
    },
    {
        "label": "SpaceToDepthModule",
        "kind": 6,
        "importPath": "timm.models.layers.space_to_depth",
        "description": "timm.models.layers.space_to_depth",
        "peekOfCode": "class SpaceToDepthModule(nn.Module):\n    def __init__(self, no_jit=False):\n        super().__init__()\n        if not no_jit:\n            self.op = SpaceToDepthJit()\n        else:\n            self.op = SpaceToDepth()\n    def forward(self, x):\n        return self.op(x)\nclass DepthToSpace(nn.Module):",
        "detail": "timm.models.layers.space_to_depth",
        "documentation": {}
    },
    {
        "label": "DepthToSpace",
        "kind": 6,
        "importPath": "timm.models.layers.space_to_depth",
        "description": "timm.models.layers.space_to_depth",
        "peekOfCode": "class DepthToSpace(nn.Module):\n    def __init__(self, block_size):\n        super().__init__()\n        self.bs = block_size\n    def forward(self, x):\n        N, C, H, W = x.size()\n        x = x.view(N, self.bs, self.bs, C // (self.bs ** 2), H, W)  # (N, bs, bs, C//bs^2, H, W)\n        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # (N, C//bs^2, H, bs, W, bs)\n        x = x.view(N, C // (self.bs ** 2), H * self.bs, W * self.bs)  # (N, C//bs^2, H * bs, W * bs)\n        return x",
        "detail": "timm.models.layers.space_to_depth",
        "documentation": {}
    },
    {
        "label": "RadixSoftmax",
        "kind": 6,
        "importPath": "timm.models.layers.split_attn",
        "description": "timm.models.layers.split_attn",
        "peekOfCode": "class RadixSoftmax(nn.Module):\n    def __init__(self, radix, cardinality):\n        super(RadixSoftmax, self).__init__()\n        self.radix = radix\n        self.cardinality = cardinality\n    def forward(self, x):\n        batch = x.size(0)\n        if self.radix > 1:\n            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n            x = F.softmax(x, dim=1)",
        "detail": "timm.models.layers.split_attn",
        "documentation": {}
    },
    {
        "label": "SplitAttn",
        "kind": 6,
        "importPath": "timm.models.layers.split_attn",
        "description": "timm.models.layers.split_attn",
        "peekOfCode": "class SplitAttn(nn.Module):\n    \"\"\"Split-Attention (aka Splat)\n    \"\"\"\n    def __init__(self, in_channels, out_channels=None, kernel_size=3, stride=1, padding=None,\n                 dilation=1, groups=1, bias=False, radix=2, rd_ratio=0.25, rd_channels=None, rd_divisor=8,\n                 act_layer=nn.ReLU, norm_layer=None, drop_block=None, **kwargs):\n        super(SplitAttn, self).__init__()\n        out_channels = out_channels or in_channels\n        self.radix = radix\n        self.drop_block = drop_block",
        "detail": "timm.models.layers.split_attn",
        "documentation": {}
    },
    {
        "label": "SplitBatchNorm2d",
        "kind": 6,
        "importPath": "timm.models.layers.split_batchnorm",
        "description": "timm.models.layers.split_batchnorm",
        "peekOfCode": "class SplitBatchNorm2d(torch.nn.BatchNorm2d):\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n                 track_running_stats=True, num_splits=2):\n        super().__init__(num_features, eps, momentum, affine, track_running_stats)\n        assert num_splits > 1, 'Should have at least one aux BN layer (num_splits at least 2)'\n        self.num_splits = num_splits\n        self.aux_bn = nn.ModuleList([\n            nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats) for _ in range(num_splits - 1)])\n    def forward(self, input: torch.Tensor):\n        if self.training:  # aux BN only relevant while training",
        "detail": "timm.models.layers.split_batchnorm",
        "documentation": {}
    },
    {
        "label": "convert_splitbn_model",
        "kind": 2,
        "importPath": "timm.models.layers.split_batchnorm",
        "description": "timm.models.layers.split_batchnorm",
        "peekOfCode": "def convert_splitbn_model(module, num_splits=2):\n    \"\"\"\n    Recursively traverse module and its children to replace all instances of\n    ``torch.nn.modules.batchnorm._BatchNorm`` with `SplitBatchnorm2d`.\n    Args:\n        module (torch.nn.Module): input module\n        num_splits: number of separate batchnorm layers to split input across\n    Example::\n        >>> # model is an instance of torch.nn.Module\n        >>> model = timm.models.convert_splitbn_model(model, num_splits=2)",
        "detail": "timm.models.layers.split_batchnorm",
        "documentation": {}
    },
    {
        "label": "SEModule",
        "kind": 6,
        "importPath": "timm.models.layers.squeeze_excite",
        "description": "timm.models.layers.squeeze_excite",
        "peekOfCode": "class SEModule(nn.Module):\n    \"\"\" SE Module as defined in original SE-Nets with a few additions\n    Additions include:\n        * divisor can be specified to keep channels % div == 0 (default: 8)\n        * reduction channels can be specified directly by arg (if rd_channels is set)\n        * reduction channels can be specified by float rd_ratio (default: 1/16)\n        * global max pooling can be added to the squeeze aggregation\n        * customizable activation, normalization, and gate layer\n    \"\"\"\n    def __init__(",
        "detail": "timm.models.layers.squeeze_excite",
        "documentation": {}
    },
    {
        "label": "EffectiveSEModule",
        "kind": 6,
        "importPath": "timm.models.layers.squeeze_excite",
        "description": "timm.models.layers.squeeze_excite",
        "peekOfCode": "class EffectiveSEModule(nn.Module):\n    \"\"\" 'Effective Squeeze-Excitation\n    From `CenterMask : Real-Time Anchor-Free Instance Segmentation` - https://arxiv.org/abs/1911.06667\n    \"\"\"\n    def __init__(self, channels, add_maxpool=False, gate_layer='hard_sigmoid', **_):\n        super(EffectiveSEModule, self).__init__()\n        self.add_maxpool = add_maxpool\n        self.fc = nn.Conv2d(channels, channels, kernel_size=1, padding=0)\n        self.gate = create_act_layer(gate_layer)\n    def forward(self, x):",
        "detail": "timm.models.layers.squeeze_excite",
        "documentation": {}
    },
    {
        "label": "SqueezeExcite",
        "kind": 5,
        "importPath": "timm.models.layers.squeeze_excite",
        "description": "timm.models.layers.squeeze_excite",
        "peekOfCode": "SqueezeExcite = SEModule  # alias\nclass EffectiveSEModule(nn.Module):\n    \"\"\" 'Effective Squeeze-Excitation\n    From `CenterMask : Real-Time Anchor-Free Instance Segmentation` - https://arxiv.org/abs/1911.06667\n    \"\"\"\n    def __init__(self, channels, add_maxpool=False, gate_layer='hard_sigmoid', **_):\n        super(EffectiveSEModule, self).__init__()\n        self.add_maxpool = add_maxpool\n        self.fc = nn.Conv2d(channels, channels, kernel_size=1, padding=0)\n        self.gate = create_act_layer(gate_layer)",
        "detail": "timm.models.layers.squeeze_excite",
        "documentation": {}
    },
    {
        "label": "EffectiveSqueezeExcite",
        "kind": 5,
        "importPath": "timm.models.layers.squeeze_excite",
        "description": "timm.models.layers.squeeze_excite",
        "peekOfCode": "EffectiveSqueezeExcite = EffectiveSEModule  # alias",
        "detail": "timm.models.layers.squeeze_excite",
        "documentation": {}
    },
    {
        "label": "StdConv2d",
        "kind": 6,
        "importPath": "timm.models.layers.std_conv",
        "description": "timm.models.layers.std_conv",
        "peekOfCode": "class StdConv2d(nn.Conv2d):\n    \"\"\"Conv2d with Weight Standardization. Used for BiT ResNet-V2 models.\n    Paper: `Micro-Batch Training with Batch-Channel Normalization and Weight Standardization` -\n        https://arxiv.org/abs/1903.10520v2\n    \"\"\"\n    def __init__(\n            self, in_channel, out_channels, kernel_size, stride=1, padding=None,\n            dilation=1, groups=1, bias=False, eps=1e-6):\n        if padding is None:\n            padding = get_padding(kernel_size, stride, dilation)",
        "detail": "timm.models.layers.std_conv",
        "documentation": {}
    },
    {
        "label": "StdConv2dSame",
        "kind": 6,
        "importPath": "timm.models.layers.std_conv",
        "description": "timm.models.layers.std_conv",
        "peekOfCode": "class StdConv2dSame(nn.Conv2d):\n    \"\"\"Conv2d with Weight Standardization. TF compatible SAME padding. Used for ViT Hybrid model.\n    Paper: `Micro-Batch Training with Batch-Channel Normalization and Weight Standardization` -\n        https://arxiv.org/abs/1903.10520v2\n    \"\"\"\n    def __init__(\n            self, in_channel, out_channels, kernel_size, stride=1, padding='SAME',\n            dilation=1, groups=1, bias=False, eps=1e-6):\n        padding, is_dynamic = get_padding_value(padding, kernel_size, stride=stride, dilation=dilation)\n        super().__init__(",
        "detail": "timm.models.layers.std_conv",
        "documentation": {}
    },
    {
        "label": "ScaledStdConv2d",
        "kind": 6,
        "importPath": "timm.models.layers.std_conv",
        "description": "timm.models.layers.std_conv",
        "peekOfCode": "class ScaledStdConv2d(nn.Conv2d):\n    \"\"\"Conv2d layer with Scaled Weight Standardization.\n    Paper: `Characterizing signal propagation to close the performance gap in unnormalized ResNets` -\n        https://arxiv.org/abs/2101.08692\n    NOTE: the operations used in this impl differ slightly from the DeepMind Haiku impl. The impact is minor.\n    \"\"\"\n    def __init__(\n            self, in_channels, out_channels, kernel_size, stride=1, padding=None,\n            dilation=1, groups=1, bias=True, gamma=1.0, eps=1e-6, gain_init=1.0):\n        if padding is None:",
        "detail": "timm.models.layers.std_conv",
        "documentation": {}
    },
    {
        "label": "ScaledStdConv2dSame",
        "kind": 6,
        "importPath": "timm.models.layers.std_conv",
        "description": "timm.models.layers.std_conv",
        "peekOfCode": "class ScaledStdConv2dSame(nn.Conv2d):\n    \"\"\"Conv2d layer with Scaled Weight Standardization and Tensorflow-like SAME padding support\n    Paper: `Characterizing signal propagation to close the performance gap in unnormalized ResNets` -\n        https://arxiv.org/abs/2101.08692\n    NOTE: the operations used in this impl differ slightly from the DeepMind Haiku impl. The impact is minor.\n    \"\"\"\n    def __init__(\n            self, in_channels, out_channels, kernel_size, stride=1, padding='SAME',\n            dilation=1, groups=1, bias=True, gamma=1.0, eps=1e-6, gain_init=1.0):\n        padding, is_dynamic = get_padding_value(padding, kernel_size, stride=stride, dilation=dilation)",
        "detail": "timm.models.layers.std_conv",
        "documentation": {}
    },
    {
        "label": "TestTimePoolHead",
        "kind": 6,
        "importPath": "timm.models.layers.test_time_pool",
        "description": "timm.models.layers.test_time_pool",
        "peekOfCode": "class TestTimePoolHead(nn.Module):\n    def __init__(self, base, original_pool=7):\n        super(TestTimePoolHead, self).__init__()\n        self.base = base\n        self.original_pool = original_pool\n        base_fc = self.base.get_classifier()\n        if isinstance(base_fc, nn.Conv2d):\n            self.fc = base_fc\n        else:\n            self.fc = nn.Conv2d(",
        "detail": "timm.models.layers.test_time_pool",
        "documentation": {}
    },
    {
        "label": "apply_test_time_pool",
        "kind": 2,
        "importPath": "timm.models.layers.test_time_pool",
        "description": "timm.models.layers.test_time_pool",
        "peekOfCode": "def apply_test_time_pool(model, config, use_test_size=True):\n    test_time_pool = False\n    if not hasattr(model, 'default_cfg') or not model.default_cfg:\n        return model, False\n    if use_test_size and 'test_input_size' in model.default_cfg:\n        df_input_size = model.default_cfg['test_input_size']\n    else:\n        df_input_size = model.default_cfg['input_size']\n    if config['input_size'][-1] > df_input_size[-1] and config['input_size'][-2] > df_input_size[-2]:\n        _logger.info('Target input size %s > pretrained default %s, using test time pooling' %",
        "detail": "timm.models.layers.test_time_pool",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.layers.test_time_pool",
        "description": "timm.models.layers.test_time_pool",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass TestTimePoolHead(nn.Module):\n    def __init__(self, base, original_pool=7):\n        super(TestTimePoolHead, self).__init__()\n        self.base = base\n        self.original_pool = original_pool\n        base_fc = self.base.get_classifier()\n        if isinstance(base_fc, nn.Conv2d):\n            self.fc = base_fc\n        else:",
        "detail": "timm.models.layers.test_time_pool",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "kind": 2,
        "importPath": "timm.models.layers.weight_init",
        "description": "timm.models.layers.weight_init",
        "peekOfCode": "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n    # type: (Tensor, float, float, float, float) -> Tensor\n    r\"\"\"Fills the input Tensor with values drawn from a truncated\n    normal distribution. The values are effectively drawn from the\n    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n    with values outside :math:`[a, b]` redrawn until they are within\n    the bounds. The method used for generating the random values works\n    best when :math:`a \\leq \\text{mean} \\leq b`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`",
        "detail": "timm.models.layers.weight_init",
        "documentation": {}
    },
    {
        "label": "variance_scaling_",
        "kind": 2,
        "importPath": "timm.models.layers.weight_init",
        "description": "timm.models.layers.weight_init",
        "peekOfCode": "def variance_scaling_(tensor, scale=1.0, mode='fan_in', distribution='normal'):\n    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n    if mode == 'fan_in':\n        denom = fan_in\n    elif mode == 'fan_out':\n        denom = fan_out\n    elif mode == 'fan_avg':\n        denom = (fan_in + fan_out) / 2\n    variance = scale / denom\n    if distribution == \"truncated_normal\":",
        "detail": "timm.models.layers.weight_init",
        "documentation": {}
    },
    {
        "label": "lecun_normal_",
        "kind": 2,
        "importPath": "timm.models.layers.weight_init",
        "description": "timm.models.layers.weight_init",
        "peekOfCode": "def lecun_normal_(tensor):\n    variance_scaling_(tensor, mode='fan_in', distribution='truncated_normal')",
        "detail": "timm.models.layers.weight_init",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "class Attention(nn.Module):\n    def __init__(\n            self, dim, num_heads=8, qkv_bias=False, attn_drop=0.,\n            proj_drop=0., window_size=None, attn_head_dim=None):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        if attn_head_dim is not None:\n            head_dim = attn_head_dim\n        all_head_dim = head_dim * self.num_heads",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., init_values=None, act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n                 window_size=None, attn_head_dim=None):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = Attention(\n            dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop,\n            window_size=window_size, attn_head_dim=attn_head_dim)\n        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "RelativePositionBias",
        "kind": 6,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "class RelativePositionBias(nn.Module):\n    def __init__(self, window_size, num_heads):\n        super().__init__()\n        self.window_size = window_size\n        self.num_relative_distance = (2 * window_size[0] - 1) * (2 * window_size[1] - 1) + 3\n        self.relative_position_bias_table = nn.Parameter(\n            torch.zeros(self.num_relative_distance, num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n        # cls to token & token 2 cls & cls to cls\n        # get pair-wise relative position index for each token inside the window\n        coords_h = torch.arange(window_size[0])",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "Beit",
        "kind": 6,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "class Beit(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n                 num_heads=12, mlp_ratio=4., qkv_bias=True, drop_rate=0., attn_drop_rate=0.,\n                 drop_path_rate=0., norm_layer=partial(nn.LayerNorm, eps=1e-6), init_values=None,\n                 use_abs_pos_emb=True, use_rel_pos_bias=False, use_shared_rel_pos_bias=False,\n                 use_mean_pooling=True, init_scale=0.001):\n        super().__init__()\n        self.num_classes = num_classes",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_base_patch16_224",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_base_patch16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=0.1, **kwargs)\n    model = _create_beit('beit_base_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_base_patch16_384(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=384, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_base_patch16_384",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_base_patch16_384(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=384, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=0.1, **kwargs)\n    model = _create_beit('beit_base_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_base_patch16_224_in22k(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_base_patch16_224_in22k",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_base_patch16_224_in22k(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=0.1, **kwargs)\n    model = _create_beit('beit_base_patch16_224_in22k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_large_patch16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_large_patch16_224",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_large_patch16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=1e-5,  **kwargs)\n    model = _create_beit('beit_large_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_large_patch16_384(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=384, patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_large_patch16_384",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_large_patch16_384(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=384, patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=1e-5, **kwargs)\n    model = _create_beit('beit_large_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_large_patch16_512(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=512, patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_large_patch16_512",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_large_patch16_512(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        img_size=512, patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=1e-5, **kwargs)\n    model = _create_beit('beit_large_patch16_512', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef beit_large_patch16_224_in22k(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "beit_large_patch16_224_in22k",
        "kind": 2,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "def beit_large_patch16_224_in22k(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=1024, depth=24, num_heads=16, mlp_ratio=4, qkv_bias=True,\n        use_abs_pos_emb=False, use_rel_pos_bias=True, init_values=1e-5,  **kwargs)\n    model = _create_beit('beit_large_patch16_224_in22k', pretrained=pretrained, **model_kwargs)\n    return model",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.beit",
        "description": "timm.models.beit",
        "peekOfCode": "default_cfgs = {\n    'beit_base_patch16_224': _cfg(\n        url='https://unilm.blob.core.windows.net/beit/beit_base_patch16_224_pt22k_ft22kto1k.pth'),\n    'beit_base_patch16_384': _cfg(\n        url='https://unilm.blob.core.windows.net/beit/beit_base_patch16_384_pt22k_ft22kto1k.pth',\n        input_size=(3, 384, 384), crop_pct=1.0,\n    ),\n    'beit_base_patch16_224_in22k': _cfg(\n        url='https://unilm.blob.core.windows.net/beit/beit_base_patch16_224_pt22k_ft22k.pth',\n        num_classes=21841,",
        "detail": "timm.models.beit",
        "documentation": {}
    },
    {
        "label": "botnet26t_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def botnet26t_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ ResNet26-T backbone.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('botnet26t_256', 'botnet26t', pretrained=pretrained, **kwargs)\n@register_model\ndef sebotnet33ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU,\n    \"\"\"\n    return _create_byoanet('sebotnet33ts_256', 'sebotnet33ts', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "sebotnet33ts_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def sebotnet33ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU,\n    \"\"\"\n    return _create_byoanet('sebotnet33ts_256', 'sebotnet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef botnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ ResNet50-T backbone, silu act.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('botnet50ts_256', 'botnet50ts', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "botnet50ts_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def botnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ ResNet50-T backbone, silu act.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('botnet50ts_256', 'botnet50ts', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_botnext26ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ ResNet26-T backbone, silu act.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "eca_botnext26ts_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def eca_botnext26ts_256(pretrained=False, **kwargs):\n    \"\"\" Bottleneck Transformer w/ ResNet26-T backbone, silu act.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('eca_botnext26ts_256', 'eca_botnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef halonet_h1(pretrained=False, **kwargs):\n    \"\"\" HaloNet-H1. Halo attention in all stages as per the paper.\n    NOTE: This runs very slowly!\n    \"\"\"",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "halonet_h1",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def halonet_h1(pretrained=False, **kwargs):\n    \"\"\" HaloNet-H1. Halo attention in all stages as per the paper.\n    NOTE: This runs very slowly!\n    \"\"\"\n    return _create_byoanet('halonet_h1', pretrained=pretrained, **kwargs)\n@register_model\ndef halonet26t(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet26-t backbone. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('halonet26t', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "halonet26t",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def halonet26t(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet26-t backbone. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('halonet26t', pretrained=pretrained, **kwargs)\n@register_model\ndef sehalonet33ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU, 1-2 Halo in stage 2,3,4.\n    \"\"\"\n    return _create_byoanet('sehalonet33ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "sehalonet33ts",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def sehalonet33ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet33-t backbone, SE attn for non Halo blocks, SiLU, 1-2 Halo in stage 2,3,4.\n    \"\"\"\n    return _create_byoanet('sehalonet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef halonet50ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet50-t backbone, silu act. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('halonet50ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "halonet50ts",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def halonet50ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet50-t backbone, silu act. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('halonet50ts', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_halonext26ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet26-t backbone, silu act. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('eca_halonext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "eca_halonext26ts",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def eca_halonext26ts(pretrained=False, **kwargs):\n    \"\"\" HaloNet w/ a ResNet26-t backbone, silu act. Halo attention in final two stages\n    \"\"\"\n    return _create_byoanet('eca_halonext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef lambda_resnet26t(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-26-T. Lambda layers w/ conv pos in last two stages.\n    \"\"\"\n    return _create_byoanet('lambda_resnet26t', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "lambda_resnet26t",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def lambda_resnet26t(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-26-T. Lambda layers w/ conv pos in last two stages.\n    \"\"\"\n    return _create_byoanet('lambda_resnet26t', pretrained=pretrained, **kwargs)\n@register_model\ndef lambda_resnet50ts(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-50-TS. SiLU act. Lambda layers w/ conv pos in last two stages.\n    \"\"\"\n    return _create_byoanet('lambda_resnet50ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "lambda_resnet50ts",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def lambda_resnet50ts(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-50-TS. SiLU act. Lambda layers w/ conv pos in last two stages.\n    \"\"\"\n    return _create_byoanet('lambda_resnet50ts', pretrained=pretrained, **kwargs)\n@register_model\ndef lambda_resnet26rpt_256(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-26-R-T. Lambda layers w/ rel pos embed in last two stages.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('lambda_resnet26rpt_256', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "lambda_resnet26rpt_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def lambda_resnet26rpt_256(pretrained=False, **kwargs):\n    \"\"\" Lambda-ResNet-26-R-T. Lambda layers w/ rel pos embed in last two stages.\n    \"\"\"\n    kwargs.setdefault('img_size', 256)\n    return _create_byoanet('lambda_resnet26rpt_256', pretrained=pretrained, **kwargs)\n@register_model\ndef haloregnetz_b(pretrained=False, **kwargs):\n    \"\"\" Halo + RegNetZ\n    \"\"\"\n    return _create_byoanet('haloregnetz_b', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "haloregnetz_b",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def haloregnetz_b(pretrained=False, **kwargs):\n    \"\"\" Halo + RegNetZ\n    \"\"\"\n    return _create_byoanet('haloregnetz_b', pretrained=pretrained, **kwargs)\n@register_model\ndef lamhalobotnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Combo Attention (Lambda + Halo + Bot) Network\n    \"\"\"\n    return _create_byoanet('lamhalobotnet50ts_256', 'lamhalobotnet50ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "lamhalobotnet50ts_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def lamhalobotnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Combo Attention (Lambda + Halo + Bot) Network\n    \"\"\"\n    return _create_byoanet('lamhalobotnet50ts_256', 'lamhalobotnet50ts', pretrained=pretrained, **kwargs)\n@register_model\ndef halo2botnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Combo Attention (Halo + Halo + Bot) Network\n    \"\"\"\n    return _create_byoanet('halo2botnet50ts_256', 'halo2botnet50ts', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "halo2botnet50ts_256",
        "kind": 2,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "def halo2botnet50ts_256(pretrained=False, **kwargs):\n    \"\"\" Combo Attention (Halo + Halo + Bot) Network\n    \"\"\"\n    return _create_byoanet('halo2botnet50ts_256', 'halo2botnet50ts', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "__all__ = []\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.95, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.conv1.conv', 'classifier': 'head.fc',\n        'fixed_input_size': False, 'min_input_size': (3, 224, 224),\n        **kwargs\n    }",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "default_cfgs = {\n    # GPU-Efficient (ResNet) weights\n    'botnet26t_256': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/botnet26t_c1_256-167a0e9f.pth',\n        fixed_input_size=True, input_size=(3, 256, 256), pool_size=(8, 8)),\n    'sebotnet33ts_256': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/sebotnet33ts_a1h2_256-957e3c3e.pth',\n        fixed_input_size=True, input_size=(3, 256, 256), pool_size=(8, 8), crop_pct=0.94),\n    'botnet50ts_256': _cfg(\n        url='',",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.byoanet",
        "description": "timm.models.byoanet",
        "peekOfCode": "model_cfgs = dict(\n    botnet26t=ByoModelCfg(\n        blocks=(\n            ByoBlockCfg(type='bottle', d=2, c=256, s=1, gs=0, br=0.25),\n            ByoBlockCfg(type='bottle', d=2, c=512, s=2, gs=0, br=0.25),\n            interleave_blocks(types=('bottle', 'self_attn'), d=2, c=1024, s=2, gs=0, br=0.25),\n            ByoBlockCfg(type='self_attn', d=2, c=2048, s=2, gs=0, br=0.25),\n        ),\n        stem_chs=64,\n        stem_type='tiered',",
        "detail": "timm.models.byoanet",
        "documentation": {}
    },
    {
        "label": "ByoBlockCfg",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class ByoBlockCfg:\n    type: Union[str, nn.Module]\n    d: int  # block depth (number of block repeats in stage)\n    c: int  # number of output channels for each block in stage\n    s: int = 2  # stride of stage (first block)\n    gs: Optional[Union[int, Callable]] = None  # group-size of blocks in stage, conv is depthwise if gs == 1\n    br: float = 1.  # bottleneck-ratio of blocks in stage\n    # NOTE: these config items override the model cfgs that are applied to all blocks by default\n    attn_layer: Optional[str] = None\n    attn_kwargs: Optional[Dict[str, Any]] = None",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "ByoModelCfg",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class ByoModelCfg:\n    blocks: Tuple[Union[ByoBlockCfg, Tuple[ByoBlockCfg, ...]], ...]\n    downsample: str = 'conv1x1'\n    stem_type: str = '3x3'\n    stem_pool: Optional[str] = 'maxpool'\n    stem_chs: int = 32\n    width_factor: float = 1.0\n    num_features: int = 0  # num out_channels for final conv, no final 1x1 conv if 0\n    zero_init_last: bool = True  # zero init last weight (usually bn) in residual path\n    fixed_input_size: bool = False  # model constrained to a fixed-input size / img_size must be provided on creation",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "LayerFn",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class LayerFn:\n    conv_norm_act: Callable = ConvBnAct\n    norm_act: Callable = BatchNormAct2d\n    act: Callable = nn.ReLU\n    attn: Optional[Callable] = None\n    self_attn: Optional[Callable] = None\nclass DownsampleAvg(nn.Module):\n    def __init__(self, in_chs, out_chs, stride=1, dilation=1, apply_act=False, layers: LayerFn = None):\n        \"\"\" AvgPool Downsampling as in 'D' ResNet variants.\"\"\"\n        super(DownsampleAvg, self).__init__()",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "DownsampleAvg",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class DownsampleAvg(nn.Module):\n    def __init__(self, in_chs, out_chs, stride=1, dilation=1, apply_act=False, layers: LayerFn = None):\n        \"\"\" AvgPool Downsampling as in 'D' ResNet variants.\"\"\"\n        super(DownsampleAvg, self).__init__()\n        layers = layers or LayerFn()\n        avg_stride = stride if dilation == 1 else 1\n        if stride > 1 or dilation > 1:\n            avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n            self.pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)\n        else:",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class BasicBlock(nn.Module):\n    \"\"\" ResNet Basic Block - kxk + kxk\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), group_size=None, bottle_ratio=1.0,\n            downsample='avg', attn_last=True, linear_out=False, layers: LayerFn = None, drop_block=None,\n            drop_path_rate=0.):\n        super(BasicBlock, self).__init__()\n        layers = layers or LayerFn()\n        mid_chs = make_divisible(out_chs * bottle_ratio)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "BottleneckBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class BottleneckBlock(nn.Module):\n    \"\"\" ResNet-like Bottleneck Block - 1x1 - kxk - 1x1\n    \"\"\"\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), bottle_ratio=1., group_size=None,\n                 downsample='avg', attn_last=False, linear_out=False, extra_conv=False, bottle_in=False,\n                 layers: LayerFn = None, drop_block=None, drop_path_rate=0.):\n        super(BottleneckBlock, self).__init__()\n        layers = layers or LayerFn()\n        mid_chs = make_divisible((in_chs if bottle_in else out_chs) * bottle_ratio)\n        groups = num_groups(group_size, mid_chs)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "DarkBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class DarkBlock(nn.Module):\n    \"\"\" DarkNet-like (1x1 + 3x3 w/ stride) block\n    The GE-Net impl included a 1x1 + 3x3 block in their search space. It was not used in the feature models.\n    This block is pretty much a DarkNet block (also DenseNet) hence the name. Neither DarkNet or DenseNet\n    uses strides within the block (external 3x3 or maxpool downsampling is done in front of the block repeats).\n    If one does want to use a lot of these blocks w/ stride, I'd recommend using the EdgeBlock (3x3 /w stride + 1x1)\n    for more optimal compute.\n    \"\"\"\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), bottle_ratio=1.0, group_size=None,\n                 downsample='avg', attn_last=True, linear_out=False, layers: LayerFn = None, drop_block=None,",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "EdgeBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class EdgeBlock(nn.Module):\n    \"\"\" EdgeResidual-like (3x3 + 1x1) block\n    A two layer block like DarkBlock, but with the order of the 3x3 and 1x1 convs reversed.\n    Very similar to the EfficientNet Edge-Residual block but this block it ends with activations, is\n    intended to be used with either expansion or bottleneck contraction, and can use DW/group/non-grouped convs.\n    FIXME is there a more common 3x3 + 1x1 conv block to name this after?\n    \"\"\"\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), bottle_ratio=1.0, group_size=None,\n                 downsample='avg', attn_last=False, linear_out=False, layers: LayerFn = None,\n                 drop_block=None, drop_path_rate=0.):",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "RepVggBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class RepVggBlock(nn.Module):\n    \"\"\" RepVGG Block.\n    Adapted from impl at https://github.com/DingXiaoH/RepVGG\n    This version does not currently support the deploy optimization. It is currently fixed in 'train' mode.\n    \"\"\"\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), bottle_ratio=1.0, group_size=None,\n                 downsample='', layers: LayerFn = None, drop_block=None, drop_path_rate=0.):\n        super(RepVggBlock, self).__init__()\n        layers = layers or LayerFn()\n        groups = num_groups(group_size, in_chs)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "SelfAttnBlock",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class SelfAttnBlock(nn.Module):\n    \"\"\" ResNet-like Bottleneck Block - 1x1 - optional kxk - self attn - 1x1\n    \"\"\"\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=1, dilation=(1, 1), bottle_ratio=1., group_size=None,\n                 downsample='avg', extra_conv=False, linear_out=False, bottle_in=False, post_attn_na=True,\n                 feat_size=None, layers: LayerFn = None, drop_block=None, drop_path_rate=0.):\n        super(SelfAttnBlock, self).__init__()\n        assert layers is not None\n        mid_chs = make_divisible((in_chs if bottle_in else out_chs) * bottle_ratio)\n        groups = num_groups(group_size, mid_chs)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "Stem",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class Stem(nn.Sequential):\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=4, pool='maxpool',\n                 num_rep=3, num_act=None, chs_decay=0.5, layers: LayerFn = None):\n        super().__init__()\n        assert stride in (2, 4)\n        layers = layers or LayerFn()\n        if isinstance(out_chs, (list, tuple)):\n            num_rep = len(out_chs)\n            stem_chs = out_chs\n        else:",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "ByobNet",
        "kind": 6,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "class ByobNet(nn.Module):\n    \"\"\" 'Bring-your-own-blocks' Net\n    A flexible network backbone that allows building model stem + blocks via\n    dataclass cfg definition w/ factory functions for module instantiation.\n    Current assumption is that both stem and blocks are in conv-bn-act order (w/ block ending in act).\n    \"\"\"\n    def __init__(self, cfg: ByoModelCfg, num_classes=1000, in_chans=3, global_pool='avg', output_stride=32,\n                 zero_init_last=True, img_size=None, drop_rate=0., drop_path_rate=0.):\n        super().__init__()\n        self.num_classes = num_classes",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "interleave_blocks",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def interleave_blocks(\n        types: Tuple[str, str], d, every: Union[int, List[int]] = 1, first: bool = False, **kwargs\n) -> Tuple[ByoBlockCfg]:\n    \"\"\" interleave 2 block types in stack\n    \"\"\"\n    assert len(types) == 2\n    if isinstance(every, int):\n        every = list(range(0 if first else every, d, every + 1))\n        if not every:\n            every = [d - 1]",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gernet_l",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gernet_l(pretrained=False, **kwargs):\n    \"\"\" GEResNet-Large (GENet-Large from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"\n    return _create_byobnet('gernet_l', pretrained=pretrained, **kwargs)\n@register_model\ndef gernet_m(pretrained=False, **kwargs):\n    \"\"\" GEResNet-Medium (GENet-Normal from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gernet_m",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gernet_m(pretrained=False, **kwargs):\n    \"\"\" GEResNet-Medium (GENet-Normal from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"\n    return _create_byobnet('gernet_m', pretrained=pretrained, **kwargs)\n@register_model\ndef gernet_s(pretrained=False, **kwargs):\n    \"\"\" EResNet-Small (GENet-Small from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gernet_s",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gernet_s(pretrained=False, **kwargs):\n    \"\"\" EResNet-Small (GENet-Small from official impl)\n    `Neural Architecture Design for GPU-Efficient Networks` - https://arxiv.org/abs/2006.14090\n    \"\"\"\n    return _create_byobnet('gernet_s', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_a2(pretrained=False, **kwargs):\n    \"\"\" RepVGG-A2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_a2",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_a2(pretrained=False, **kwargs):\n    \"\"\" RepVGG-A2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_a2', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b0(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B0\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b0",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b0(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B0\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b0', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b1(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B1\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b1",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b1(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B1\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b1', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b1g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B1g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b1g4",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b1g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B1g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b1g4', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b2(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b2",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b2(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B2\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b2', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b2g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B2g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b2g4",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b2g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B2g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b2g4', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b3(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B3\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b3",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b3(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B3\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b3', pretrained=pretrained, **kwargs)\n@register_model\ndef repvgg_b3g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B3g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "repvgg_b3g4",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def repvgg_b3g4(pretrained=False, **kwargs):\n    \"\"\" RepVGG-B3g4\n    `Making VGG-style ConvNets Great Again` - https://arxiv.org/abs/2101.03697\n    \"\"\"\n    return _create_byobnet('repvgg_b3g4', pretrained=pretrained, **kwargs)\n@register_model\ndef resnet51q(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet51q', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "resnet51q",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def resnet51q(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet51q', pretrained=pretrained, **kwargs)\n@register_model\ndef resnet61q(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet61q', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "resnet61q",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def resnet61q(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet61q', pretrained=pretrained, **kwargs)\n@register_model\ndef resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "resnext26ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef gcresnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gcresnext26ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gcresnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef seresnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('seresnext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "seresnext26ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def seresnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('seresnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('eca_resnext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "eca_resnext26ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def eca_resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('eca_resnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef bat_resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('bat_resnext26ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "bat_resnext26ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def bat_resnext26ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('bat_resnext26ts', pretrained=pretrained, **kwargs)\n@register_model\ndef resnet32ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet32ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "resnet32ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def resnet32ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet32ts', pretrained=pretrained, **kwargs)\n@register_model\ndef resnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet33ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "resnet33ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def resnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('resnet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef gcresnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnet33ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gcresnet33ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gcresnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef seresnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('seresnet33ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "seresnet33ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def seresnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('seresnet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_resnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('eca_resnet33ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "eca_resnet33ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def eca_resnet33ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('eca_resnet33ts', pretrained=pretrained, **kwargs)\n@register_model\ndef gcresnet50t(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnet50t', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gcresnet50t",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gcresnet50t(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnet50t', pretrained=pretrained, **kwargs)\n@register_model\ndef gcresnext50ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnext50ts', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "gcresnext50ts",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def gcresnext50ts(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('gcresnext50ts', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_b16(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_b16', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_b16",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_b16(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_b16', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_c16(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_c16', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_c16",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_c16(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_c16', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_d32(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d32', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_d32",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_d32(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d32', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_d8(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_d8",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_d8(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_e8(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_e8', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_e8",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_e8(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_e8', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_d8_evob(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8_evob', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_d8_evob",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_d8_evob(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8_evob', pretrained=pretrained, **kwargs)\n@register_model\ndef regnetz_d8_evos(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8_evos', pretrained=pretrained, **kwargs)\ndef expand_blocks_cfg(stage_blocks_cfg: Union[ByoBlockCfg, Sequence[ByoBlockCfg]]) -> List[ByoBlockCfg]:",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "regnetz_d8_evos",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def regnetz_d8_evos(pretrained=False, **kwargs):\n    \"\"\"\n    \"\"\"\n    return _create_byobnet('regnetz_d8_evos', pretrained=pretrained, **kwargs)\ndef expand_blocks_cfg(stage_blocks_cfg: Union[ByoBlockCfg, Sequence[ByoBlockCfg]]) -> List[ByoBlockCfg]:\n    if not isinstance(stage_blocks_cfg, Sequence):\n        stage_blocks_cfg = (stage_blocks_cfg,)\n    block_cfgs = []\n    for i, cfg in enumerate(stage_blocks_cfg):\n        block_cfgs += [replace(cfg, d=1) for _ in range(cfg.d)]",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "expand_blocks_cfg",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def expand_blocks_cfg(stage_blocks_cfg: Union[ByoBlockCfg, Sequence[ByoBlockCfg]]) -> List[ByoBlockCfg]:\n    if not isinstance(stage_blocks_cfg, Sequence):\n        stage_blocks_cfg = (stage_blocks_cfg,)\n    block_cfgs = []\n    for i, cfg in enumerate(stage_blocks_cfg):\n        block_cfgs += [replace(cfg, d=1) for _ in range(cfg.d)]\n    return block_cfgs\ndef num_groups(group_size, channels):\n    if not group_size:  # 0 or None\n        return 1  # normal conv with 1 group",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "num_groups",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def num_groups(group_size, channels):\n    if not group_size:  # 0 or None\n        return 1  # normal conv with 1 group\n    else:\n        # NOTE group_size == 1 -> depthwise conv\n        assert channels % group_size == 0\n        return channels // group_size\n@dataclass\nclass LayerFn:\n    conv_norm_act: Callable = ConvBnAct",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "create_shortcut",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def create_shortcut(downsample_type, layers: LayerFn, in_chs, out_chs, stride, dilation, **kwargs):\n    assert downsample_type in ('avg', 'conv1x1', '')\n    if in_chs != out_chs or stride != 1 or dilation[0] != dilation[1]:\n        if not downsample_type:\n            return None  # no shortcut\n        elif downsample_type == 'avg':\n            return DownsampleAvg(in_chs, out_chs, stride=stride, dilation=dilation[0], **kwargs)\n        else:\n            return layers.conv_norm_act(in_chs, out_chs, kernel_size=1, stride=stride, dilation=dilation[0], **kwargs)\n    else:",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "register_block",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def register_block(block_type:str, block_fn: nn.Module):\n    _block_registry[block_type] = block_fn\ndef create_block(block: Union[str, nn.Module], **kwargs):\n    if isinstance(block, (nn.Module, partial)):\n        return block(**kwargs)\n    assert block in _block_registry, f'Unknown block type ({block}'\n    return _block_registry[block](**kwargs)\nclass Stem(nn.Sequential):\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=4, pool='maxpool',\n                 num_rep=3, num_act=None, chs_decay=0.5, layers: LayerFn = None):",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "create_block",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def create_block(block: Union[str, nn.Module], **kwargs):\n    if isinstance(block, (nn.Module, partial)):\n        return block(**kwargs)\n    assert block in _block_registry, f'Unknown block type ({block}'\n    return _block_registry[block](**kwargs)\nclass Stem(nn.Sequential):\n    def __init__(self, in_chs, out_chs, kernel_size=3, stride=4, pool='maxpool',\n                 num_rep=3, num_act=None, chs_decay=0.5, layers: LayerFn = None):\n        super().__init__()\n        assert stride in (2, 4)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "create_byob_stem",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def create_byob_stem(in_chs, out_chs, stem_type='', pool_type='', feat_prefix='stem', layers: LayerFn = None):\n    layers = layers or LayerFn()\n    assert stem_type in ('', 'quad', 'quad2', 'tiered', 'deep', 'rep', '7x7', '3x3')\n    if 'quad' in stem_type:\n        # based on NFNet stem, stack of 4 3x3 convs\n        num_act = 2 if 'quad2' in stem_type else None\n        stem = Stem(in_chs, out_chs, num_rep=4, num_act=num_act, pool=pool_type, layers=layers)\n    elif 'tiered' in stem_type:\n        # 3x3 stack of 3 convs as in my ResNet-T\n        stem = Stem(in_chs, (3 * out_chs // 8, out_chs // 2, out_chs), pool=pool_type, layers=layers)",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "reduce_feat_size",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def reduce_feat_size(feat_size, stride=2):\n    return None if feat_size is None else tuple([s // stride for s in feat_size])\ndef override_kwargs(block_kwargs, model_kwargs):\n    \"\"\" Override model level attn/self-attn/block kwargs w/ block level\n    NOTE: kwargs are NOT merged across levels, block_kwargs will fully replace model_kwargs\n    for the block if set to anything that isn't None.\n    i.e. an empty block_kwargs dict will remove kwargs set at model level for that block\n    \"\"\"\n    out_kwargs = block_kwargs if block_kwargs is not None else model_kwargs\n    return out_kwargs or {}  # make sure None isn't returned",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "override_kwargs",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def override_kwargs(block_kwargs, model_kwargs):\n    \"\"\" Override model level attn/self-attn/block kwargs w/ block level\n    NOTE: kwargs are NOT merged across levels, block_kwargs will fully replace model_kwargs\n    for the block if set to anything that isn't None.\n    i.e. an empty block_kwargs dict will remove kwargs set at model level for that block\n    \"\"\"\n    out_kwargs = block_kwargs if block_kwargs is not None else model_kwargs\n    return out_kwargs or {}  # make sure None isn't returned\ndef update_block_kwargs(block_kwargs: Dict[str, Any], block_cfg: ByoBlockCfg, model_cfg: ByoModelCfg, ):\n    layer_fns = block_kwargs['layers']",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "update_block_kwargs",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def update_block_kwargs(block_kwargs: Dict[str, Any], block_cfg: ByoBlockCfg, model_cfg: ByoModelCfg, ):\n    layer_fns = block_kwargs['layers']\n    # override attn layer / args with block local config\n    attn_set = block_cfg.attn_layer is not None\n    if attn_set or block_cfg.attn_kwargs is not None:\n        # override attn layer config\n        if attn_set and not block_cfg.attn_layer:\n            # empty string for attn_layer type will disable attn for this block\n            attn_layer = None\n        else:",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "create_byob_stages",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def create_byob_stages(\n        cfg: ByoModelCfg, drop_path_rate: float, output_stride: int, stem_feat: Dict[str, Any],\n        feat_size: Optional[int] = None,\n        layers: Optional[LayerFn] = None,\n        block_kwargs_fn: Optional[Callable] = update_block_kwargs):\n    layers = layers or LayerFn()\n    feature_info = []\n    block_cfgs = [expand_blocks_cfg(s) for s in cfg.blocks]\n    depths = [sum([bc.d for bc in stage_bcs]) for stage_bcs in block_cfgs]\n    dpr = [x.tolist() for x in torch.linspace(0, drop_path_rate, sum(depths)).split(depths)]",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "get_layer_fns",
        "kind": 2,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "def get_layer_fns(cfg: ByoModelCfg):\n    act = get_act_layer(cfg.act_layer)\n    norm_act = convert_norm_act(norm_layer=cfg.norm_layer, act_layer=act)\n    conv_norm_act = partial(ConvBnAct, norm_layer=cfg.norm_layer, act_layer=act)\n    attn = partial(get_attn(cfg.attn_layer), **cfg.attn_kwargs) if cfg.attn_layer else None\n    self_attn = partial(get_attn(cfg.self_attn_layer), **cfg.self_attn_kwargs) if cfg.self_attn_layer else None\n    layer_fn = LayerFn(conv_norm_act=conv_norm_act, norm_act=norm_act, act=act, attn=attn, self_attn=self_attn)\n    return layer_fn\nclass ByobNet(nn.Module):\n    \"\"\" 'Bring-your-own-blocks' Net",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "__all__ = ['ByobNet', 'ByoModelCfg', 'ByoBlockCfg', 'create_byob_stem', 'create_block']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.conv', 'classifier': 'head.fc',\n        **kwargs\n    }\ndef _cfgr(url='', **kwargs):",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "default_cfgs = {\n    # GPU-Efficient (ResNet) weights\n    'gernet_s': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_s-756b4751.pth'),\n    'gernet_m': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_m-0873c53a.pth'),\n    'gernet_l': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_l-f31e2e8d.pth',\n        input_size=(3, 256, 256), pool_size=(8, 8)),\n    # RepVGG weights",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "model_cfgs = dict(\n    gernet_l=ByoModelCfg(\n        blocks=(\n            ByoBlockCfg(type='basic', d=1, c=128, s=2, gs=0, br=1.),\n            ByoBlockCfg(type='basic', d=2, c=192, s=2, gs=0, br=1.),\n            ByoBlockCfg(type='bottle', d=6, c=640, s=2, gs=0, br=1 / 4),\n            ByoBlockCfg(type='bottle', d=5, c=640, s=2, gs=1, br=3.),\n            ByoBlockCfg(type='bottle', d=4, c=640, s=1, gs=1, br=3.),\n        ),\n        stem_chs=32,",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "_block_registry",
        "kind": 5,
        "importPath": "timm.models.byobnet",
        "description": "timm.models.byobnet",
        "peekOfCode": "_block_registry = dict(\n    basic=BasicBlock,\n    bottle=BottleneckBlock,\n    dark=DarkBlock,\n    edge=EdgeBlock,\n    rep=RepVggBlock,\n    self_attn=SelfAttnBlock,\n)\ndef register_block(block_type:str, block_fn: nn.Module):\n    _block_registry[block_type] = block_fn",
        "detail": "timm.models.byobnet",
        "documentation": {}
    },
    {
        "label": "ClassAttn",
        "kind": 6,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "class ClassAttn(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    # with slight modifications to do CA \n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n        self.k = nn.Linear(dim, dim, bias=qkv_bias)",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "LayerScaleBlockClassAttn",
        "kind": 6,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "class LayerScaleBlockClassAttn(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    # with slight modifications to add CA and LayerScale\n    def __init__(\n            self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n            drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, attn_block=ClassAttn,\n            mlp_block=Mlp, init_values=1e-4):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = attn_block(",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "TalkingHeadAttn",
        "kind": 6,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "class TalkingHeadAttn(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    # with slight modifications to add Talking Heads Attention (https://arxiv.org/pdf/2003.02436v1.pdf)\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "LayerScaleBlock",
        "kind": 6,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "class LayerScaleBlock(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    # with slight modifications to add layerScale\n    def __init__(\n            self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n            drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, attn_block=TalkingHeadAttn,\n            mlp_block=Mlp, init_values=1e-4):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = attn_block(",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "Cait",
        "kind": 6,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "class Cait(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    # with slight modifications to adapt to our cait models\n    def __init__(\n            self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n            num_heads=12, mlp_ratio=4., qkv_bias=True, drop_rate=0., attn_drop_rate=0.,\n            drop_path_rate=0.,\n            norm_layer=partial(nn.LayerNorm, eps=1e-6),\n            global_pool=None,\n            block_layers=LayerScaleBlock,",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model=None):\n    if 'model' in state_dict:\n        state_dict = state_dict['model']\n    checkpoint_no_module = {}\n    for k, v in state_dict.items():\n        checkpoint_no_module[k.replace('module.', '')] = v\n    return checkpoint_no_module\ndef _create_cait(variant, pretrained=False, **kwargs):\n    if kwargs.get('features_only', None):\n        raise RuntimeError('features_only not implemented for Vision Transformer models.')",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_xxs24_224",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_xxs24_224(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=24, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_xxs24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=24, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_xxs24_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_xxs24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=24, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_xxs36_224(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=36, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs36_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_xxs36_224",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_xxs36_224(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=36, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs36_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_xxs36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=36, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_xxs36_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_xxs36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=192, depth=36, num_heads=4, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xxs36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_xs24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=288, depth=24, num_heads=6, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xs24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_xs24_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_xs24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=288, depth=24, num_heads=6, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_xs24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_s24_224(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=24, num_heads=8, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_s24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_s24_224",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_s24_224(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=24, num_heads=8, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_s24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_s24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=24, num_heads=8, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_s24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_s24_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_s24_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=24, num_heads=8, init_scale=1e-5, **kwargs)\n    model = _create_cait('cait_s24_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_s36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=36, num_heads=8, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_s36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_s36_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_s36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=384, depth=36, num_heads=8, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_s36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_m36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=768, depth=36, num_heads=16, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_m36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_m36_384",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_m36_384(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=768, depth=36, num_heads=16, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_m36_384', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef cait_m48_448(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=768, depth=48, num_heads=16, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_m48_448', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "cait_m48_448",
        "kind": 2,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "def cait_m48_448(pretrained=False, **kwargs):\n    model_args = dict(patch_size=16, embed_dim=768, depth=48, num_heads=16, init_scale=1e-6, **kwargs)\n    model = _create_cait('cait_m48_448', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "__all__ = ['Cait', 'ClassAttn', 'LayerScaleBlockClassAttn', 'LayerScaleBlock', 'TalkingHeadAttn']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 384, 384), 'pool_size': None,\n        'crop_pct': 1.0, 'interpolation': 'bicubic', 'fixed_input_size': True,\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n        **kwargs\n    }",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.cait",
        "description": "timm.models.cait",
        "peekOfCode": "default_cfgs = dict(\n    cait_xxs24_224=_cfg(\n        url='https://dl.fbaipublicfiles.com/deit/XXS24_224.pth',\n        input_size=(3, 224, 224),\n    ),\n    cait_xxs24_384=_cfg(\n        url='https://dl.fbaipublicfiles.com/deit/XXS24_384.pth',\n    ),\n    cait_xxs36_224=_cfg(\n        url='https://dl.fbaipublicfiles.com/deit/XXS36_224.pth',",
        "detail": "timm.models.cait",
        "documentation": {}
    },
    {
        "label": "ConvRelPosEnc",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class ConvRelPosEnc(nn.Module):\n    \"\"\" Convolutional relative position encoding. \"\"\"\n    def __init__(self, Ch, h, window):\n        \"\"\"\n        Initialization.\n            Ch: Channels per head.\n            h: Number of heads.\n            window: Window size(s) in convolutional relative positional encoding. It can have two forms:\n                1. An integer of window size, which assigns all attention heads with the same window s\n                    size in ConvRelPosEnc.",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "FactorAtt_ConvRelPosEnc",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class FactorAtt_ConvRelPosEnc(nn.Module):\n    \"\"\" Factorized attention with convolutional relative position encoding class. \"\"\"\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0., shared_crpe=None):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)  # Note: attn_drop is actually not used.\n        self.proj = nn.Linear(dim, dim)",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "ConvPosEnc",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class ConvPosEnc(nn.Module):\n    \"\"\" Convolutional Position Encoding. \n        Note: This module is similar to the conditional position encoding in CPVT.\n    \"\"\"\n    def __init__(self, dim, k=3):\n        super(ConvPosEnc, self).__init__()\n        self.proj = nn.Conv2d(dim, dim, k, 1, k//2, groups=dim) \n    def forward(self, x, size: Tuple[int, int]):\n        B, N, C = x.shape\n        H, W = size",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "SerialBlock",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class SerialBlock(nn.Module):\n    \"\"\" Serial block class.\n        Note: In this implementation, each serial block only contains a conv-attention and a FFN (MLP) module. \"\"\"\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, shared_cpe=None, shared_crpe=None):\n        super().__init__()\n        # Conv-Attention.\n        self.cpe = shared_cpe\n        self.norm1 = norm_layer(dim)\n        self.factoratt_crpe = FactorAtt_ConvRelPosEnc(",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "ParallelBlock",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class ParallelBlock(nn.Module):\n    \"\"\" Parallel block class. \"\"\"\n    def __init__(self, dims, num_heads, mlp_ratios=[], qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, shared_crpes=None):\n        super().__init__()\n        # Conv-Attention.\n        self.norm12 = norm_layer(dims[1])\n        self.norm13 = norm_layer(dims[2])\n        self.norm14 = norm_layer(dims[3])\n        self.factoratt_crpe2 = FactorAtt_ConvRelPosEnc(",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "CoaT",
        "kind": 6,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "class CoaT(nn.Module):\n    \"\"\" CoaT class. \"\"\"\n    def __init__(\n            self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dims=(0, 0, 0, 0), \n            serial_depths=(0, 0, 0, 0), parallel_depth=0, num_heads=0, mlp_ratios=(0, 0, 0, 0), qkv_bias=True,\n            drop_rate=0., attn_drop_rate=0., drop_path_rate=0., norm_layer=partial(nn.LayerNorm, eps=1e-6),\n            return_interm_layers=False, out_features=None, crpe_window=None, **kwargs):\n        super().__init__()\n        crpe_window = crpe_window or {3: 2, 5: 3, 7: 3}\n        self.return_interm_layers = return_interm_layers",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    out_dict = {}\n    for k, v in state_dict.items():\n        # original model had unused norm layers, removing them requires filtering pretrained checkpoints\n        if k.startswith('norm1') or \\\n                (model.norm2 is None and k.startswith('norm2')) or \\\n                (model.norm3 is None and k.startswith('norm3')):\n            continue\n        out_dict[k] = v\n    return out_dict",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "coat_tiny",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def coat_tiny(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[152, 152, 152, 152], serial_depths=[2, 2, 2, 2], parallel_depth=6,\n        num_heads=8, mlp_ratios=[4, 4, 4, 4], **kwargs)\n    model = _create_coat('coat_tiny', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef coat_mini(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[152, 216, 216, 216], serial_depths=[2, 2, 2, 2], parallel_depth=6,",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "coat_mini",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def coat_mini(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[152, 216, 216, 216], serial_depths=[2, 2, 2, 2], parallel_depth=6,\n        num_heads=8, mlp_ratios=[4, 4, 4, 4], **kwargs)\n    model = _create_coat('coat_mini', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef coat_lite_tiny(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 256, 320], serial_depths=[2, 2, 2, 2], parallel_depth=0,",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "coat_lite_tiny",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def coat_lite_tiny(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 256, 320], serial_depths=[2, 2, 2, 2], parallel_depth=0,\n        num_heads=8, mlp_ratios=[8, 8, 4, 4], **kwargs)\n    model = _create_coat('coat_lite_tiny', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef coat_lite_mini(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], serial_depths=[2, 2, 2, 2], parallel_depth=0,",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "coat_lite_mini",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def coat_lite_mini(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], serial_depths=[2, 2, 2, 2], parallel_depth=0,\n        num_heads=8, mlp_ratios=[8, 8, 4, 4], **kwargs)\n    model = _create_coat('coat_lite_mini', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef coat_lite_small(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], serial_depths=[3, 4, 6, 3], parallel_depth=0,",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "coat_lite_small",
        "kind": 2,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "def coat_lite_small(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], serial_depths=[3, 4, 6, 3], parallel_depth=0,\n        num_heads=8, mlp_ratios=[8, 8, 4, 4], **kwargs)\n    model = _create_coat('coat_lite_small', pretrained=pretrained, **model_cfg)\n    return model",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "__all__ = [\n    \"coat_tiny\",\n    \"coat_mini\",\n    \"coat_lite_tiny\",\n    \"coat_lite_mini\",\n    \"coat_lite_small\"\n]\ndef _cfg_coat(url='', **kwargs):\n    return {\n        'url': url,",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.coat",
        "description": "timm.models.coat",
        "peekOfCode": "default_cfgs = {\n    'coat_tiny': _cfg_coat(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_tiny-473c2a20.pth'\n    ),\n    'coat_mini': _cfg_coat(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_mini-2c6baf49.pth'\n    ),\n    'coat_lite_tiny': _cfg_coat(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_tiny-461b07a7.pth'\n    ),",
        "detail": "timm.models.coat",
        "documentation": {}
    },
    {
        "label": "GPSA",
        "kind": 6,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "class GPSA(nn.Module):\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.,\n                 locality_strength=1.):\n        super().__init__()\n        self.num_heads = num_heads\n        self.dim = dim\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.locality_strength = locality_strength\n        self.qk = nn.Linear(dim, dim * 2, bias=qkv_bias)",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "MHSA",
        "kind": 6,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "class MHSA(nn.Module):\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, use_gpsa=True, **kwargs):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.use_gpsa = use_gpsa\n        if self.use_gpsa:\n            self.attn = GPSA(\n                dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop, **kwargs)\n        else:",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "ConViT",
        "kind": 6,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "class ConViT(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n                 num_heads=12, mlp_ratio=4., qkv_bias=False, drop_rate=0., attn_drop_rate=0.,\n                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm, global_pool=None,\n                 local_up_to_layer=3, locality_strength=1., use_pos_embed=True):\n        super().__init__()\n        embed_dim *= num_heads\n        self.num_classes = num_classes",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "convit_tiny",
        "kind": 2,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "def convit_tiny(pretrained=False, **kwargs):\n    model_args = dict(\n        local_up_to_layer=10, locality_strength=1.0, embed_dim=48,\n        num_heads=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n    model = _create_convit(variant='convit_tiny', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convit_small(pretrained=False, **kwargs):\n    model_args = dict(\n        local_up_to_layer=10, locality_strength=1.0, embed_dim=48,",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "convit_small",
        "kind": 2,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "def convit_small(pretrained=False, **kwargs):\n    model_args = dict(\n        local_up_to_layer=10, locality_strength=1.0, embed_dim=48,\n        num_heads=9, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n    model = _create_convit(variant='convit_small', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convit_base(pretrained=False, **kwargs):\n    model_args = dict(\n        local_up_to_layer=10, locality_strength=1.0, embed_dim=48,",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "convit_base",
        "kind": 2,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "def convit_base(pretrained=False, **kwargs):\n    model_args = dict(\n        local_up_to_layer=10, locality_strength=1.0, embed_dim=48,\n        num_heads=16, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n    model = _create_convit(variant='convit_base', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.convit",
        "description": "timm.models.convit",
        "peekOfCode": "default_cfgs = {\n    # ConViT\n    'convit_tiny': _cfg(\n        url=\"https://dl.fbaipublicfiles.com/convit/convit_tiny.pth\"),\n    'convit_small': _cfg(\n        url=\"https://dl.fbaipublicfiles.com/convit/convit_small.pth\"),\n    'convit_base': _cfg(\n        url=\"https://dl.fbaipublicfiles.com/convit/convit_base.pth\")\n}\n@register_notrace_module  # reason: FX can't symbolically trace control flow in forward method",
        "detail": "timm.models.convit",
        "documentation": {}
    },
    {
        "label": "Residual",
        "kind": 6,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "class Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n    def forward(self, x):\n        return self.fn(x) + x\nclass ConvMixer(nn.Module):\n    def __init__(self, dim, depth, kernel_size=9, patch_size=7, in_chans=3, num_classes=1000, activation=nn.GELU, **kwargs):\n        super().__init__()\n        self.num_classes = num_classes",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "ConvMixer",
        "kind": 6,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "class ConvMixer(nn.Module):\n    def __init__(self, dim, depth, kernel_size=9, patch_size=7, in_chans=3, num_classes=1000, activation=nn.GELU, **kwargs):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_features = dim\n        self.head = nn.Linear(dim, num_classes) if num_classes > 0 else nn.Identity()\n        self.stem = nn.Sequential(\n            nn.Conv2d(in_chans, dim, kernel_size=patch_size, stride=patch_size),\n            activation(),\n            nn.BatchNorm2d(dim)",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "convmixer_1536_20",
        "kind": 2,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "def convmixer_1536_20(pretrained=False, **kwargs):\n    model_args = dict(dim=1536, depth=20, kernel_size=9, patch_size=7, **kwargs)\n    return _create_convmixer('convmixer_1536_20', pretrained, **model_args)\n@register_model\ndef convmixer_768_32(pretrained=False, **kwargs):\n    model_args = dict(dim=768, depth=32, kernel_size=7, patch_size=7, activation=nn.ReLU, **kwargs)\n    return _create_convmixer('convmixer_768_32', pretrained, **model_args)\n@register_model\ndef convmixer_1024_20_ks9_p14(pretrained=False, **kwargs):\n    model_args = dict(dim=1024, depth=20, kernel_size=9, patch_size=14, **kwargs)",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "convmixer_768_32",
        "kind": 2,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "def convmixer_768_32(pretrained=False, **kwargs):\n    model_args = dict(dim=768, depth=32, kernel_size=7, patch_size=7, activation=nn.ReLU, **kwargs)\n    return _create_convmixer('convmixer_768_32', pretrained, **model_args)\n@register_model\ndef convmixer_1024_20_ks9_p14(pretrained=False, **kwargs):\n    model_args = dict(dim=1024, depth=20, kernel_size=9, patch_size=14, **kwargs)\n    return _create_convmixer('convmixer_1024_20_ks9_p14', pretrained, **model_args)",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "convmixer_1024_20_ks9_p14",
        "kind": 2,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "def convmixer_1024_20_ks9_p14(pretrained=False, **kwargs):\n    model_args = dict(dim=1024, depth=20, kernel_size=9, patch_size=14, **kwargs)\n    return _create_convmixer('convmixer_1024_20_ks9_p14', pretrained, **model_args)",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.convmixer",
        "description": "timm.models.convmixer",
        "peekOfCode": "default_cfgs = {\n    'convmixer_1536_20': _cfg(url='https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1536_20_ks9_p7.pth.tar'),\n    'convmixer_768_32': _cfg(url='https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_768_32_ks7_p7_relu.pth.tar'),\n    'convmixer_1024_20_ks9_p14': _cfg(url='https://github.com/tmp-iclr/convmixer/releases/download/timm-v1.0/convmixer_1024_20_ks9_p14.pth.tar')\n}\nclass Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n    def forward(self, x):",
        "detail": "timm.models.convmixer",
        "documentation": {}
    },
    {
        "label": "LayerNorm2d",
        "kind": 6,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "class LayerNorm2d(nn.LayerNorm):\n    r\"\"\" LayerNorm for channels_first tensors with 2d spatial dimensions (ie N, C, H, W).\n    \"\"\"\n    def __init__(self, normalized_shape, eps=1e-6):\n        super().__init__(normalized_shape, eps=eps)\n    def forward(self, x) -> torch.Tensor:\n        if _is_contiguous(x):\n            return F.layer_norm(\n                x.permute(0, 2, 3, 1), self.normalized_shape, self.weight, self.bias, self.eps).permute(0, 3, 1, 2)\n        else:",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "ConvNeXtBlock",
        "kind": 6,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "class ConvNeXtBlock(nn.Module):\n    \"\"\" ConvNeXt Block\n    There are two equivalent implementations:\n      (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n      (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n    Unlike the official impl, this one allows choice of 1 or 2, 1x1 conv can be faster with appropriate\n    choice of LayerNorm impl, however as model size increases the tradeoffs appear to change and nn.Linear\n    is a better choice. This was observed with PyTorch 1.10 on 3090 GPU, it could change over time & w/ different HW.\n    Args:\n        dim (int): Number of input channels.",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "ConvNeXtStage",
        "kind": 6,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "class ConvNeXtStage(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=2, depth=2, dp_rates=None, ls_init_value=1.0, conv_mlp=False,\n            norm_layer=None, cl_norm_layer=None, cross_stage=False):\n        super().__init__()\n        if in_chs != out_chs or stride > 1:\n            self.downsample = nn.Sequential(\n                norm_layer(in_chs),\n                nn.Conv2d(in_chs, out_chs, kernel_size=stride, stride=stride),\n            )",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "ConvNeXt",
        "kind": 6,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "class ConvNeXt(nn.Module):\n    r\"\"\" ConvNeXt\n        A PyTorch impl of : `A ConvNet for the 2020s`  - https://arxiv.org/pdf/2201.03545.pdf\n    Args:\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n        dims (tuple(int)): Feature dimension at each stage. Default: [96, 192, 384, 768]\n        drop_rate (float): Head dropout rate\n        drop_path_rate (float): Stochastic depth rate. Default: 0.",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" Remap FB checkpoints -> timm \"\"\"\n    if 'model' in state_dict:\n        state_dict = state_dict['model']\n    out_dict = {}\n    import re\n    for k, v in state_dict.items():\n        k = k.replace('downsample_layers.0.', 'stem.')\n        k = re.sub(r'stages.([0-9]+).([0-9]+)', r'stages.\\1.blocks.\\2', k)\n        k = re.sub(r'downsample_layers.([0-9]+).([0-9]+)', r'stages.\\1.downsample.\\2', k)",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_tiny",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_tiny(pretrained=False, **kwargs):\n    model_args = dict(depths=(3, 3, 9, 3), dims=(96, 192, 384, 768), **kwargs)\n    model = _create_convnext('convnext_tiny', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_tiny_hnf(pretrained=False, **kwargs):\n    model_args = dict(depths=(3, 3, 9, 3), dims=(96, 192, 384, 768), head_norm_first=True, **kwargs)\n    model = _create_convnext('convnext_tiny_hnf', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_tiny_hnf",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_tiny_hnf(pretrained=False, **kwargs):\n    model_args = dict(depths=(3, 3, 9, 3), dims=(96, 192, 384, 768), head_norm_first=True, **kwargs)\n    model = _create_convnext('convnext_tiny_hnf', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_small(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n    model = _create_convnext('convnext_small', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_small",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_small(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n    model = _create_convnext('convnext_small', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_base(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_base",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_base(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_large(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_large",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_large(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_base_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_base_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_base_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_large_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_large_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_large_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_xlarge_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_xlarge_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_xlarge_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_base_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_base_384_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_base_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_large_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_large_384_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_large_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_xlarge_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_xlarge_384_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_xlarge_384_in22ft1k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_384_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_base_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_in22k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_base_in22k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_base_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n    model = _create_convnext('convnext_base_in22k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_large_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_in22k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_large_in22k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_large_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n    model = _create_convnext('convnext_large_in22k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef convnext_xlarge_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_in22k', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "convnext_xlarge_in22k",
        "kind": 2,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "def convnext_xlarge_in22k(pretrained=False, **kwargs):\n    model_args = dict(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n    model = _create_convnext('convnext_xlarge_in22k', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "__all__ = ['ConvNeXt']  # model_registry will add each entrypoint fn to this\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.0', 'classifier': 'head.fc',\n        **kwargs\n    }",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.convnext",
        "description": "timm.models.convnext",
        "peekOfCode": "default_cfgs = dict(\n    convnext_tiny=_cfg(url=\"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\"),\n    convnext_small=_cfg(url=\"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\"),\n    convnext_base=_cfg(url=\"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\"),\n    convnext_large=_cfg(url=\"https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth\"),\n    convnext_tiny_hnf=_cfg(url=''),\n    convnext_base_in22ft1k=_cfg(\n        url='https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth'),\n    convnext_large_in22ft1k=_cfg(\n        url='https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth'),",
        "detail": "timm.models.convnext",
        "documentation": {}
    },
    {
        "label": "PatchEmbed",
        "kind": 6,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "class PatchEmbed(nn.Module):\n    \"\"\" Image to Patch Embedding\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, multi_conv=False):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n        self.img_size = img_size\n        self.patch_size = patch_size",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "CrossAttention",
        "kind": 6,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "class CrossAttention(nn.Module):\n    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n        self.scale = qk_scale or head_dim ** -0.5\n        self.wq = nn.Linear(dim, dim, bias=qkv_bias)\n        self.wk = nn.Linear(dim, dim, bias=qkv_bias)\n        self.wv = nn.Linear(dim, dim, bias=qkv_bias)",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "CrossAttentionBlock",
        "kind": 6,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "class CrossAttentionBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = CrossAttention(\n            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n    def forward(self, x):",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "MultiScaleBlock",
        "kind": 6,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "class MultiScaleBlock(nn.Module):\n    def __init__(self, dim, patches, depth, num_heads, mlp_ratio, qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        num_branches = len(dim)\n        self.num_branches = num_branches\n        # different branch could have different embedding size, the first one is the base\n        self.blocks = nn.ModuleList()\n        for d in range(num_branches):\n            tmp = []",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "CrossViT",
        "kind": 6,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "class CrossViT(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    \"\"\"\n    def __init__(\n            self, img_size=224, img_scale=(1.0, 1.0), patch_size=(8, 16), in_chans=3, num_classes=1000,\n            embed_dim=(192, 384), depth=((1, 3, 1), (1, 3, 1), (1, 3, 1)), num_heads=(6, 12), mlp_ratio=(2., 2., 4.),\n            qkv_bias=True, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n            norm_layer=partial(nn.LayerNorm, eps=1e-6), multi_conv=False, crop_scale=False,\n    ):\n        super().__init__()",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "scale_image",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def scale_image(x, ss: Tuple[int, int], crop_scale: bool = False):  # annotations for torchscript\n    \"\"\"\n    Pulled out of CrossViT.forward_features to bury conditional logic in a leaf node for FX tracing.\n    Args:\n        x (Tensor): input image\n        ss (tuple[int, int]): height and width to scale to\n        crop_scale (bool): whether to crop instead of interpolate to achieve the desired scale. Defaults to False\n    Returns:\n        Tensor: the \"scaled\" image batch tensor\n    \"\"\"",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_tiny_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_tiny_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[96, 192], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],\n        num_heads=[3, 3], mlp_ratio=[4, 4, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_tiny_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_small_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_small_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_small_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],\n        num_heads=[6, 6], mlp_ratio=[4, 4, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_small_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_base_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[384, 768], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_base_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_base_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[384, 768], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],\n        num_heads=[12, 12], mlp_ratio=[4, 4, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_base_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_9_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_9_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_9_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],\n        num_heads=[4, 4], mlp_ratio=[3, 3, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_9_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_15_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_15_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_15_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],\n        num_heads=[6, 6], mlp_ratio=[3, 3, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_15_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_18_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_18_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_18_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],\n        num_heads=[7, 7], mlp_ratio=[3, 3, 1], **kwargs)\n    model = _create_crossvit(variant='crossvit_18_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_9_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_9_dagger_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_9_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],\n        num_heads=[4, 4], mlp_ratio=[3, 3, 1], multi_conv=True, **kwargs)\n    model = _create_crossvit(variant='crossvit_9_dagger_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_15_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_15_dagger_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_15_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],\n        num_heads=[6, 6], mlp_ratio=[3, 3, 1], multi_conv=True, **kwargs)\n    model = _create_crossvit(variant='crossvit_15_dagger_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_15_dagger_408(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_15_dagger_408",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_15_dagger_408(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],\n        num_heads=[6, 6], mlp_ratio=[3, 3, 1], multi_conv=True, **kwargs)\n    model = _create_crossvit(variant='crossvit_15_dagger_408', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_18_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_18_dagger_240",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_18_dagger_240(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],\n        num_heads=[7, 7], mlp_ratio=[3, 3, 1], multi_conv=True, **kwargs)\n    model = _create_crossvit(variant='crossvit_18_dagger_240', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef crossvit_18_dagger_408(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "crossvit_18_dagger_408",
        "kind": 2,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "def crossvit_18_dagger_408(pretrained=False, **kwargs):\n    model_args = dict(\n        img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],\n        num_heads=[7, 7], mlp_ratio=[3, 3, 1], multi_conv=True, **kwargs)\n    model = _create_crossvit(variant='crossvit_18_dagger_408', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.crossvit",
        "description": "timm.models.crossvit",
        "peekOfCode": "default_cfgs = {\n    'crossvit_15_240': _cfg(url='https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_224.pth'),\n    'crossvit_15_dagger_240': _cfg(\n        url='https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_224.pth',\n        first_conv=('patch_embed.0.proj.0', 'patch_embed.1.proj.0'),\n    ),\n    'crossvit_15_dagger_408': _cfg(\n        url='https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_384.pth',\n        input_size=(3, 408, 408), first_conv=('patch_embed.0.proj.0', 'patch_embed.1.proj.0'), crop_pct=1.0,\n    ),",
        "detail": "timm.models.crossvit",
        "documentation": {}
    },
    {
        "label": "ResBottleneck",
        "kind": 6,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "class ResBottleneck(nn.Module):\n    \"\"\" ResNe(X)t Bottleneck Block\n    \"\"\"\n    def __init__(self, in_chs, out_chs, dilation=1, bottle_ratio=0.25, groups=1,\n                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, attn_last=False,\n                 attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(ResBottleneck, self).__init__()\n        mid_chs = int(round(out_chs * bottle_ratio))\n        ckwargs = dict(act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer, drop_block=drop_block)\n        self.conv1 = ConvBnAct(in_chs, mid_chs, kernel_size=1, **ckwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "DarkBlock",
        "kind": 6,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "class DarkBlock(nn.Module):\n    \"\"\" DarkNet Block\n    \"\"\"\n    def __init__(self, in_chs, out_chs, dilation=1, bottle_ratio=0.5, groups=1,\n                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, attn_layer=None, aa_layer=None,\n                 drop_block=None, drop_path=None):\n        super(DarkBlock, self).__init__()\n        mid_chs = int(round(out_chs * bottle_ratio))\n        ckwargs = dict(act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer, drop_block=drop_block)\n        self.conv1 = ConvBnAct(in_chs, mid_chs, kernel_size=1, **ckwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "CrossStage",
        "kind": 6,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "class CrossStage(nn.Module):\n    \"\"\"Cross Stage.\"\"\"\n    def __init__(self, in_chs, out_chs, stride, dilation, depth, block_ratio=1., bottle_ratio=1., exp_ratio=1.,\n                 groups=1, first_dilation=None, down_growth=False, cross_linear=False, block_dpr=None,\n                 block_fn=ResBottleneck, **block_kwargs):\n        super(CrossStage, self).__init__()\n        first_dilation = first_dilation or dilation\n        down_chs = out_chs if down_growth else in_chs  # grow downsample channels to output channels\n        exp_chs = int(round(out_chs * exp_ratio))\n        block_out_chs = int(round(out_chs * block_ratio))",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "DarkStage",
        "kind": 6,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "class DarkStage(nn.Module):\n    \"\"\"DarkNet stage.\"\"\"\n    def __init__(self, in_chs, out_chs, stride, dilation, depth, block_ratio=1., bottle_ratio=1., groups=1,\n                 first_dilation=None, block_fn=ResBottleneck, block_dpr=None, **block_kwargs):\n        super(DarkStage, self).__init__()\n        first_dilation = first_dilation or dilation\n        self.conv_down = ConvBnAct(\n            in_chs, out_chs, kernel_size=3, stride=stride, dilation=first_dilation, groups=groups,\n            act_layer=block_kwargs.get('act_layer'), norm_layer=block_kwargs.get('norm_layer'),\n            aa_layer=block_kwargs.get('aa_layer', None))",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "CspNet",
        "kind": 6,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "class CspNet(nn.Module):\n    \"\"\"Cross Stage Partial base model.\n    Paper: `CSPNet: A New Backbone that can Enhance Learning Capability of CNN` - https://arxiv.org/abs/1911.11929\n    Ref Impl: https://github.com/WongKinYiu/CrossStagePartialNetworks\n    NOTE: There are differences in the way I handle the 1x1 'expansion' conv in this impl vs the\n    darknet impl. I did it this way for simplicity and less special cases.\n    \"\"\"\n    def __init__(self, cfg, in_chans=3, num_classes=1000, output_stride=32, global_pool='avg', drop_rate=0.,\n                 act_layer=nn.LeakyReLU, norm_layer=nn.BatchNorm2d, aa_layer=None, drop_path_rate=0.,\n                 zero_init_last_bn=True, stage_fn=CrossStage, block_fn=ResBottleneck):",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "create_stem",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def create_stem(\n        in_chans=3, out_chs=32, kernel_size=3, stride=2, pool='',\n        act_layer=None, norm_layer=None, aa_layer=None):\n    stem = nn.Sequential()\n    if not isinstance(out_chs, (tuple, list)):\n        out_chs = [out_chs]\n    assert len(out_chs)\n    in_c = in_chans\n    for i, out_c in enumerate(out_chs):\n        conv_name = f'conv{i + 1}'",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspresnet50",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspresnet50(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnet50d(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50d', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnet50w(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50w', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50(pretrained=False, **kwargs):",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspresnet50d",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspresnet50d(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50d', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnet50w(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50w', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnext50', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50_iabn(pretrained=False, **kwargs):",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspresnet50w",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspresnet50w(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnet50w', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnext50', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspresnext50_iabn', pretrained=pretrained, norm_layer=norm_layer, **kwargs)\n@register_model",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspresnext50",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspresnext50(pretrained=False, **kwargs):\n    return _create_cspnet('cspresnext50', pretrained=pretrained, **kwargs)\n@register_model\ndef cspresnext50_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspresnext50_iabn', pretrained=pretrained, norm_layer=norm_layer, **kwargs)\n@register_model\ndef cspdarknet53(pretrained=False, **kwargs):\n    return _create_cspnet('cspdarknet53', pretrained=pretrained, block_fn=DarkBlock, **kwargs)\n@register_model",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspresnext50_iabn",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspresnext50_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspresnext50_iabn', pretrained=pretrained, norm_layer=norm_layer, **kwargs)\n@register_model\ndef cspdarknet53(pretrained=False, **kwargs):\n    return _create_cspnet('cspdarknet53', pretrained=pretrained, block_fn=DarkBlock, **kwargs)\n@register_model\ndef cspdarknet53_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspdarknet53_iabn', pretrained=pretrained, block_fn=DarkBlock, norm_layer=norm_layer, **kwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspdarknet53",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspdarknet53(pretrained=False, **kwargs):\n    return _create_cspnet('cspdarknet53', pretrained=pretrained, block_fn=DarkBlock, **kwargs)\n@register_model\ndef cspdarknet53_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspdarknet53_iabn', pretrained=pretrained, block_fn=DarkBlock, norm_layer=norm_layer, **kwargs)\n@register_model\ndef darknet53(pretrained=False, **kwargs):\n    return _create_cspnet('darknet53', pretrained=pretrained, block_fn=DarkBlock, stage_fn=DarkStage, **kwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "cspdarknet53_iabn",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def cspdarknet53_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_cspnet('cspdarknet53_iabn', pretrained=pretrained, block_fn=DarkBlock, norm_layer=norm_layer, **kwargs)\n@register_model\ndef darknet53(pretrained=False, **kwargs):\n    return _create_cspnet('darknet53', pretrained=pretrained, block_fn=DarkBlock, stage_fn=DarkStage, **kwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "darknet53",
        "kind": 2,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "def darknet53(pretrained=False, **kwargs):\n    return _create_cspnet('darknet53', pretrained=pretrained, block_fn=DarkBlock, stage_fn=DarkStage, **kwargs)",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "__all__ = ['CspNet']  # model_registry will add each entrypoint fn to this\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 256, 256), 'pool_size': (8, 8),\n        'crop_pct': 0.887, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.conv1.conv', 'classifier': 'head.fc',\n        **kwargs\n    }",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "default_cfgs = {\n    'cspresnet50': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnet50_ra-d3e8d487.pth'),\n    'cspresnet50d': _cfg(url=''),\n    'cspresnet50w': _cfg(url=''),\n    'cspresnext50': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnext50_ra_224-648b4713.pth',\n        input_size=(3, 224, 224), pool_size=(7, 7), crop_pct=0.875  # FIXME I trained this at 224x224, not 256 like ref impl\n    ),\n    'cspresnext50_iabn': _cfg(url=''),",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.cspnet",
        "description": "timm.models.cspnet",
        "peekOfCode": "model_cfgs = dict(\n    cspresnet50=dict(\n        stem=dict(out_chs=64, kernel_size=7, stride=2, pool='max'),\n        stage=dict(\n            out_chs=(128, 256, 512, 1024),\n            depth=(3, 3, 5, 2),\n            stride=(1,) + (2,) * 3,\n            exp_ratio=(2.,) * 4,\n            bottle_ratio=(0.5,) * 4,\n            block_ratio=(1.,) * 4,",
        "detail": "timm.models.cspnet",
        "documentation": {}
    },
    {
        "label": "DenseLayer",
        "kind": 6,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "class DenseLayer(nn.Module):\n    def __init__(self, num_input_features, growth_rate, bn_size, norm_layer=BatchNormAct2d,\n                 drop_rate=0., memory_efficient=False):\n        super(DenseLayer, self).__init__()\n        self.add_module('norm1', norm_layer(num_input_features)),\n        self.add_module('conv1', nn.Conv2d(\n            num_input_features, bn_size * growth_rate, kernel_size=1, stride=1, bias=False)),\n        self.add_module('norm2', norm_layer(bn_size * growth_rate)),\n        self.add_module('conv2', nn.Conv2d(\n            bn_size * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)),",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "DenseBlock",
        "kind": 6,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "class DenseBlock(nn.ModuleDict):\n    _version = 2\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, norm_layer=nn.ReLU,\n                 drop_rate=0., memory_efficient=False):\n        super(DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = DenseLayer(\n                num_input_features + i * growth_rate,\n                growth_rate=growth_rate,\n                bn_size=bn_size,",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "DenseTransition",
        "kind": 6,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "class DenseTransition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features, norm_layer=nn.BatchNorm2d, aa_layer=None):\n        super(DenseTransition, self).__init__()\n        self.add_module('norm', norm_layer(num_input_features))\n        self.add_module('conv', nn.Conv2d(\n            num_input_features, num_output_features, kernel_size=1, stride=1, bias=False))\n        if aa_layer is not None:\n            self.add_module('pool', aa_layer(num_output_features, stride=2))\n        else:\n            self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "DenseNet",
        "kind": 6,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "class DenseNet(nn.Module):\n    r\"\"\"Densenet-BC model class, based on\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n    Args:\n        growth_rate (int) - how many filters to add each layer (`k` in paper)\n        block_config (list of 4 ints) - how many layers in each pooling block\n        bn_size (int) - multiplicative factor for number of bottle neck layers\n          (i.e. bn_size * k features in the bottleneck layer)\n        drop_rate (float) - dropout rate after each dense layer\n        num_classes (int) - number of classification classes",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet121",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet121(pretrained=False, **kwargs):\n    r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet121', growth_rate=32, block_config=(6, 12, 24, 16), pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenetblur121d(pretrained=False, **kwargs):\n    r\"\"\"Densenet-121 model from",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenetblur121d",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenetblur121d(pretrained=False, **kwargs):\n    r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenetblur121d', growth_rate=32, block_config=(6, 12, 24, 16), pretrained=pretrained, stem_type='deep',\n        aa_layer=BlurPool2d, **kwargs)\n    return model\n@register_model\ndef densenet121d(pretrained=False, **kwargs):",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet121d",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet121d(pretrained=False, **kwargs):\n    r\"\"\"Densenet-121 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet121d', growth_rate=32, block_config=(6, 12, 24, 16), stem_type='deep',\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenet169(pretrained=False, **kwargs):",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet169",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet169(pretrained=False, **kwargs):\n    r\"\"\"Densenet-169 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet169', growth_rate=32, block_config=(6, 12, 32, 32), pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenet201(pretrained=False, **kwargs):\n    r\"\"\"Densenet-201 model from",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet201",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet201(pretrained=False, **kwargs):\n    r\"\"\"Densenet-201 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet201', growth_rate=32, block_config=(6, 12, 48, 32), pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenet161(pretrained=False, **kwargs):\n    r\"\"\"Densenet-161 model from",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet161",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet161(pretrained=False, **kwargs):\n    r\"\"\"Densenet-161 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet161', growth_rate=48, block_config=(6, 12, 36, 24), pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenet264(pretrained=False, **kwargs):\n    r\"\"\"Densenet-264 model from",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet264",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet264(pretrained=False, **kwargs):\n    r\"\"\"Densenet-264 model from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'densenet264', growth_rate=48, block_config=(6, 12, 64, 48), pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef densenet264d_iabn(pretrained=False, **kwargs):\n    r\"\"\"Densenet-264 model with deep stem and Inplace-ABN",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "densenet264d_iabn",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def densenet264d_iabn(pretrained=False, **kwargs):\n    r\"\"\"Densenet-264 model with deep stem and Inplace-ABN\n    \"\"\"\n    def norm_act_fn(num_features, **kwargs):\n        return create_norm_act('iabn', num_features, **kwargs)\n    model = _create_densenet(\n        'densenet264d_iabn', growth_rate=48, block_config=(6, 12, 64, 48), stem_type='deep',\n        norm_layer=norm_act_fn, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "tv_densenet121",
        "kind": 2,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "def tv_densenet121(pretrained=False, **kwargs):\n    r\"\"\"Densenet-121 model with original Torchvision weights, from\n    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n    \"\"\"\n    model = _create_densenet(\n        'tv_densenet121', growth_rate=32, block_config=(6, 12, 24, 16), pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "__all__ = ['DenseNet']\ndef _cfg(url=''):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'features.conv0', 'classifier': 'classifier',\n    }\ndefault_cfgs = {\n    'densenet121': _cfg(",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.densenet",
        "description": "timm.models.densenet",
        "peekOfCode": "default_cfgs = {\n    'densenet121': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/densenet121_ra-50efcf5c.pth'),\n    'densenet121d': _cfg(url=''),\n    'densenetblur121d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/densenetblur121d_ra-100dcfbc.pth'),\n    'densenet169': _cfg(url='https://download.pytorch.org/models/densenet169-b2777c0a.pth'),\n    'densenet201': _cfg(url='https://download.pytorch.org/models/densenet201-c1103571.pth'),\n    'densenet161': _cfg(url='https://download.pytorch.org/models/densenet161-8d451a50.pth'),\n    'densenet264': _cfg(url=''),",
        "detail": "timm.models.densenet",
        "documentation": {}
    },
    {
        "label": "DlaBasic",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DlaBasic(nn.Module):\n    \"\"\"DLA Basic\"\"\"\n    def __init__(self, inplanes, planes, stride=1, dilation=1, **_):\n        super(DlaBasic, self).__init__()\n        self.conv1 = nn.Conv2d(\n            inplanes, planes, kernel_size=3, stride=stride, padding=dilation, bias=False, dilation=dilation)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=1, padding=dilation, bias=False, dilation=dilation)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "DlaBottleneck",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DlaBottleneck(nn.Module):\n    \"\"\"DLA/DLA-X Bottleneck\"\"\"\n    expansion = 2\n    def __init__(self, inplanes, outplanes, stride=1, dilation=1, cardinality=1, base_width=64):\n        super(DlaBottleneck, self).__init__()\n        self.stride = stride\n        mid_planes = int(math.floor(outplanes * (base_width / 64)) * cardinality)\n        mid_planes = mid_planes // self.expansion\n        self.conv1 = nn.Conv2d(inplanes, mid_planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(mid_planes)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "DlaBottle2neck",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DlaBottle2neck(nn.Module):\n    \"\"\" Res2Net/Res2NeXT DLA Bottleneck\n    Adapted from https://github.com/gasvn/Res2Net/blob/master/dla.py\n    \"\"\"\n    expansion = 2\n    def __init__(self, inplanes, outplanes, stride=1, dilation=1, scale=4, cardinality=8, base_width=4):\n        super(DlaBottle2neck, self).__init__()\n        self.is_first = stride > 1\n        self.scale = scale\n        mid_planes = int(math.floor(outplanes * (base_width / 64)) * cardinality)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "DlaRoot",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DlaRoot(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, shortcut):\n        super(DlaRoot, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, 1, stride=1, bias=False, padding=(kernel_size - 1) // 2)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.shortcut = shortcut\n    def forward(self, *x):\n        children = x",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "DlaTree",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DlaTree(nn.Module):\n    def __init__(self, levels, block, in_channels, out_channels, stride=1,\n                 dilation=1, cardinality=1, base_width=64,\n                 level_root=False, root_dim=0, root_kernel_size=1, root_shortcut=False):\n        super(DlaTree, self).__init__()\n        if root_dim == 0:\n            root_dim = 2 * out_channels\n        if level_root:\n            root_dim += in_channels\n        self.downsample = nn.MaxPool2d(stride, stride=stride) if stride > 1 else nn.Identity()",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "DLA",
        "kind": 6,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "class DLA(nn.Module):\n    def __init__(self, levels, channels, output_stride=32, num_classes=1000, in_chans=3,\n                 cardinality=1, base_width=64, block=DlaBottle2neck, shortcut_root=False,\n                 drop_rate=0.0, global_pool='avg'):\n        super(DLA, self).__init__()\n        self.channels = channels\n        self.num_classes = num_classes\n        self.cardinality = cardinality\n        self.base_width = base_width\n        self.drop_rate = drop_rate",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla60_res2net",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla60_res2net(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        levels=(1, 1, 1, 2, 3, 1), channels=(16, 32, 128, 256, 512, 1024),\n        block=DlaBottle2neck, cardinality=1, base_width=28, **kwargs)\n    return _create_dla('dla60_res2net', pretrained, **model_kwargs)\n@register_model\ndef dla60_res2next(pretrained=False,**kwargs):\n    model_kwargs = dict(\n        levels=(1, 1, 1, 2, 3, 1), channels=(16, 32, 128, 256, 512, 1024),\n        block=DlaBottle2neck, cardinality=8, base_width=4, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla60_res2next",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla60_res2next(pretrained=False,**kwargs):\n    model_kwargs = dict(\n        levels=(1, 1, 1, 2, 3, 1), channels=(16, 32, 128, 256, 512, 1024),\n        block=DlaBottle2neck, cardinality=8, base_width=4, **kwargs)\n    return _create_dla('dla60_res2next', pretrained, **model_kwargs)\n@register_model\ndef dla34(pretrained=False, **kwargs):  # DLA-34\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 128, 256, 512],\n        block=DlaBasic, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla34",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla34(pretrained=False, **kwargs):  # DLA-34\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 128, 256, 512],\n        block=DlaBasic, **kwargs)\n    return _create_dla('dla34', pretrained, **model_kwargs)\n@register_model\ndef dla46_c(pretrained=False, **kwargs):  # DLA-46-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla46_c",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla46_c(pretrained=False, **kwargs):  # DLA-46-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, **kwargs)\n    return _create_dla('dla46_c', pretrained, **model_kwargs)\n@register_model\ndef dla46x_c(pretrained=False, **kwargs):  # DLA-X-46-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla46x_c",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla46x_c(pretrained=False, **kwargs):  # DLA-X-46-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 2, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)\n    return _create_dla('dla46x_c', pretrained, **model_kwargs)\n@register_model\ndef dla60x_c(pretrained=False, **kwargs):  # DLA-X-60-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla60x_c",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla60x_c(pretrained=False, **kwargs):  # DLA-X-60-C\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 64, 64, 128, 256],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)\n    return _create_dla('dla60x_c', pretrained, **model_kwargs)\n@register_model\ndef dla60(pretrained=False, **kwargs):  # DLA-60\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla60",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla60(pretrained=False, **kwargs):  # DLA-60\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, **kwargs)\n    return _create_dla('dla60', pretrained, **model_kwargs)\n@register_model\ndef dla60x(pretrained=False, **kwargs):  # DLA-X-60\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla60x",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla60x(pretrained=False, **kwargs):  # DLA-X-60\n    model_kwargs = dict(\n        levels=[1, 1, 1, 2, 3, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=32, base_width=4, **kwargs)\n    return _create_dla('dla60x', pretrained, **model_kwargs)\n@register_model\ndef dla102(pretrained=False, **kwargs):  # DLA-102\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, shortcut_root=True, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla102",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla102(pretrained=False, **kwargs):  # DLA-102\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, shortcut_root=True, **kwargs)\n    return _create_dla('dla102', pretrained, **model_kwargs)\n@register_model\ndef dla102x(pretrained=False, **kwargs):  # DLA-X-102\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=32, base_width=4, shortcut_root=True, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla102x",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla102x(pretrained=False, **kwargs):  # DLA-X-102\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=32, base_width=4, shortcut_root=True, **kwargs)\n    return _create_dla('dla102x', pretrained, **model_kwargs)\n@register_model\ndef dla102x2(pretrained=False, **kwargs):  # DLA-X-102 64\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=64, base_width=4, shortcut_root=True, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla102x2",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla102x2(pretrained=False, **kwargs):  # DLA-X-102 64\n    model_kwargs = dict(\n        levels=[1, 1, 1, 3, 4, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, cardinality=64, base_width=4, shortcut_root=True, **kwargs)\n    return _create_dla('dla102x2', pretrained, **model_kwargs)\n@register_model\ndef dla169(pretrained=False, **kwargs):  # DLA-169\n    model_kwargs = dict(\n        levels=[1, 1, 2, 3, 5, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, shortcut_root=True, **kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "dla169",
        "kind": 2,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "def dla169(pretrained=False, **kwargs):  # DLA-169\n    model_kwargs = dict(\n        levels=[1, 1, 2, 3, 5, 1], channels=[16, 32, 128, 256, 512, 1024],\n        block=DlaBottleneck, shortcut_root=True, **kwargs)\n    return _create_dla('dla169', pretrained, **model_kwargs)",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "__all__ = ['DLA']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'base_layer.0', 'classifier': 'fc',\n        **kwargs\n    }",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.dla",
        "description": "timm.models.dla",
        "peekOfCode": "default_cfgs = {\n    'dla34': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla34-ba72cf86.pth'),\n    'dla46_c': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla46_c-2bfd52c3.pth'),\n    'dla46x_c': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla46x_c-d761bae7.pth'),\n    'dla60x_c': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla60x_c-b870c45c.pth'),\n    'dla60': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla60-24839fc4.pth'),\n    'dla60x': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla60x-d15cacda.pth'),\n    'dla102': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla102-d94d9790.pth'),\n    'dla102x': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla102x-ad62be81.pth'),\n    'dla102x2': _cfg(url='http://dl.yf.io/dla/models/imagenet/dla102x2-262837b6.pth'),",
        "detail": "timm.models.dla",
        "documentation": {}
    },
    {
        "label": "CatBnAct",
        "kind": 6,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "class CatBnAct(nn.Module):\n    def __init__(self, in_chs, norm_layer=BatchNormAct2d):\n        super(CatBnAct, self).__init__()\n        self.bn = norm_layer(in_chs, eps=0.001)\n    @torch.jit._overload_method  # noqa: F811\n    def forward(self, x):\n        # type: (Tuple[torch.Tensor, torch.Tensor]) -> (torch.Tensor)\n        pass\n    @torch.jit._overload_method  # noqa: F811\n    def forward(self, x):",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "BnActConv2d",
        "kind": 6,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "class BnActConv2d(nn.Module):\n    def __init__(self, in_chs, out_chs, kernel_size, stride, groups=1, norm_layer=BatchNormAct2d):\n        super(BnActConv2d, self).__init__()\n        self.bn = norm_layer(in_chs, eps=0.001)\n        self.conv = create_conv2d(in_chs, out_chs, kernel_size, stride=stride, groups=groups)\n    def forward(self, x):\n        return self.conv(self.bn(x))\nclass DualPathBlock(nn.Module):\n    def __init__(\n            self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, groups, block_type='normal', b=False):",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "DualPathBlock",
        "kind": 6,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "class DualPathBlock(nn.Module):\n    def __init__(\n            self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, groups, block_type='normal', b=False):\n        super(DualPathBlock, self).__init__()\n        self.num_1x1_c = num_1x1_c\n        self.inc = inc\n        self.b = b\n        if block_type == 'proj':\n            self.key_stride = 1\n            self.has_proj = True",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "DPN",
        "kind": 6,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "class DPN(nn.Module):\n    def __init__(self, small=False, num_init_features=64, k_r=96, groups=32,\n                 b=False, k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128), output_stride=32,\n                 num_classes=1000, in_chans=3, drop_rate=0., global_pool='avg', fc_act=nn.ELU):\n        super(DPN, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        self.b = b\n        assert output_stride == 32  # FIXME look into dilation support\n        norm_layer = partial(BatchNormAct2d, eps=.001)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn68",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn68(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        small=True, num_init_features=10, k_r=128, groups=32,\n        k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64), **kwargs)\n    return _create_dpn('dpn68', pretrained=pretrained, **model_kwargs)\n@register_model\ndef dpn68b(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        small=True, num_init_features=10, k_r=128, groups=32,\n        b=True, k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64), **kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn68b",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn68b(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        small=True, num_init_features=10, k_r=128, groups=32,\n        b=True, k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64), **kwargs)\n    return _create_dpn('dpn68b', pretrained=pretrained, **model_kwargs)\n@register_model\ndef dpn92(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=64, k_r=96, groups=32,\n        k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128), **kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn92",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn92(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=64, k_r=96, groups=32,\n        k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128), **kwargs)\n    return _create_dpn('dpn92', pretrained=pretrained, **model_kwargs)\n@register_model\ndef dpn98(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=96, k_r=160, groups=40,\n        k_sec=(3, 6, 20, 3), inc_sec=(16, 32, 32, 128), **kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn98",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn98(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=96, k_r=160, groups=40,\n        k_sec=(3, 6, 20, 3), inc_sec=(16, 32, 32, 128), **kwargs)\n    return _create_dpn('dpn98', pretrained=pretrained, **model_kwargs)\n@register_model\ndef dpn131(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=128, k_r=160, groups=40,\n        k_sec=(4, 8, 28, 3), inc_sec=(16, 32, 32, 128), **kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn131",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn131(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=128, k_r=160, groups=40,\n        k_sec=(4, 8, 28, 3), inc_sec=(16, 32, 32, 128), **kwargs)\n    return _create_dpn('dpn131', pretrained=pretrained, **model_kwargs)\n@register_model\ndef dpn107(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=128, k_r=200, groups=50,\n        k_sec=(4, 8, 20, 3), inc_sec=(20, 64, 64, 128), **kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "dpn107",
        "kind": 2,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "def dpn107(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        num_init_features=128, k_r=200, groups=50,\n        k_sec=(4, 8, 20, 3), inc_sec=(20, 64, 64, 128), **kwargs)\n    return _create_dpn('dpn107', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "__all__ = ['DPN']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DPN_MEAN, 'std': IMAGENET_DPN_STD,\n        'first_conv': 'features.conv1_1.conv', 'classifier': 'classifier',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.dpn",
        "description": "timm.models.dpn",
        "peekOfCode": "default_cfgs = {\n    'dpn68': _cfg(\n        url='https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn68-66bebafa7.pth'),\n    'dpn68b': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/dpn68b_ra-a31ca160.pth',\n        mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n    'dpn92': _cfg(\n        url='https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn92_extra-b040e4a9b.pth'),\n    'dpn98': _cfg(\n        url='https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn98-5b90dec4d.pth'),",
        "detail": "timm.models.dpn",
        "documentation": {}
    },
    {
        "label": "EfficientNet",
        "kind": 6,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "class EfficientNet(nn.Module):\n    \"\"\" (Generic) EfficientNet\n    A flexible and performant PyTorch implementation of efficient network architectures, including:\n      * EfficientNet-V2 Small, Medium, Large, XL & B0-B3\n      * EfficientNet B0-B8, L2\n      * EfficientNet-EdgeTPU\n      * EfficientNet-CondConv\n      * MixNet S, M, L, XL\n      * MnasNet A1, B1, and small\n      * MobileNet-V2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "EfficientNetFeatures",
        "kind": 6,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "class EfficientNetFeatures(nn.Module):\n    \"\"\" EfficientNet Feature Extractor\n    A work-in-progress feature extraction module for EfficientNet, to use as a backbone for segmentation\n    and object detection models.\n    \"\"\"\n    def __init__(self, block_args, out_indices=(0, 1, 2, 3, 4), feature_location='bottleneck', in_chans=3,\n                 stem_size=32, fix_stem=False, output_stride=32, pad_type='', round_chs_fn=round_channels,\n                 act_layer=None, norm_layer=None, se_layer=None, drop_rate=0., drop_path_rate=0.):\n        super(EfficientNetFeatures, self).__init__()\n        act_layer = act_layer or nn.ReLU",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_050",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_050(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 0.5. \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_075(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 0.75. \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_075",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_075(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 0.75. \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_100(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_100",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_100(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_b1(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"\n    return mnasnet_100(pretrained, **kwargs)\n@register_model\ndef mnasnet_140(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_b1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_b1(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1, depth multiplier of 1.0. \"\"\"\n    return mnasnet_100(pretrained, **kwargs)\n@register_model\ndef mnasnet_140(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1,  depth multiplier of 1.4 \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef semnasnet_050(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_140",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_140(pretrained=False, **kwargs):\n    \"\"\" MNASNet B1,  depth multiplier of 1.4 \"\"\"\n    model = _gen_mnasnet_b1('mnasnet_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef semnasnet_050(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 0.5 \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "semnasnet_050",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def semnasnet_050(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 0.5 \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef semnasnet_075(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE),  depth multiplier of 0.75. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "semnasnet_075",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def semnasnet_075(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE),  depth multiplier of 0.75. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef semnasnet_100(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "semnasnet_100",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def semnasnet_100(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_a1(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"\n    return semnasnet_100(pretrained, **kwargs)\n@register_model\ndef semnasnet_140(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_a1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_a1(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.0. \"\"\"\n    return semnasnet_100(pretrained, **kwargs)\n@register_model\ndef semnasnet_140(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.4. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_small(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "semnasnet_140",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def semnasnet_140(pretrained=False, **kwargs):\n    \"\"\" MNASNet A1 (w/ SE), depth multiplier of 1.4. \"\"\"\n    model = _gen_mnasnet_a1('semnasnet_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mnasnet_small(pretrained=False, **kwargs):\n    \"\"\" MNASNet Small,  depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_small('mnasnet_small', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mnasnet_small",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mnasnet_small(pretrained=False, **kwargs):\n    \"\"\" MNASNet Small,  depth multiplier of 1.0. \"\"\"\n    model = _gen_mnasnet_small('mnasnet_small', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_035(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.35 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_035', 0.35, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_035",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_035(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.35 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_035', 0.35, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_050(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.5 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_050",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_050(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.5 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.75 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_075",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 0.75 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.0 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_100",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.0 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_140(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.4 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_140",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_140(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.4 channel multiplier \"\"\"\n    model = _gen_mobilenet_v2('mobilenetv2_140', 1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_110d(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.1 channel, 1.2 depth multipliers\"\"\"\n    model = _gen_mobilenet_v2(\n        'mobilenetv2_110d', 1.1, depth_multiplier=1.2, fix_stem_head=True, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_110d",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_110d(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.1 channel, 1.2 depth multipliers\"\"\"\n    model = _gen_mobilenet_v2(\n        'mobilenetv2_110d', 1.1, depth_multiplier=1.2, fix_stem_head=True, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv2_120d(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.2 channel, 1.4 depth multipliers \"\"\"\n    model = _gen_mobilenet_v2(\n        'mobilenetv2_120d', 1.2, depth_multiplier=1.4, fix_stem_head=True, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mobilenetv2_120d",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mobilenetv2_120d(pretrained=False, **kwargs):\n    \"\"\" MobileNet V2 w/ 1.2 channel, 1.4 depth multipliers \"\"\"\n    model = _gen_mobilenet_v2(\n        'mobilenetv2_120d', 1.2, depth_multiplier=1.4, fix_stem_head=True, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef fbnetc_100(pretrained=False, **kwargs):\n    \"\"\" FBNet-C \"\"\"\n    if pretrained:\n        # pretrained model trained with non-default BN epsilon",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "fbnetc_100",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def fbnetc_100(pretrained=False, **kwargs):\n    \"\"\" FBNet-C \"\"\"\n    if pretrained:\n        # pretrained model trained with non-default BN epsilon\n        kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    model = _gen_fbnetc('fbnetc_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef spnasnet_100(pretrained=False, **kwargs):\n    \"\"\" Single-Path NAS Pixel1\"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "spnasnet_100",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def spnasnet_100(pretrained=False, **kwargs):\n    \"\"\" Single-Path NAS Pixel1\"\"\"\n    model = _gen_spnasnet('spnasnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b0",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b1', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b2', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b2a(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 @ 288x288 w/ 1.0 test crop\"\"\"\n    # WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b2a",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b2a(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 @ 288x288 w/ 1.0 test crop\"\"\"\n    # WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now\n    return efficientnet_b2(pretrained=pretrained, **kwargs)\n@register_model\ndef efficientnet_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b3",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b3a(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 @ 320x320 w/ 1.0 test crop-pct \"\"\"\n    # WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b3a",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b3a(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 @ 320x320 w/ 1.0 test crop-pct \"\"\"\n    # WARN this model def is deprecated, different train/test res + test crop handled by default_cfg now\n    return efficientnet_b3(pretrained=pretrained, **kwargs)\n@register_model\ndef efficientnet_b4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b4",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b5(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b5",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b5(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b5', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b6(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b6",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b6(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b6', channel_multiplier=1.8, depth_multiplier=2.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b7(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B7 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b7",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b7(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B7 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b7', channel_multiplier=2.0, depth_multiplier=3.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b8(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B8 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b8",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b8(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B8 \"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_b8', channel_multiplier=2.2, depth_multiplier=3.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_l2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-L2.\"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_l2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_l2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-L2.\"\"\"\n    # NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2\n    model = _gen_efficientnet(\n        'efficientnet_l2', channel_multiplier=4.3, depth_multiplier=5.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_es(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge Small. \"\"\"\n    model = _gen_efficientnet_edge(",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_es",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_es(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge Small. \"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_es', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_es_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge Small Pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_es_pruned', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_es_pruned",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_es_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge Small Pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_es_pruned', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_em(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Medium. \"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_em', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_em",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_em(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Medium. \"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_em', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_el(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large. \"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_el', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_el",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_el(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large. \"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_el', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_el_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_el_pruned', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_el_pruned",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_el_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large pruned. For more info: https://github.com/DeGirum/pruned-models/releases/tag/efficientnet_v1.0\"\"\"\n    model = _gen_efficientnet_edge(\n        'efficientnet_el_pruned', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_cc_b0_4e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_condconv(",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_cc_b0_4e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_cc_b0_4e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_condconv(\n        'efficientnet_cc_b0_4e', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_cc_b0_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_cc_b0_8e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_cc_b0_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 8 Experts \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_condconv(\n        'efficientnet_cc_b0_8e', channel_multiplier=1.0, depth_multiplier=1.0, experts_multiplier=2,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_cc_b1_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B1 w/ 8 Experts \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_cc_b1_8e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_cc_b1_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B1 w/ 8 Experts \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_condconv(\n        'efficientnet_cc_b1_8e', channel_multiplier=1.0, depth_multiplier=1.1, experts_multiplier=2,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_lite0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite0 \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_lite0",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_lite0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite0 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_lite(\n        'efficientnet_lite0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_lite1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite1 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_lite1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_lite1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite1 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    model = _gen_efficientnet_lite(\n        'efficientnet_lite1', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_lite2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite2 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_lite2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_lite2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite2 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    model = _gen_efficientnet_lite(\n        'efficientnet_lite2', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_lite3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite3 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_lite3",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_lite3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite3 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    model = _gen_efficientnet_lite(\n        'efficientnet_lite3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_lite4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite4 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_lite4",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_lite4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite4 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2\n    model = _gen_efficientnet_lite(\n        'efficientnet_lite4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b1_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b1_pruned",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b1_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    variant = 'efficientnet_b1_pruned'\n    model = _gen_efficientnet(\n        variant, channel_multiplier=1.0, depth_multiplier=1.1, pruned=True, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b2_pruned(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b2_pruned",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b2_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'efficientnet_b2_pruned', channel_multiplier=1.1, depth_multiplier=1.2, pruned=True,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnet_b3_pruned(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnet_b3_pruned",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnet_b3_pruned(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 Pruned. The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'efficientnet_b3_pruned', channel_multiplier=1.2, depth_multiplier=1.4, pruned=True,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_rw_t(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_rw_t",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_rw_t(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Tiny (Custom variant, tiny not in paper). \"\"\"\n    model = _gen_efficientnetv2_s(\n        'efficientnetv2_rw_t', channel_multiplier=0.8, depth_multiplier=0.9, rw=False, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef gc_efficientnetv2_rw_t(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Tiny w/ Global Context Attn (Custom variant, tiny not in paper). \"\"\"\n    model = _gen_efficientnetv2_s(\n        'gc_efficientnetv2_rw_t', channel_multiplier=0.8, depth_multiplier=0.9,",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "gc_efficientnetv2_rw_t",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def gc_efficientnetv2_rw_t(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Tiny w/ Global Context Attn (Custom variant, tiny not in paper). \"\"\"\n    model = _gen_efficientnetv2_s(\n        'gc_efficientnetv2_rw_t', channel_multiplier=0.8, depth_multiplier=0.9,\n        rw=False, se_layer='gc', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_rw_s(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small (RW variant).\n    NOTE: This is my initial (pre official code release) w/ some differences.",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_rw_s",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_rw_s(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small (RW variant).\n    NOTE: This is my initial (pre official code release) w/ some differences.\n    See efficientnetv2_s and tf_efficientnetv2_s for versions that match the official w/ PyTorch vs TF padding\n    \"\"\"\n    model = _gen_efficientnetv2_s('efficientnetv2_rw_s', rw=True, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_rw_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium (RW variant).",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_rw_m",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_rw_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium (RW variant).\n    \"\"\"\n    model = _gen_efficientnetv2_s(\n        'efficientnetv2_rw_m', channel_multiplier=1.2, depth_multiplier=(1.2,) * 4 + (1.6,) * 2, rw=True,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_s(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small. \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_s",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_s(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small. \"\"\"\n    model = _gen_efficientnetv2_s('efficientnetv2_s', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. \"\"\"\n    model = _gen_efficientnetv2_m('efficientnetv2_m', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_m",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. \"\"\"\n    model = _gen_efficientnetv2_m('efficientnetv2_m', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_l(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. \"\"\"\n    model = _gen_efficientnetv2_l('efficientnetv2_l', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_l",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_l(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. \"\"\"\n    model = _gen_efficientnetv2_l('efficientnetv2_l', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef efficientnetv2_xl(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large. \"\"\"\n    model = _gen_efficientnetv2_xl('efficientnetv2_xl', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "efficientnetv2_xl",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def efficientnetv2_xl(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large. \"\"\"\n    model = _gen_efficientnetv2_xl('efficientnetv2_xl', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b0",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b1', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b2', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b3",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b4",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b5(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b5",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b5(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b5', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b6(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b6",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b6(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b6', channel_multiplier=1.8, depth_multiplier=2.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b7(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b7",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b7(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B7. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b7', channel_multiplier=2.0, depth_multiplier=3.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b8(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b8",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b8(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B8. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b8', channel_multiplier=2.2, depth_multiplier=3.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b0_ap(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b0_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b0_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0 AdvProp. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b0_ap', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b1_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 AdvProp. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b1_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b1_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 AdvProp. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b1_ap', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b2_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 AdvProp. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b2_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b2_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 AdvProp. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b2_ap', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b3_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 AdvProp. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b3_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b3_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 AdvProp. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b3_ap', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b4_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 AdvProp. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b4_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b4_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 AdvProp. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b4_ap', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b5_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 AdvProp. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b5_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b5_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 AdvProp. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b5_ap', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b6_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 AdvProp. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b6_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b6_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 AdvProp. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b6_ap', channel_multiplier=1.8, depth_multiplier=2.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b7_ap(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b7_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b7_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B7 AdvProp. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b7_ap', channel_multiplier=2.0, depth_multiplier=3.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b8_ap(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b8_ap",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b8_ap(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B8 AdvProp. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b8_ap', channel_multiplier=2.2, depth_multiplier=3.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b0_ns(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b0_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b0_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B0 NoisyStudent. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b0_ns', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b1_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 NoisyStudent. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b1_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b1_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B1 NoisyStudent. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b1_ns', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b2_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 NoisyStudent. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b2_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b2_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B2 NoisyStudent. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b2_ns', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b3_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 NoisyStudent. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b3_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b3_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B3 NoisyStudent. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b3_ns', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b4_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 NoisyStudent. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b4_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b4_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B4 NoisyStudent. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b4_ns', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b5_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 NoisyStudent. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b5_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b5_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B5 NoisyStudent. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b5_ns', channel_multiplier=1.6, depth_multiplier=2.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b6_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 NoisyStudent. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b6_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b6_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B6 NoisyStudent. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b6_ns', channel_multiplier=1.8, depth_multiplier=2.6, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_b7_ns(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_b7_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_b7_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-B7 NoisyStudent. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_b7_ns', channel_multiplier=2.0, depth_multiplier=3.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_l2_ns_475(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_l2_ns_475",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_l2_ns_475(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-L2 NoisyStudent @ 475x475. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_l2_ns_475', channel_multiplier=4.3, depth_multiplier=5.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_l2_ns(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_l2_ns",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_l2_ns(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-L2 NoisyStudent. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.5\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet(\n        'tf_efficientnet_l2_ns', channel_multiplier=4.3, depth_multiplier=5.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_es(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_es",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_es(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge Small. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_edge(\n        'tf_efficientnet_es', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_em(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Medium. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_em",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_em(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Medium. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_edge(\n        'tf_efficientnet_em', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_el(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_el",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_el(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Edge-Large. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_edge(\n        'tf_efficientnet_el', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_cc_b0_4e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 4 Experts. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_cc_b0_4e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_cc_b0_4e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 4 Experts. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_condconv(\n        'tf_efficientnet_cc_b0_4e', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_cc_b0_8e(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_cc_b0_8e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_cc_b0_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B0 w/ 8 Experts. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_condconv(\n        'tf_efficientnet_cc_b0_8e', channel_multiplier=1.0, depth_multiplier=1.0, experts_multiplier=2,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_cc_b1_8e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_cc_b1_8e(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-CondConv-B1 w/ 8 Experts. Tensorflow compatible variant \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_condconv(\n        'tf_efficientnet_cc_b1_8e', channel_multiplier=1.0, depth_multiplier=1.1, experts_multiplier=2,\n        pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_lite0",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_lite0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite0 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_lite(\n        'tf_efficientnet_lite0', channel_multiplier=1.0, depth_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_lite1(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_lite1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_lite1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite1 \"\"\"\n    # NOTE for train, drop_rate should be 0.2, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_lite(\n        'tf_efficientnet_lite1', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_lite2(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_lite2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_lite2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite2 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_lite(\n        'tf_efficientnet_lite2', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_lite3(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_lite3",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_lite3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite3 \"\"\"\n    # NOTE for train, drop_rate should be 0.3, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_lite(\n        'tf_efficientnet_lite3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnet_lite4(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnet_lite4",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnet_lite4(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-Lite4 \"\"\"\n    # NOTE for train, drop_rate should be 0.4, drop_path_rate should be 0.2\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnet_lite(\n        'tf_efficientnet_lite4', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_s(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_s",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_s(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_s('tf_efficientnetv2_s', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_m",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_m(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_m('tf_efficientnetv2_m', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_l(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_l",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_l(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_l('tf_efficientnetv2_l', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_s_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_s_in21ft1k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_s_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_s('tf_efficientnetv2_s_in21ft1k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_m_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_m_in21ft1k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_m_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_m('tf_efficientnetv2_m_in21ft1k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_l_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_l_in21ft1k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_l_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_l('tf_efficientnetv2_l_in21ft1k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_xl_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_xl_in21ft1k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_xl_in21ft1k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large. Pretrained on ImageNet-21k, fine-tuned on 1k. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_xl('tf_efficientnetv2_xl_in21ft1k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_s_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small w/ ImageNet-21k pretrained weights. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_s_in21k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_s_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Small w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_s('tf_efficientnetv2_s_in21k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_m_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium w/ ImageNet-21k pretrained weights. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_m_in21k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_m_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Medium w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_m('tf_efficientnetv2_m_in21k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_l_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_l_in21k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_l_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_l('tf_efficientnetv2_l_in21k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_xl_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_xl_in21k",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_xl_in21k(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2 Xtra-Large w/ ImageNet-21k pretrained weights. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_xl('tf_efficientnetv2_xl_in21k', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B0. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_b0",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_b0(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B0. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_base('tf_efficientnetv2_b0', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B1. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_b1",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_b1(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B1. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_base(\n        'tf_efficientnetv2_b1', channel_multiplier=1.0, depth_multiplier=1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B2. Tensorflow compatible variant  \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_b2",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_b2(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B2. Tensorflow compatible variant  \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_base(\n        'tf_efficientnetv2_b2', channel_multiplier=1.1, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_efficientnetv2_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B3. Tensorflow compatible variant \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_efficientnetv2_b3",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_efficientnetv2_b3(pretrained=False, **kwargs):\n    \"\"\" EfficientNet-V2-B3. Tensorflow compatible variant \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_efficientnetv2_base(\n        'tf_efficientnetv2_b3', channel_multiplier=1.2, depth_multiplier=1.4, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mixnet_s(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Small model.",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mixnet_s",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mixnet_s(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Small model.\n    \"\"\"\n    model = _gen_mixnet_s(\n        'mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mixnet_m(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Medium model.\n    \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mixnet_m",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mixnet_m(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Medium model.\n    \"\"\"\n    model = _gen_mixnet_m(\n        'mixnet_m', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mixnet_l(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Large model.\n    \"\"\"",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mixnet_l",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mixnet_l(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Large model.\n    \"\"\"\n    model = _gen_mixnet_m(\n        'mixnet_l', channel_multiplier=1.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mixnet_xl(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Extra-Large model.\n    Not a paper spec, experimental def by RW w/ depth scaling.",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mixnet_xl",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mixnet_xl(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Extra-Large model.\n    Not a paper spec, experimental def by RW w/ depth scaling.\n    \"\"\"\n    model = _gen_mixnet_m(\n        'mixnet_xl', channel_multiplier=1.6, depth_multiplier=1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mixnet_xxl(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Double Extra Large model.",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "mixnet_xxl",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def mixnet_xxl(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Double Extra Large model.\n    Not a paper spec, experimental def by RW w/ depth scaling.\n    \"\"\"\n    model = _gen_mixnet_m(\n        'mixnet_xxl', channel_multiplier=2.4, depth_multiplier=1.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mixnet_s(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Small model. Tensorflow compatible variant",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_mixnet_s",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_mixnet_s(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Small model. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mixnet_s(\n        'tf_mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mixnet_m(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_mixnet_m",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_mixnet_m(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Medium model. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mixnet_m(\n        'tf_mixnet_m', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mixnet_l(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tf_mixnet_l",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tf_mixnet_l(pretrained=False, **kwargs):\n    \"\"\"Creates a MixNet Large model. Tensorflow compatible variant\n    \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mixnet_m(\n        'tf_mixnet_l', channel_multiplier=1.3, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_a(pretrained=False, **kwargs):",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tinynet_a",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tinynet_a(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_a', 1.0, 1.2, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_b(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_b', 0.75, 1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_c(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_c', 0.54, 0.85, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tinynet_b",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tinynet_b(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_b', 0.75, 1.1, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_c(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_c', 0.54, 0.85, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_d(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_d', 0.54, 0.695, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tinynet_c",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tinynet_c(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_c', 0.54, 0.85, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_d(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_d', 0.54, 0.695, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_e(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_e', 0.51, 0.6, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tinynet_d",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tinynet_d(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_d', 0.54, 0.695, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tinynet_e(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_e', 0.51, 0.6, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "tinynet_e",
        "kind": 2,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "def tinynet_e(pretrained=False, **kwargs):\n    model = _gen_tinynet('tinynet_e', 0.51, 0.6, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "__all__ = ['EfficientNet', 'EfficientNetFeatures']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv_stem', 'classifier': 'classifier',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "peekOfCode": "default_cfgs = {\n    'mnasnet_050': _cfg(url=''),\n    'mnasnet_075': _cfg(url=''),\n    'mnasnet_100': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mnasnet_b1-74cb7081.pth'),\n    'mnasnet_140': _cfg(url=''),\n    'semnasnet_050': _cfg(url=''),\n    'semnasnet_075': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/semnasnet_075-18710866.pth'),\n    'semnasnet_100': _cfg(",
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "SqueezeExcite",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class SqueezeExcite(nn.Module):\n    \"\"\" Squeeze-and-Excitation w/ specific features for EfficientNet/MobileNet family\n    Args:\n        in_chs (int): input channels to layer\n        rd_ratio (float): ratio of squeeze reduction\n        act_layer (nn.Module): activation layer of containing block\n        gate_layer (Callable): attention gate function\n        force_act_layer (nn.Module): override block's activation fn if this is set/bound\n        rd_round_fn (Callable): specify a fn to calculate rounding of reduced chs\n    \"\"\"",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "ConvBnAct",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class ConvBnAct(nn.Module):\n    \"\"\" Conv + Norm Layer + Activation w/ optional skip connection\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs, kernel_size, stride=1, dilation=1, pad_type='',\n            skip=False, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, drop_path_rate=0.):\n        super(ConvBnAct, self).__init__()\n        self.has_residual = skip and stride == 1 and in_chs == out_chs\n        self.drop_path_rate = drop_path_rate\n        self.conv = create_conv2d(in_chs, out_chs, kernel_size, stride=stride, dilation=dilation, padding=pad_type)",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "DepthwiseSeparableConv",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class DepthwiseSeparableConv(nn.Module):\n    \"\"\" DepthwiseSeparable block\n    Used for DS convs in MobileNet-V1 and in the place of IR blocks that have no expansion\n    (factor of 1.0). This is an alternative to having a IR with an optional first pw conv.\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs, dw_kernel_size=3, stride=1, dilation=1, pad_type='',\n            noskip=False, pw_kernel_size=1, pw_act=False, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,\n            se_layer=None, drop_path_rate=0.):\n        super(DepthwiseSeparableConv, self).__init__()",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "InvertedResidual",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class InvertedResidual(nn.Module):\n    \"\"\" Inverted residual block w/ optional SE\n    Originally used in MobileNet-V2 - https://arxiv.org/abs/1801.04381v4, this layer is often\n    referred to as 'MBConv' for (Mobile inverted bottleneck conv) and is also used in\n      * MNasNet - https://arxiv.org/abs/1807.11626\n      * EfficientNet - https://arxiv.org/abs/1905.11946\n      * MobileNet-V3 - https://arxiv.org/abs/1905.02244\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs, dw_kernel_size=3, stride=1, dilation=1, pad_type='',",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "CondConvResidual",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class CondConvResidual(InvertedResidual):\n    \"\"\" Inverted residual block w/ CondConv routing\"\"\"\n    def __init__(\n            self, in_chs, out_chs, dw_kernel_size=3, stride=1, dilation=1, pad_type='',\n            noskip=False, exp_ratio=1.0, exp_kernel_size=1, pw_kernel_size=1, act_layer=nn.ReLU,\n            norm_layer=nn.BatchNorm2d, se_layer=None, num_experts=0, drop_path_rate=0.):\n        self.num_experts = num_experts\n        conv_kwargs = dict(num_experts=self.num_experts)\n        super(CondConvResidual, self).__init__(\n            in_chs, out_chs, dw_kernel_size=dw_kernel_size, stride=stride, dilation=dilation, pad_type=pad_type,",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "EdgeResidual",
        "kind": 6,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "class EdgeResidual(nn.Module):\n    \"\"\" Residual block with expansion convolution followed by pointwise-linear w/ stride\n    Originally introduced in `EfficientNet-EdgeTPU: Creating Accelerator-Optimized Neural Networks with AutoML`\n        - https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html\n    This layer is also called FusedMBConv in the MobileDet, EfficientNet-X, and EfficientNet-V2 papers\n      * MobileDet - https://arxiv.org/abs/2004.14525\n      * EfficientNet-X - https://arxiv.org/abs/2102.05610\n      * EfficientNet-V2 - https://arxiv.org/abs/2104.00298\n    \"\"\"\n    def __init__(",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.efficientnet_blocks",
        "description": "timm.models.efficientnet_blocks",
        "peekOfCode": "__all__ = [\n    'SqueezeExcite', 'ConvBnAct', 'DepthwiseSeparableConv', 'InvertedResidual', 'CondConvResidual', 'EdgeResidual']\nclass SqueezeExcite(nn.Module):\n    \"\"\" Squeeze-and-Excitation w/ specific features for EfficientNet/MobileNet family\n    Args:\n        in_chs (int): input channels to layer\n        rd_ratio (float): ratio of squeeze reduction\n        act_layer (nn.Module): activation layer of containing block\n        gate_layer (Callable): attention gate function\n        force_act_layer (nn.Module): override block's activation fn if this is set/bound",
        "detail": "timm.models.efficientnet_blocks",
        "documentation": {}
    },
    {
        "label": "EfficientNetBuilder",
        "kind": 6,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "class EfficientNetBuilder:\n    \"\"\" Build Trunk Blocks\n    This ended up being somewhat of a cross between\n    https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_models.py\n    and\n    https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/modeling/backbone/fbnet_builder.py\n    \"\"\"\n    def __init__(self, output_stride=32, pad_type='', round_chs_fn=round_channels, se_from_exp=False,\n                 act_layer=None, norm_layer=None, se_layer=None, drop_path_rate=0., feature_location=''):\n        self.output_stride = output_stride",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "get_bn_args_tf",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def get_bn_args_tf():\n    return _BN_ARGS_TF.copy()\ndef resolve_bn_args(kwargs):\n    bn_args = {}\n    bn_momentum = kwargs.pop('bn_momentum', None)\n    if bn_momentum is not None:\n        bn_args['momentum'] = bn_momentum\n    bn_eps = kwargs.pop('bn_eps', None)\n    if bn_eps is not None:\n        bn_args['eps'] = bn_eps",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "resolve_bn_args",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def resolve_bn_args(kwargs):\n    bn_args = {}\n    bn_momentum = kwargs.pop('bn_momentum', None)\n    if bn_momentum is not None:\n        bn_args['momentum'] = bn_momentum\n    bn_eps = kwargs.pop('bn_eps', None)\n    if bn_eps is not None:\n        bn_args['eps'] = bn_eps\n    return bn_args\ndef resolve_act_layer(kwargs, default='relu'):",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "resolve_act_layer",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def resolve_act_layer(kwargs, default='relu'):\n    return get_act_layer(kwargs.pop('act_layer', default))\ndef round_channels(channels, multiplier=1.0, divisor=8, channel_min=None, round_limit=0.9):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    if not multiplier:\n        return channels\n    return make_divisible(channels * multiplier, divisor, channel_min, round_limit=round_limit)\ndef _log_info_if(msg, condition):\n    if condition:\n        _logger.info(msg)",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "round_channels",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def round_channels(channels, multiplier=1.0, divisor=8, channel_min=None, round_limit=0.9):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    if not multiplier:\n        return channels\n    return make_divisible(channels * multiplier, divisor, channel_min, round_limit=round_limit)\ndef _log_info_if(msg, condition):\n    if condition:\n        _logger.info(msg)\ndef _parse_ksize(ss):\n    if ss.isdigit():",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "decode_arch_def",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def decode_arch_def(arch_def, depth_multiplier=1.0, depth_trunc='ceil', experts_multiplier=1, fix_first_last=False):\n    arch_args = []\n    if isinstance(depth_multiplier, tuple):\n        assert len(depth_multiplier) == len(arch_def)\n    else:\n        depth_multiplier = (depth_multiplier,) * len(arch_def)\n    for stack_idx, (block_strings, multiplier) in enumerate(zip(arch_def, depth_multiplier)):\n        assert isinstance(block_strings, list)\n        stack_args = []\n        repeats = []",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "efficientnet_init_weights",
        "kind": 2,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "def efficientnet_init_weights(model: nn.Module, init_fn=None):\n    init_fn = init_fn or _init_weight_goog\n    for n, m in model.named_modules():\n        init_fn(m, n)",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "__all__ = [\"EfficientNetBuilder\", \"decode_arch_def\", \"efficientnet_init_weights\",\n           'resolve_bn_args', 'resolve_act_layer', 'round_channels', 'BN_MOMENTUM_TF_DEFAULT', 'BN_EPS_TF_DEFAULT']\n_logger = logging.getLogger(__name__)\n_DEBUG_BUILDER = False\n# Defaults used for Google/Tensorflow training of mobile networks /w RMSprop as per\n# papers and TF reference implementations. PT momentum equiv for TF decay is (1 - TF decay)\n# NOTE: momentum varies btw .99 and .9997 depending on source\n# .99 in official TF TPU impl\n# .9997 (/w .999 in search space) for paper\nBN_MOMENTUM_TF_DEFAULT = 1 - 0.99",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "_logger = logging.getLogger(__name__)\n_DEBUG_BUILDER = False\n# Defaults used for Google/Tensorflow training of mobile networks /w RMSprop as per\n# papers and TF reference implementations. PT momentum equiv for TF decay is (1 - TF decay)\n# NOTE: momentum varies btw .99 and .9997 depending on source\n# .99 in official TF TPU impl\n# .9997 (/w .999 in search space) for paper\nBN_MOMENTUM_TF_DEFAULT = 1 - 0.99\nBN_EPS_TF_DEFAULT = 1e-3\n_BN_ARGS_TF = dict(momentum=BN_MOMENTUM_TF_DEFAULT, eps=BN_EPS_TF_DEFAULT)",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "_DEBUG_BUILDER",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "_DEBUG_BUILDER = False\n# Defaults used for Google/Tensorflow training of mobile networks /w RMSprop as per\n# papers and TF reference implementations. PT momentum equiv for TF decay is (1 - TF decay)\n# NOTE: momentum varies btw .99 and .9997 depending on source\n# .99 in official TF TPU impl\n# .9997 (/w .999 in search space) for paper\nBN_MOMENTUM_TF_DEFAULT = 1 - 0.99\nBN_EPS_TF_DEFAULT = 1e-3\n_BN_ARGS_TF = dict(momentum=BN_MOMENTUM_TF_DEFAULT, eps=BN_EPS_TF_DEFAULT)\ndef get_bn_args_tf():",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "BN_MOMENTUM_TF_DEFAULT",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "BN_MOMENTUM_TF_DEFAULT = 1 - 0.99\nBN_EPS_TF_DEFAULT = 1e-3\n_BN_ARGS_TF = dict(momentum=BN_MOMENTUM_TF_DEFAULT, eps=BN_EPS_TF_DEFAULT)\ndef get_bn_args_tf():\n    return _BN_ARGS_TF.copy()\ndef resolve_bn_args(kwargs):\n    bn_args = {}\n    bn_momentum = kwargs.pop('bn_momentum', None)\n    if bn_momentum is not None:\n        bn_args['momentum'] = bn_momentum",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "BN_EPS_TF_DEFAULT",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "BN_EPS_TF_DEFAULT = 1e-3\n_BN_ARGS_TF = dict(momentum=BN_MOMENTUM_TF_DEFAULT, eps=BN_EPS_TF_DEFAULT)\ndef get_bn_args_tf():\n    return _BN_ARGS_TF.copy()\ndef resolve_bn_args(kwargs):\n    bn_args = {}\n    bn_momentum = kwargs.pop('bn_momentum', None)\n    if bn_momentum is not None:\n        bn_args['momentum'] = bn_momentum\n    bn_eps = kwargs.pop('bn_eps', None)",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "_BN_ARGS_TF",
        "kind": 5,
        "importPath": "timm.models.efficientnet_builder",
        "description": "timm.models.efficientnet_builder",
        "peekOfCode": "_BN_ARGS_TF = dict(momentum=BN_MOMENTUM_TF_DEFAULT, eps=BN_EPS_TF_DEFAULT)\ndef get_bn_args_tf():\n    return _BN_ARGS_TF.copy()\ndef resolve_bn_args(kwargs):\n    bn_args = {}\n    bn_momentum = kwargs.pop('bn_momentum', None)\n    if bn_momentum is not None:\n        bn_args['momentum'] = bn_momentum\n    bn_eps = kwargs.pop('bn_eps', None)\n    if bn_eps is not None:",
        "detail": "timm.models.efficientnet_builder",
        "documentation": {}
    },
    {
        "label": "split_model_name",
        "kind": 2,
        "importPath": "timm.models.factory",
        "description": "timm.models.factory",
        "peekOfCode": "def split_model_name(model_name):\n    model_split = model_name.split(':', 1)\n    if len(model_split) == 1:\n        return '', model_split[0]\n    else:\n        source_name, model_name = model_split\n        assert source_name in ('timm', 'hf_hub')\n        return source_name, model_name\ndef safe_model_name(model_name, remove_source=True):\n    def make_safe(name):",
        "detail": "timm.models.factory",
        "documentation": {}
    },
    {
        "label": "safe_model_name",
        "kind": 2,
        "importPath": "timm.models.factory",
        "description": "timm.models.factory",
        "peekOfCode": "def safe_model_name(model_name, remove_source=True):\n    def make_safe(name):\n        return ''.join(c if c.isalnum() else '_' for c in name).rstrip('_')\n    if remove_source:\n        model_name = split_model_name(model_name)[-1]\n    return make_safe(model_name)\ndef create_model(\n        model_name,\n        pretrained=False,\n        checkpoint_path='',",
        "detail": "timm.models.factory",
        "documentation": {}
    },
    {
        "label": "create_model",
        "kind": 2,
        "importPath": "timm.models.factory",
        "description": "timm.models.factory",
        "peekOfCode": "def create_model(\n        model_name,\n        pretrained=False,\n        checkpoint_path='',\n        scriptable=None,\n        exportable=None,\n        no_jit=None,\n        **kwargs):\n    \"\"\"Create a model\n    Args:",
        "detail": "timm.models.factory",
        "documentation": {}
    },
    {
        "label": "FeatureInfo",
        "kind": 6,
        "importPath": "timm.models.features",
        "description": "timm.models.features",
        "peekOfCode": "class FeatureInfo:\n    def __init__(self, feature_info: List[Dict], out_indices: Tuple[int]):\n        prev_reduction = 1\n        for fi in feature_info:\n            # sanity check the mandatory fields, there may be additional fields depending on the model\n            assert 'num_chs' in fi and fi['num_chs'] > 0\n            assert 'reduction' in fi and fi['reduction'] >= prev_reduction\n            prev_reduction = fi['reduction']\n            assert 'module' in fi\n        self.out_indices = out_indices",
        "detail": "timm.models.features",
        "documentation": {}
    },
    {
        "label": "FeatureHooks",
        "kind": 6,
        "importPath": "timm.models.features",
        "description": "timm.models.features",
        "peekOfCode": "class FeatureHooks:\n    \"\"\" Feature Hook Helper\n    This module helps with the setup and extraction of hooks for extracting features from\n    internal nodes in a model by node name. This works quite well in eager Python but needs\n    redesign for torcscript.\n    \"\"\"\n    def __init__(self, hooks, named_modules, out_map=None, default_hook_type='forward'):\n        # setup feature hooks\n        modules = {k: v for k, v in named_modules}\n        for i, h in enumerate(hooks):",
        "detail": "timm.models.features",
        "documentation": {}
    },
    {
        "label": "FeatureDictNet",
        "kind": 6,
        "importPath": "timm.models.features",
        "description": "timm.models.features",
        "peekOfCode": "class FeatureDictNet(nn.ModuleDict):\n    \"\"\" Feature extractor with OrderedDict return\n    Wrap a model and extract features as specified by the out indices, the network is\n    partially re-built from contained modules.\n    There is a strong assumption that the modules have been registered into the model in the same\n    order as they are used. There should be no reuse of the same nn.Module more than once, including\n    trivial modules like `self.relu = nn.ReLU`.\n    Only submodules that are directly assigned to the model class (`model.feature1`) or at most\n    one Sequential container deep (`model.features.1`, with flatten_sequent=True) can be captured.\n    All Sequential containers that are directly assigned to the original model will have their",
        "detail": "timm.models.features",
        "documentation": {}
    },
    {
        "label": "FeatureListNet",
        "kind": 6,
        "importPath": "timm.models.features",
        "description": "timm.models.features",
        "peekOfCode": "class FeatureListNet(FeatureDictNet):\n    \"\"\" Feature extractor with list return\n    See docstring for FeatureDictNet above, this class exists only to appease Torchscript typing constraints.\n    In eager Python we could have returned List[Tensor] vs Dict[id, Tensor] based on a member bool.\n    \"\"\"\n    def __init__(\n            self, model,\n            out_indices=(0, 1, 2, 3, 4), out_map=None, feature_concat=False, flatten_sequential=False):\n        super(FeatureListNet, self).__init__(\n            model, out_indices=out_indices, out_map=out_map, feature_concat=feature_concat,",
        "detail": "timm.models.features",
        "documentation": {}
    },
    {
        "label": "FeatureHookNet",
        "kind": 6,
        "importPath": "timm.models.features",
        "description": "timm.models.features",
        "peekOfCode": "class FeatureHookNet(nn.ModuleDict):\n    \"\"\" FeatureHookNet\n    Wrap a model and extract features specified by the out indices using forward/forward-pre hooks.\n    If `no_rewrite` is True, features are extracted via hooks without modifying the underlying\n    network in any way.\n    If `no_rewrite` is False, the model will be re-written as in the\n    FeatureList/FeatureDict case by folding first to second (Sequential only) level modules into this one.\n    FIXME this does not currently work with Torchscript, see FeatureHooks class\n    \"\"\"\n    def __init__(",
        "detail": "timm.models.features",
        "documentation": {}
    },
    {
        "label": "FeatureGraphNet",
        "kind": 6,
        "importPath": "timm.models.fx_features",
        "description": "timm.models.fx_features",
        "peekOfCode": "class FeatureGraphNet(nn.Module):\n    def __init__(self, model, out_indices, out_map=None):\n        super().__init__()\n        assert has_fx_feature_extraction, 'Please update to PyTorch 1.10+, torchvision 0.11+ for FX feature extraction'\n        self.feature_info = _get_feature_info(model, out_indices)\n        if out_map is not None:\n            assert len(out_map) == len(out_indices)\n        return_nodes = {info['module']: out_map[i] if out_map is not None else info['module']\n                        for i, info in enumerate(self.feature_info) if i in out_indices}\n        self.graph_module = create_feature_extractor(",
        "detail": "timm.models.fx_features",
        "documentation": {}
    },
    {
        "label": "register_notrace_module",
        "kind": 2,
        "importPath": "timm.models.fx_features",
        "description": "timm.models.fx_features",
        "peekOfCode": "def register_notrace_module(module: nn.Module):\n    \"\"\"\n    Any module not under timm.models.layers should get this decorator if we don't want to trace through it.\n    \"\"\"\n    _leaf_modules.add(module)\n    return module\n# Functions we want to autowrap (treat them as leaves)\n_autowrap_functions = set()\ndef register_notrace_function(func: Callable):\n    \"\"\"",
        "detail": "timm.models.fx_features",
        "documentation": {}
    },
    {
        "label": "register_notrace_function",
        "kind": 2,
        "importPath": "timm.models.fx_features",
        "description": "timm.models.fx_features",
        "peekOfCode": "def register_notrace_function(func: Callable):\n    \"\"\"\n    Decorator for functions which ought not to be traced through\n    \"\"\"\n    _autowrap_functions.add(func)\n    return func\nclass FeatureGraphNet(nn.Module):\n    def __init__(self, model, out_indices, out_map=None):\n        super().__init__()\n        assert has_fx_feature_extraction, 'Please update to PyTorch 1.10+, torchvision 0.11+ for FX feature extraction'",
        "detail": "timm.models.fx_features",
        "documentation": {}
    },
    {
        "label": "_leaf_modules",
        "kind": 5,
        "importPath": "timm.models.fx_features",
        "description": "timm.models.fx_features",
        "peekOfCode": "_leaf_modules = {\n    BatchNormAct2d,  # reason: flow control for jit scripting\n    BilinearAttnTransform,  # reason: flow control t <= 1\n    BlurPool2d,  # reason: TypeError: F.conv2d received Proxy in groups=x.shape[1]\n    # Reason: get_same_padding has a max which raises a control flow error\n    Conv2dSame, MaxPool2dSame,  ScaledStdConv2dSame, StdConv2dSame, AvgPool2dSame,\n    CondConv2d,  # reason: TypeError: F.conv2d received Proxy in groups=self.groups * B (because B = x.shape[0])\n    DropPath,  # reason: TypeError: rand recieved Proxy in `size` argument\n}\ntry:",
        "detail": "timm.models.fx_features",
        "documentation": {}
    },
    {
        "label": "_autowrap_functions",
        "kind": 5,
        "importPath": "timm.models.fx_features",
        "description": "timm.models.fx_features",
        "peekOfCode": "_autowrap_functions = set()\ndef register_notrace_function(func: Callable):\n    \"\"\"\n    Decorator for functions which ought not to be traced through\n    \"\"\"\n    _autowrap_functions.add(func)\n    return func\nclass FeatureGraphNet(nn.Module):\n    def __init__(self, model, out_indices, out_map=None):\n        super().__init__()",
        "detail": "timm.models.fx_features",
        "documentation": {}
    },
    {
        "label": "GhostModule",
        "kind": 6,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "class GhostModule(nn.Module):\n    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True):\n        super(GhostModule, self).__init__()\n        self.oup = oup\n        init_channels = math.ceil(oup / ratio)\n        new_channels = init_channels * (ratio - 1)\n        self.primary_conv = nn.Sequential(\n            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n            nn.BatchNorm2d(init_channels),\n            nn.ReLU(inplace=True) if relu else nn.Sequential(),",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "kind": 6,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "class GhostBottleneck(nn.Module):\n    \"\"\" Ghost bottleneck w/ optional SE\"\"\"\n    def __init__(self, in_chs, mid_chs, out_chs, dw_kernel_size=3,\n                 stride=1, act_layer=nn.ReLU, se_ratio=0.):\n        super(GhostBottleneck, self).__init__()\n        has_se = se_ratio is not None and se_ratio > 0.\n        self.stride = stride\n        # Point-wise expansion\n        self.ghost1 = GhostModule(in_chs, mid_chs, relu=True)\n        # Depth-wise convolution",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "GhostNet",
        "kind": 6,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "class GhostNet(nn.Module):\n    def __init__(self, cfgs, num_classes=1000, width=1.0, dropout=0.2, in_chans=3, output_stride=32, global_pool='avg'):\n        super(GhostNet, self).__init__()\n        # setting of inverted residual blocks\n        assert output_stride == 32, 'only output_stride==32 is valid, dilation not supported'\n        self.cfgs = cfgs\n        self.num_classes = num_classes\n        self.dropout = dropout\n        self.feature_info = []\n        # building first layer",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "ghostnet_050",
        "kind": 2,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "def ghostnet_050(pretrained=False, **kwargs):\n    \"\"\" GhostNet-0.5x \"\"\"\n    model = _create_ghostnet('ghostnet_050', width=0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef ghostnet_100(pretrained=False, **kwargs):\n    \"\"\" GhostNet-1.0x \"\"\"\n    model = _create_ghostnet('ghostnet_100', width=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "ghostnet_100",
        "kind": 2,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "def ghostnet_100(pretrained=False, **kwargs):\n    \"\"\" GhostNet-1.0x \"\"\"\n    model = _create_ghostnet('ghostnet_100', width=1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef ghostnet_130(pretrained=False, **kwargs):\n    \"\"\" GhostNet-1.3x \"\"\"\n    model = _create_ghostnet('ghostnet_130', width=1.3, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "ghostnet_130",
        "kind": 2,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "def ghostnet_130(pretrained=False, **kwargs):\n    \"\"\" GhostNet-1.3x \"\"\"\n    model = _create_ghostnet('ghostnet_130', width=1.3, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "__all__ = ['GhostNet']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (1, 1),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv_stem', 'classifier': 'classifier',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "default_cfgs = {\n    'ghostnet_050': _cfg(url=''),\n    'ghostnet_100': _cfg(\n        url='https://github.com/huawei-noah/CV-backbones/releases/download/ghostnet_pth/ghostnet_1x.pth'),\n    'ghostnet_130': _cfg(url=''),\n}\n_SE_LAYER = partial(SqueezeExcite, gate_layer='hard_sigmoid', rd_round_fn=partial(make_divisible, divisor=4))\nclass GhostModule(nn.Module):\n    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True):\n        super(GhostModule, self).__init__()",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "_SE_LAYER",
        "kind": 5,
        "importPath": "timm.models.ghostnet",
        "description": "timm.models.ghostnet",
        "peekOfCode": "_SE_LAYER = partial(SqueezeExcite, gate_layer='hard_sigmoid', rd_round_fn=partial(make_divisible, divisor=4))\nclass GhostModule(nn.Module):\n    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True):\n        super(GhostModule, self).__init__()\n        self.oup = oup\n        init_channels = math.ceil(oup / ratio)\n        new_channels = init_channels * (ratio - 1)\n        self.primary_conv = nn.Sequential(\n            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n            nn.BatchNorm2d(init_channels),",
        "detail": "timm.models.ghostnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet18_v1b",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet18_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], **kwargs)\n    return _create_resnet('gluon_resnet18_v1b', pretrained, **model_args)\n@register_model\ndef gluon_resnet34_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet34_v1b",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet34_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], **kwargs)\n    return _create_resnet('gluon_resnet34_v1b', pretrained, **model_args)\n@register_model\ndef gluon_resnet50_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet50_v1b",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet50_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('gluon_resnet50_v1b', pretrained, **model_args)\n@register_model\ndef gluon_resnet101_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet101_v1b",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet101_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], **kwargs)\n    return _create_resnet('gluon_resnet101_v1b', pretrained, **model_args)\n@register_model\ndef gluon_resnet152_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet152_v1b",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet152_v1b(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)\n    return _create_resnet('gluon_resnet152_v1b', pretrained, **model_args)\n@register_model\ndef gluon_resnet50_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet50_v1c",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet50_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet50_v1c', pretrained, **model_args)\n@register_model\ndef gluon_resnet101_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet101_v1c",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet101_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet101_v1c', pretrained, **model_args)\n@register_model\ndef gluon_resnet152_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet152_v1c",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet152_v1c(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet152_v1c', pretrained, **model_args)\n@register_model\ndef gluon_resnet50_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet50_v1d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet50_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('gluon_resnet50_v1d', pretrained, **model_args)\n@register_model\ndef gluon_resnet101_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet101_v1d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet101_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('gluon_resnet101_v1d', pretrained, **model_args)\n@register_model\ndef gluon_resnet152_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet152_v1d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet152_v1d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('gluon_resnet152_v1d', pretrained, **model_args)\n@register_model\ndef gluon_resnet50_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet50_v1s",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet50_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=64, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet50_v1s', pretrained, **model_args)\n@register_model\ndef gluon_resnet101_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet101_v1s",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet101_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], stem_width=64, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet101_v1s', pretrained, **model_args)\n@register_model\ndef gluon_resnet152_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnet152_v1s",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnet152_v1s(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=64, stem_type='deep', **kwargs)\n    return _create_resnet('gluon_resnet152_v1s', pretrained, **model_args)\n@register_model\ndef gluon_resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('gluon_resnext50_32x4d', pretrained, **model_args)\n@register_model\ndef gluon_resnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('gluon_resnext101_32x4d', pretrained, **model_args)\n@register_model\ndef gluon_resnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=64, base_width=4, **kwargs)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_resnext101_64x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_resnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=64, base_width=4, **kwargs)\n    return _create_resnet('gluon_resnext101_64x4d', pretrained, **model_args)\n@register_model\ndef gluon_seresnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt50-32x4d model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_seresnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_seresnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt50-32x4d model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4,\n        block_args=dict(attn_layer=SEModule), **kwargs)\n    return _create_resnet('gluon_seresnext50_32x4d', pretrained, **model_args)\n@register_model\ndef gluon_seresnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt-101-32x4d model.",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_seresnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_seresnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt-101-32x4d model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4,\n        block_args=dict(attn_layer=SEModule), **kwargs)\n    return _create_resnet('gluon_seresnext101_32x4d', pretrained, **model_args)\n@register_model\ndef gluon_seresnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt-101-64x4d model.",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_seresnext101_64x4d",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_seresnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SEResNeXt-101-64x4d model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=64, base_width=4,\n        block_args=dict(attn_layer=SEModule), **kwargs)\n    return _create_resnet('gluon_seresnext101_64x4d', pretrained, **model_args)\n@register_model\ndef gluon_senet154(pretrained=False, **kwargs):\n    \"\"\"Constructs an SENet-154 model.",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "gluon_senet154",
        "kind": 2,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "def gluon_senet154(pretrained=False, **kwargs):\n    \"\"\"Constructs an SENet-154 model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], cardinality=64, base_width=4, stem_type='deep',\n        down_kernel_size=3, block_reduce_first=2, block_args=dict(attn_layer=SEModule), **kwargs)\n    return _create_resnet('gluon_senet154', pretrained, **model_args)",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.gluon_resnet",
        "description": "timm.models.gluon_resnet",
        "peekOfCode": "default_cfgs = {\n    'gluon_resnet18_v1b': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet18_v1b-0757602b.pth'),\n    'gluon_resnet34_v1b': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet34_v1b-c6d82d59.pth'),\n    'gluon_resnet50_v1b': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1b-0ebe02e2.pth'),\n    'gluon_resnet101_v1b': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1b-3b017079.pth'),\n    'gluon_resnet152_v1b': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet152_v1b-c1edb0dd.pth'),\n    'gluon_resnet50_v1c': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1c-48092f55.pth',\n                               first_conv='conv1.0'),\n    'gluon_resnet101_v1c': _cfg(url='https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1c-1f26822a.pth',\n                                first_conv='conv1.0'),",
        "detail": "timm.models.gluon_resnet",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, norm_layer=None):\n        super(SeparableConv2d, self).__init__()\n        self.kernel_size = kernel_size\n        self.dilation = dilation\n        # depthwise convolution\n        padding = get_padding(kernel_size, stride, dilation)\n        self.conv_dw = nn.Conv2d(\n            inplanes, inplanes, kernel_size, stride=stride,\n            padding=padding, dilation=dilation, groups=inplanes, bias=bias)",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, inplanes, planes, stride=1, dilation=1, start_with_relu=True, norm_layer=None):\n        super(Block, self).__init__()\n        if isinstance(planes, (list, tuple)):\n            assert len(planes) == 3\n        else:\n            planes = (planes,) * 3\n        outplanes = planes[-1]\n        if outplanes != inplanes or stride != 1:\n            self.skip = nn.Sequential()",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "Xception65",
        "kind": 6,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "class Xception65(nn.Module):\n    \"\"\"Modified Aligned Xception.\n    NOTE: only the 65 layer version is included here, the 71 layer variant\n    was not correct and had no pretrained weights\n    \"\"\"\n    def __init__(self, num_classes=1000, in_chans=3, output_stride=32, norm_layer=nn.BatchNorm2d,\n                 drop_rate=0., global_pool='avg'):\n        super(Xception65, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "gluon_xception65",
        "kind": 2,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "def gluon_xception65(pretrained=False, **kwargs):\n    \"\"\" Modified Aligned Xception-65\n    \"\"\"\n    return _create_gluon_xception('gluon_xception65', pretrained, **kwargs)",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "__all__ = ['Xception65']\ndefault_cfgs = {\n    'gluon_xception65': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_xception-7015a15c.pth',\n        'input_size': (3, 299, 299),\n        'crop_pct': 0.903,\n        'pool_size': (10, 10),\n        'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN,\n        'std': IMAGENET_DEFAULT_STD,",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.gluon_xception",
        "description": "timm.models.gluon_xception",
        "peekOfCode": "default_cfgs = {\n    'gluon_xception65': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_xception-7015a15c.pth',\n        'input_size': (3, 299, 299),\n        'crop_pct': 0.903,\n        'pool_size': (10, 10),\n        'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN,\n        'std': IMAGENET_DEFAULT_STD,\n        'num_classes': 1000,",
        "detail": "timm.models.gluon_xception",
        "documentation": {}
    },
    {
        "label": "hardcorenas_a",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_a(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_A \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'], ['ir_r1_k5_s2_e3_c24_nre', 'ir_r1_k5_s1_e3_c24_nre_se0.25'],\n                ['ir_r1_k5_s2_e3_c40_nre', 'ir_r1_k5_s1_e6_c40_nre_se0.25'],\n                ['ir_r1_k5_s2_e6_c80_se0.25', 'ir_r1_k5_s1_e6_c80_se0.25'],\n                ['ir_r1_k5_s1_e6_c112_se0.25', 'ir_r1_k5_s1_e6_c112_se0.25'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25'], ['cn_r1_k1_s1_c960']]\n    model = _gen_hardcorenas(pretrained=pretrained, variant='hardcorenas_a', arch_def=arch_def, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "hardcorenas_b",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_b(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_B \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'],\n                ['ir_r1_k5_s2_e3_c24_nre', 'ir_r1_k5_s1_e3_c24_nre_se0.25', 'ir_r1_k3_s1_e3_c24_nre'],\n                ['ir_r1_k5_s2_e3_c40_nre', 'ir_r1_k5_s1_e3_c40_nre', 'ir_r1_k5_s1_e3_c40_nre'],\n                ['ir_r1_k5_s2_e3_c80', 'ir_r1_k5_s1_e3_c80', 'ir_r1_k3_s1_e3_c80', 'ir_r1_k3_s1_e3_c80'],\n                ['ir_r1_k5_s1_e3_c112', 'ir_r1_k3_s1_e3_c112', 'ir_r1_k3_s1_e3_c112', 'ir_r1_k3_s1_e3_c112'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25', 'ir_r1_k3_s1_e3_c192_se0.25'],\n                ['cn_r1_k1_s1_c960']]\n    model = _gen_hardcorenas(pretrained=pretrained, variant='hardcorenas_b', arch_def=arch_def, **kwargs)",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "hardcorenas_c",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_c(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_C \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'], ['ir_r1_k5_s2_e3_c24_nre', 'ir_r1_k5_s1_e3_c24_nre_se0.25'],\n                ['ir_r1_k5_s2_e3_c40_nre', 'ir_r1_k5_s1_e3_c40_nre', 'ir_r1_k5_s1_e3_c40_nre',\n                 'ir_r1_k5_s1_e3_c40_nre'],\n                ['ir_r1_k5_s2_e4_c80', 'ir_r1_k5_s1_e6_c80_se0.25', 'ir_r1_k3_s1_e3_c80', 'ir_r1_k3_s1_e3_c80'],\n                ['ir_r1_k5_s1_e6_c112_se0.25', 'ir_r1_k3_s1_e3_c112', 'ir_r1_k3_s1_e3_c112', 'ir_r1_k3_s1_e3_c112'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25', 'ir_r1_k3_s1_e3_c192_se0.25'],\n                ['cn_r1_k1_s1_c960']]\n    model = _gen_hardcorenas(pretrained=pretrained, variant='hardcorenas_c', arch_def=arch_def, **kwargs)",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "hardcorenas_d",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_d(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_D \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'], ['ir_r1_k5_s2_e3_c24_nre_se0.25', 'ir_r1_k5_s1_e3_c24_nre_se0.25'],\n                ['ir_r1_k5_s2_e3_c40_nre_se0.25', 'ir_r1_k5_s1_e4_c40_nre_se0.25', 'ir_r1_k3_s1_e3_c40_nre_se0.25'],\n                ['ir_r1_k5_s2_e4_c80_se0.25', 'ir_r1_k3_s1_e3_c80_se0.25', 'ir_r1_k3_s1_e3_c80_se0.25',\n                 'ir_r1_k3_s1_e3_c80_se0.25'],\n                ['ir_r1_k3_s1_e4_c112_se0.25', 'ir_r1_k5_s1_e4_c112_se0.25', 'ir_r1_k3_s1_e3_c112_se0.25',\n                 'ir_r1_k5_s1_e3_c112_se0.25'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25',\n                 'ir_r1_k3_s1_e6_c192_se0.25'], ['cn_r1_k1_s1_c960']]",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "hardcorenas_e",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_e(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_E \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'], ['ir_r1_k5_s2_e3_c24_nre_se0.25', 'ir_r1_k5_s1_e3_c24_nre_se0.25'],\n                ['ir_r1_k5_s2_e6_c40_nre_se0.25', 'ir_r1_k5_s1_e4_c40_nre_se0.25', 'ir_r1_k5_s1_e4_c40_nre_se0.25',\n                 'ir_r1_k3_s1_e3_c40_nre_se0.25'], ['ir_r1_k5_s2_e4_c80_se0.25', 'ir_r1_k3_s1_e6_c80_se0.25'],\n                ['ir_r1_k5_s1_e6_c112_se0.25', 'ir_r1_k5_s1_e6_c112_se0.25', 'ir_r1_k5_s1_e6_c112_se0.25',\n                 'ir_r1_k5_s1_e3_c112_se0.25'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25',\n                 'ir_r1_k3_s1_e6_c192_se0.25'], ['cn_r1_k1_s1_c960']]\n    model = _gen_hardcorenas(pretrained=pretrained, variant='hardcorenas_e', arch_def=arch_def, **kwargs)",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "hardcorenas_f",
        "kind": 2,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "def hardcorenas_f(pretrained=False, **kwargs):\n    \"\"\" hardcorenas_F \"\"\"\n    arch_def = [['ds_r1_k3_s1_e1_c16_nre'], ['ir_r1_k5_s2_e3_c24_nre_se0.25', 'ir_r1_k5_s1_e3_c24_nre_se0.25'],\n                ['ir_r1_k5_s2_e6_c40_nre_se0.25', 'ir_r1_k5_s1_e6_c40_nre_se0.25'],\n                ['ir_r1_k5_s2_e6_c80_se0.25', 'ir_r1_k5_s1_e6_c80_se0.25', 'ir_r1_k3_s1_e3_c80_se0.25',\n                 'ir_r1_k3_s1_e3_c80_se0.25'],\n                ['ir_r1_k3_s1_e6_c112_se0.25', 'ir_r1_k5_s1_e6_c112_se0.25', 'ir_r1_k5_s1_e6_c112_se0.25',\n                 'ir_r1_k3_s1_e3_c112_se0.25'],\n                ['ir_r1_k5_s2_e6_c192_se0.25', 'ir_r1_k5_s1_e6_c192_se0.25', 'ir_r1_k3_s1_e6_c192_se0.25',\n                 'ir_r1_k3_s1_e6_c192_se0.25'], ['cn_r1_k1_s1_c960']]",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.hardcorenas",
        "description": "timm.models.hardcorenas",
        "peekOfCode": "default_cfgs = {\n    'hardcorenas_a': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_A_Green_38ms_75.9_23474aeb.pth'),\n    'hardcorenas_b': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_B_Green_40ms_76.5_1f882d1e.pth'),\n    'hardcorenas_c': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_C_Green_44ms_77.1_d4148c9e.pth'),\n    'hardcorenas_d': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_D_Green_50ms_77.4_23e3cdde.pth'),\n    'hardcorenas_e': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_E_Green_55ms_77.9_90f20e8a.pth'),\n    'hardcorenas_f': _cfg(url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_F_Green_60ms_78.1_2855edf1.pth'),\n}\ndef _gen_hardcorenas(pretrained, variant, arch_def, **kwargs):\n    \"\"\"Creates a hardcorenas model",
        "detail": "timm.models.hardcorenas",
        "documentation": {}
    },
    {
        "label": "load_state_dict",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def load_state_dict(checkpoint_path, use_ema=False):\n    if checkpoint_path and os.path.isfile(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n        state_dict_key = ''\n        if isinstance(checkpoint, dict):\n            if use_ema and checkpoint.get('state_dict_ema', None) is not None:\n                state_dict_key = 'state_dict_ema'\n            elif use_ema and checkpoint.get('model_ema', None) is not None:\n                state_dict_key = 'model_ema'\n            elif 'state_dict' in checkpoint:",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "load_checkpoint",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def load_checkpoint(model, checkpoint_path, use_ema=False, strict=True):\n    if os.path.splitext(checkpoint_path)[-1].lower() in ('.npz', '.npy'):\n        # numpy checkpoint, try to load via model specific load_pretrained fn\n        if hasattr(model, 'load_pretrained'):\n            model.load_pretrained(checkpoint_path)\n        else:\n            raise NotImplementedError('Model cannot load numpy checkpoint')\n        return\n    state_dict = load_state_dict(checkpoint_path, use_ema)\n    model.load_state_dict(state_dict, strict=strict)",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "resume_checkpoint",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def resume_checkpoint(model, checkpoint_path, optimizer=None, loss_scaler=None, log_info=True):\n    resume_epoch = None\n    if os.path.isfile(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n            if log_info:\n                _logger.info('Restoring model state from checkpoint...')\n            new_state_dict = OrderedDict()\n            for k, v in checkpoint['state_dict'].items():\n                name = k[7:] if k.startswith('module') else k",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "load_custom_pretrained",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def load_custom_pretrained(model, default_cfg=None, load_fn=None, progress=False, check_hash=False):\n    r\"\"\"Loads a custom (read non .pth) weight file\n    Downloads checkpoint file into cache-dir like torch.hub based loaders, but calls\n    a passed in custom load fun, or the `load_pretrained` model member fn.\n    If the object is already present in `model_dir`, it's deserialized and returned.\n    The default value of `model_dir` is ``<hub_dir>/checkpoints`` where\n    `hub_dir` is the directory returned by :func:`~torch.hub.get_dir`.\n    Args:\n        model: The instantiated model to load weights into\n        default_cfg (dict): Default pretrained model cfg",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "adapt_input_conv",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def adapt_input_conv(in_chans, conv_weight):\n    conv_type = conv_weight.dtype\n    conv_weight = conv_weight.float()  # Some weights are in torch.half, ensure it's float for sum on CPU\n    O, I, J, K = conv_weight.shape\n    if in_chans == 1:\n        if I > 3:\n            assert conv_weight.shape[1] % 3 == 0\n            # For models with space2depth stems\n            conv_weight = conv_weight.reshape(O, I // 3, 3, J, K)\n            conv_weight = conv_weight.sum(dim=2, keepdim=False)",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "load_pretrained",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def load_pretrained(model, default_cfg=None, num_classes=1000, in_chans=3, filter_fn=None, strict=True, progress=False):\n    \"\"\" Load pretrained checkpoint\n    Args:\n        model (nn.Module) : PyTorch model module\n        default_cfg (Optional[Dict]): default configuration for pretrained weights / target dataset\n        num_classes (int): num_classes for model\n        in_chans (int): in_chans for model\n        filter_fn (Optional[Callable]): state_dict filter fn for load (takes state_dict, model as args)\n        strict (bool): strict load of checkpoint\n        progress (bool): enable progress bar for weight download",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "extract_layer",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def extract_layer(model, layer):\n    layer = layer.split('.')\n    module = model\n    if hasattr(model, 'module') and layer[0] != 'module':\n        module = model.module\n    if not hasattr(model, 'module') and layer[0] == 'module':\n        layer = layer[1:]\n    for l in layer:\n        if hasattr(module, l):\n            if not l.isdigit():",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "set_layer",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def set_layer(model, layer, val):\n    layer = layer.split('.')\n    module = model\n    if hasattr(model, 'module') and layer[0] != 'module':\n        module = model.module\n    lst_index = 0\n    module2 = module\n    for l in layer:\n        if hasattr(module2, l):\n            if not l.isdigit():",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "adapt_model_from_string",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def adapt_model_from_string(parent_module, model_string):\n    separator = '***'\n    state_dict = {}\n    lst_shape = model_string.split(separator)\n    for k in lst_shape:\n        k = k.split(':')\n        key = k[0]\n        shape = k[1][1:-1].split(',')\n        if shape[0] != '':\n            state_dict[key] = [int(i) for i in shape]",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "adapt_model_from_file",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def adapt_model_from_file(parent_module, model_variant):\n    adapt_file = os.path.join(os.path.dirname(__file__), 'pruned', model_variant + '.txt')\n    with open(adapt_file, 'r') as f:\n        return adapt_model_from_string(parent_module, f.read().strip())\ndef default_cfg_for_features(default_cfg):\n    default_cfg = deepcopy(default_cfg)\n    # remove default pretrained cfg fields that don't have much relevance for feature backbone\n    to_remove = ('num_classes', 'crop_pct', 'classifier', 'global_pool')  # add default final pool size?\n    for tr in to_remove:\n        default_cfg.pop(tr, None)",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "default_cfg_for_features",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def default_cfg_for_features(default_cfg):\n    default_cfg = deepcopy(default_cfg)\n    # remove default pretrained cfg fields that don't have much relevance for feature backbone\n    to_remove = ('num_classes', 'crop_pct', 'classifier', 'global_pool')  # add default final pool size?\n    for tr in to_remove:\n        default_cfg.pop(tr, None)\n    return default_cfg\ndef overlay_external_default_cfg(default_cfg, kwargs):\n    \"\"\" Overlay 'external_default_cfg' in kwargs on top of default_cfg arg.\n    \"\"\"",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "overlay_external_default_cfg",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def overlay_external_default_cfg(default_cfg, kwargs):\n    \"\"\" Overlay 'external_default_cfg' in kwargs on top of default_cfg arg.\n    \"\"\"\n    external_default_cfg = kwargs.pop('external_default_cfg', None)\n    if external_default_cfg:\n        default_cfg.pop('url', None)  # url should come from external cfg\n        default_cfg.pop('hf_hub', None)  # hf hub id should come from external cfg\n        default_cfg.update(external_default_cfg)\ndef set_default_kwargs(kwargs, names, default_cfg):\n    for n in names:",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "set_default_kwargs",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def set_default_kwargs(kwargs, names, default_cfg):\n    for n in names:\n        # for legacy reasons, model __init__args uses img_size + in_chans as separate args while\n        # default_cfg has one input_size=(C, H ,W) entry\n        if n == 'img_size':\n            input_size = default_cfg.get('input_size', None)\n            if input_size is not None:\n                assert len(input_size) == 3\n                kwargs.setdefault(n, input_size[-2:])\n        elif n == 'in_chans':",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "filter_kwargs",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def filter_kwargs(kwargs, names):\n    if not kwargs or not names:\n        return\n    for n in names:\n        kwargs.pop(n, None)\ndef update_default_cfg_and_kwargs(default_cfg, kwargs, kwargs_filter):\n    \"\"\" Update the default_cfg and kwargs before passing to model\n    FIXME this sequence of overlay default_cfg, set default kwargs, filter kwargs\n    could/should be replaced by an improved configuration mechanism\n    Args:",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "update_default_cfg_and_kwargs",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def update_default_cfg_and_kwargs(default_cfg, kwargs, kwargs_filter):\n    \"\"\" Update the default_cfg and kwargs before passing to model\n    FIXME this sequence of overlay default_cfg, set default kwargs, filter kwargs\n    could/should be replaced by an improved configuration mechanism\n    Args:\n        default_cfg: input default_cfg (updated in-place)\n        kwargs: keyword args passed to model build fn (updated in-place)\n        kwargs_filter: keyword arg keys that must be removed before model __init__\n    \"\"\"\n    # Overlay default cfg values from `external_default_cfg` if it exists in kwargs",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "build_model_with_cfg",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def build_model_with_cfg(\n        model_cls: Callable,\n        variant: str,\n        pretrained: bool,\n        default_cfg: dict,\n        model_cfg: Optional[Any] = None,\n        feature_cfg: Optional[dict] = None,\n        pretrained_strict: bool = True,\n        pretrained_filter_fn: Optional[Callable] = None,\n        pretrained_custom_load: bool = False,",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "model_parameters",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def model_parameters(model, exclude_head=False):\n    if exclude_head:\n        # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering\n        return [p for p in model.parameters()][:-2]\n    else:\n        return model.parameters()\ndef named_apply(fn: Callable, module: nn.Module, name='', depth_first=True, include_root=False) -> nn.Module:\n    if not depth_first and include_root:\n        fn(module=module, name=name)\n    for child_name, child_module in module.named_children():",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "named_apply",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def named_apply(fn: Callable, module: nn.Module, name='', depth_first=True, include_root=False) -> nn.Module:\n    if not depth_first and include_root:\n        fn(module=module, name=name)\n    for child_name, child_module in module.named_children():\n        child_name = '.'.join((name, child_name)) if name else child_name\n        named_apply(fn=fn, module=child_module, name=child_name, depth_first=depth_first, include_root=True)\n    if depth_first and include_root:\n        fn(module=module, name=name)\n    return module\ndef named_modules(module: nn.Module, name='', depth_first=True, include_root=False):",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "named_modules",
        "kind": 2,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "def named_modules(module: nn.Module, name='', depth_first=True, include_root=False):\n    if not depth_first and include_root:\n        yield name, module\n    for child_name, child_module in module.named_children():\n        child_name = '.'.join((name, child_name)) if name else child_name\n        yield from named_modules(\n            module=child_module, name=child_name, depth_first=depth_first, include_root=True)\n    if depth_first and include_root:\n        yield name, module",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.helpers",
        "description": "timm.models.helpers",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef load_state_dict(checkpoint_path, use_ema=False):\n    if checkpoint_path and os.path.isfile(checkpoint_path):\n        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n        state_dict_key = ''\n        if isinstance(checkpoint, dict):\n            if use_ema and checkpoint.get('state_dict_ema', None) is not None:\n                state_dict_key = 'state_dict_ema'\n            elif use_ema and checkpoint.get('model_ema', None) is not None:\n                state_dict_key = 'model_ema'",
        "detail": "timm.models.helpers",
        "documentation": {}
    },
    {
        "label": "HighResolutionModule",
        "kind": 6,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "class HighResolutionModule(nn.Module):\n    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n                 num_channels, fuse_method, multi_scale_output=True):\n        super(HighResolutionModule, self).__init__()\n        self._check_branches(\n            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n        self.num_inchannels = num_inchannels\n        self.fuse_method = fuse_method\n        self.num_branches = num_branches\n        self.multi_scale_output = multi_scale_output",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "HighResolutionNet",
        "kind": 6,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "class HighResolutionNet(nn.Module):\n    def __init__(self, cfg, in_chans=3, num_classes=1000, global_pool='avg', drop_rate=0.0, head='classification'):\n        super(HighResolutionNet, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        stem_width = cfg['STEM_WIDTH']\n        self.conv1 = nn.Conv2d(in_chans, stem_width, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(stem_width, momentum=_BN_MOMENTUM)\n        self.act1 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(stem_width, 64, kernel_size=3, stride=2, padding=1, bias=False)",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "HighResolutionNetFeatures",
        "kind": 6,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "class HighResolutionNetFeatures(HighResolutionNet):\n    \"\"\"HighResolutionNet feature extraction\n    The design of HRNet makes it easy to grab feature maps, this class provides a simple wrapper to do so.\n    It would be more complicated to use the FeatureNet helpers.\n    The `feature_location=incre` allows grabbing increased channel count features using part of the\n    classification head. If `feature_location=''` the default HRNet features are returned. First stem\n    conv is used for stride 2 features.\n    \"\"\"\n    def __init__(self, cfg, in_chans=3, num_classes=1000, global_pool='avg', drop_rate=0.0,\n                 feature_location='incre', out_indices=(0, 1, 2, 3, 4)):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w18_small",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w18_small(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18_small', pretrained, **kwargs)\n@register_model\ndef hrnet_w18_small_v2(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18_small_v2', pretrained, **kwargs)\n@register_model\ndef hrnet_w18(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18', pretrained, **kwargs)\n@register_model\ndef hrnet_w30(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w18_small_v2",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w18_small_v2(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18_small_v2', pretrained, **kwargs)\n@register_model\ndef hrnet_w18(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18', pretrained, **kwargs)\n@register_model\ndef hrnet_w30(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w30', pretrained, **kwargs)\n@register_model\ndef hrnet_w32(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w18",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w18(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w18', pretrained, **kwargs)\n@register_model\ndef hrnet_w30(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w30', pretrained, **kwargs)\n@register_model\ndef hrnet_w32(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w32', pretrained, **kwargs)\n@register_model\ndef hrnet_w40(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w30",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w30(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w30', pretrained, **kwargs)\n@register_model\ndef hrnet_w32(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w32', pretrained, **kwargs)\n@register_model\ndef hrnet_w40(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w40', pretrained, **kwargs)\n@register_model\ndef hrnet_w44(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w32",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w32(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w32', pretrained, **kwargs)\n@register_model\ndef hrnet_w40(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w40', pretrained, **kwargs)\n@register_model\ndef hrnet_w44(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w44', pretrained, **kwargs)\n@register_model\ndef hrnet_w48(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w40",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w40(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w40', pretrained, **kwargs)\n@register_model\ndef hrnet_w44(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w44', pretrained, **kwargs)\n@register_model\ndef hrnet_w48(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w48', pretrained, **kwargs)\n@register_model\ndef hrnet_w64(pretrained=True, **kwargs):",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w44",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w44(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w44', pretrained, **kwargs)\n@register_model\ndef hrnet_w48(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w48', pretrained, **kwargs)\n@register_model\ndef hrnet_w64(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w64', pretrained, **kwargs)",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w48",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w48(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w48', pretrained, **kwargs)\n@register_model\ndef hrnet_w64(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w64', pretrained, **kwargs)",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "hrnet_w64",
        "kind": 2,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "def hrnet_w64(pretrained=True, **kwargs):\n    return _create_hrnet('hrnet_w64', pretrained, **kwargs)",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "_BN_MOMENTUM",
        "kind": 5,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "_BN_MOMENTUM = 0.1\n_logger = logging.getLogger(__name__)\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv1', 'classifier': 'classifier',\n        **kwargs",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv1', 'classifier': 'classifier',\n        **kwargs\n    }",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "default_cfgs = {\n    'hrnet_w18_small': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v1-f460c6bc.pth'),\n    'hrnet_w18_small_v2': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnet_w18_small_v2-4c50a8cb.pth'),\n    'hrnet_w18': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w18-8cb57bb9.pth'),\n    'hrnet_w30': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w30-8d7f8dab.pth'),\n    'hrnet_w32': _cfg(",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "cfg_cls",
        "kind": 5,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "cfg_cls = dict(\n    hrnet_w18_small=dict(\n        STEM_WIDTH=64,\n        STAGE1=dict(\n            NUM_MODULES=1,\n            NUM_BRANCHES=1,\n            BLOCK='BOTTLENECK',\n            NUM_BLOCKS=(1,),\n            NUM_CHANNELS=(32,),\n            FUSE_METHOD='SUM',",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "blocks_dict",
        "kind": 5,
        "importPath": "timm.models.hrnet",
        "description": "timm.models.hrnet",
        "peekOfCode": "blocks_dict = {\n    'BASIC': BasicBlock,\n    'BOTTLENECK': Bottleneck\n}\nclass HighResolutionNet(nn.Module):\n    def __init__(self, cfg, in_chans=3, num_classes=1000, global_pool='avg', drop_rate=0.0, head='classification'):\n        super(HighResolutionNet, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        stem_width = cfg['STEM_WIDTH']",
        "detail": "timm.models.hrnet",
        "documentation": {}
    },
    {
        "label": "get_cache_dir",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def get_cache_dir(child_dir=''):\n    \"\"\"\n    Returns the location of the directory where models are cached (and creates it if necessary).\n    \"\"\"\n    # Issue warning to move data if old env is set\n    if os.getenv('TORCH_MODEL_ZOO'):\n        _logger.warning('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n    hub_dir = get_dir()\n    child_dir = () if not child_dir else (child_dir,)\n    model_dir = os.path.join(hub_dir, 'checkpoints', *child_dir)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "download_cached_file",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def download_cached_file(url, check_hash=True, progress=False):\n    parts = urlparse(url)\n    filename = os.path.basename(parts.path)\n    cached_file = os.path.join(get_cache_dir(), filename)\n    if not os.path.exists(cached_file):\n        _logger.info('Downloading: \"{}\" to {}\\n'.format(url, cached_file))\n        hash_prefix = None\n        if check_hash:\n            r = HASH_REGEX.search(filename)  # r is Optional[Match[str]]\n            hash_prefix = r.group(1) if r else None",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "has_hf_hub",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def has_hf_hub(necessary=False):\n    if not _has_hf_hub and necessary:\n        # if no HF Hub module installed and it is necessary to continue, raise error\n        raise RuntimeError(\n            'Hugging Face hub model specified but package not installed. Run `pip install huggingface_hub`.')\n    return _has_hf_hub\ndef hf_split(hf_id):\n    rev_split = hf_id.split('@')\n    assert 0 < len(rev_split) <= 2, 'hf_hub id should only contain one @ character to identify revision.'\n    hf_model_id = rev_split[0]",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "hf_split",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def hf_split(hf_id):\n    rev_split = hf_id.split('@')\n    assert 0 < len(rev_split) <= 2, 'hf_hub id should only contain one @ character to identify revision.'\n    hf_model_id = rev_split[0]\n    hf_revision = rev_split[-1] if len(rev_split) > 1 else None\n    return hf_model_id, hf_revision\ndef load_cfg_from_json(json_file: Union[str, os.PathLike]):\n    with open(json_file, \"r\", encoding=\"utf-8\") as reader:\n        text = reader.read()\n    return json.loads(text)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "load_cfg_from_json",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def load_cfg_from_json(json_file: Union[str, os.PathLike]):\n    with open(json_file, \"r\", encoding=\"utf-8\") as reader:\n        text = reader.read()\n    return json.loads(text)\ndef _download_from_hf(model_id: str, filename: str):\n    hf_model_id, hf_revision = hf_split(model_id)\n    url = hf_hub_url(hf_model_id, filename, revision=hf_revision)\n    return cached_download(url, cache_dir=get_cache_dir('hf'))\ndef load_model_config_from_hf(model_id: str):\n    assert has_hf_hub(True)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "load_model_config_from_hf",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def load_model_config_from_hf(model_id: str):\n    assert has_hf_hub(True)\n    cached_file = _download_from_hf(model_id, 'config.json')\n    default_cfg = load_cfg_from_json(cached_file)\n    default_cfg['hf_hub'] = model_id  # insert hf_hub id for pretrained weight load during model creation\n    model_name = default_cfg.get('architecture')\n    return default_cfg, model_name\ndef load_state_dict_from_hf(model_id: str):\n    assert has_hf_hub(True)\n    cached_file = _download_from_hf(model_id, 'pytorch_model.bin')",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "load_state_dict_from_hf",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def load_state_dict_from_hf(model_id: str):\n    assert has_hf_hub(True)\n    cached_file = _download_from_hf(model_id, 'pytorch_model.bin')\n    state_dict = torch.load(cached_file, map_location='cpu')\n    return state_dict\ndef save_for_hf(model, save_directory, model_config=None):\n    assert has_hf_hub(True)\n    model_config = model_config or {}\n    save_directory = Path(save_directory)\n    save_directory.mkdir(exist_ok=True, parents=True)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "save_for_hf",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def save_for_hf(model, save_directory, model_config=None):\n    assert has_hf_hub(True)\n    model_config = model_config or {}\n    save_directory = Path(save_directory)\n    save_directory.mkdir(exist_ok=True, parents=True)\n    weights_path = save_directory / 'pytorch_model.bin'\n    torch.save(model.state_dict(), weights_path)\n    config_path = save_directory / 'config.json'\n    hf_config = model.default_cfg\n    hf_config['num_classes'] = model_config.pop('num_classes', model.num_classes)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "push_to_hf_hub",
        "kind": 2,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "def push_to_hf_hub(\n    model,\n    local_dir,\n    repo_namespace_or_url=None,\n    commit_message='Add model',\n    use_auth_token=True,\n    git_email=None,\n    git_user=None,\n    revision=None,\n    model_config=None,",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.hub",
        "description": "timm.models.hub",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef get_cache_dir(child_dir=''):\n    \"\"\"\n    Returns the location of the directory where models are cached (and creates it if necessary).\n    \"\"\"\n    # Issue warning to move data if old env is set\n    if os.getenv('TORCH_MODEL_ZOO'):\n        _logger.warning('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n    hub_dir = get_dir()\n    child_dir = () if not child_dir else (child_dir,)",
        "detail": "timm.models.hub",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class BasicConv2d(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(\n            in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_planes, eps=.001)\n        self.relu = nn.ReLU(inplace=False)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Mixed_5b",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Mixed_5b(nn.Module):\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        )\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Block35",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Block35(nn.Module):\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n        self.scale = scale\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n        self.branch2 = nn.Sequential(",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Mixed_6a",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Mixed_6a(nn.Module):\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n        self.branch2 = nn.MaxPool2d(3, stride=2)",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Block17",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Block17(nn.Module):\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n        self.scale = scale\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n            BasicConv2d(160, 192, kernel_size=(7, 1), stride=1, padding=(3, 0))\n        )",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Mixed_7a",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Mixed_7a(nn.Module):\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "Block8",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class Block8(nn.Module):\n    def __init__(self, scale=1.0, no_relu=False):\n        super(Block8, self).__init__()\n        self.scale = scale\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1, 3), stride=1, padding=(0, 1)),\n            BasicConv2d(224, 256, kernel_size=(3, 1), stride=1, padding=(1, 0))\n        )",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "InceptionResnetV2",
        "kind": 6,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "class InceptionResnetV2(nn.Module):\n    def __init__(self, num_classes=1000, in_chans=3, drop_rate=0., output_stride=32, global_pool='avg'):\n        super(InceptionResnetV2, self).__init__()\n        self.drop_rate = drop_rate\n        self.num_classes = num_classes\n        self.num_features = 1536\n        assert output_stride == 32\n        self.conv2d_1a = BasicConv2d(in_chans, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "inception_resnet_v2",
        "kind": 2,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "def inception_resnet_v2(pretrained=False, **kwargs):\n    r\"\"\"InceptionResnetV2 model architecture from the\n    `\"InceptionV4, Inception-ResNet...\" <https://arxiv.org/abs/1602.07261>` paper.\n    \"\"\"\n    return _create_inception_resnet_v2('inception_resnet_v2', pretrained=pretrained, **kwargs)\n@register_model\ndef ens_adv_inception_resnet_v2(pretrained=False, **kwargs):\n    r\"\"\" Ensemble Adversarially trained InceptionResnetV2 model architecture\n    As per https://arxiv.org/abs/1705.07204 and\n    https://github.com/tensorflow/models/tree/master/research/adv_imagenet_models.",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "ens_adv_inception_resnet_v2",
        "kind": 2,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "def ens_adv_inception_resnet_v2(pretrained=False, **kwargs):\n    r\"\"\" Ensemble Adversarially trained InceptionResnetV2 model architecture\n    As per https://arxiv.org/abs/1705.07204 and\n    https://github.com/tensorflow/models/tree/master/research/adv_imagenet_models.\n    \"\"\"\n    return _create_inception_resnet_v2('ens_adv_inception_resnet_v2', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "__all__ = ['InceptionResnetV2']\ndefault_cfgs = {\n    # ported from http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\n    'inception_resnet_v2': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/inception_resnet_v2-940b1cd6.pth',\n        'num_classes': 1000, 'input_size': (3, 299, 299), 'pool_size': (8, 8),\n        'crop_pct': 0.8975, 'interpolation': 'bicubic',\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'conv2d_1a.conv', 'classifier': 'classif',\n        'label_offset': 1,  # 1001 classes in pretrained weights",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.inception_resnet_v2",
        "description": "timm.models.inception_resnet_v2",
        "peekOfCode": "default_cfgs = {\n    # ported from http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\n    'inception_resnet_v2': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/inception_resnet_v2-940b1cd6.pth',\n        'num_classes': 1000, 'input_size': (3, 299, 299), 'pool_size': (8, 8),\n        'crop_pct': 0.8975, 'interpolation': 'bicubic',\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'conv2d_1a.conv', 'classifier': 'classif',\n        'label_offset': 1,  # 1001 classes in pretrained weights\n    },",
        "detail": "timm.models.inception_resnet_v2",
        "documentation": {}
    },
    {
        "label": "InceptionA",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionA(nn.Module):\n    def __init__(self, in_channels, pool_features, conv_block=None):\n        super(InceptionA, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionB",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionB(nn.Module):\n    def __init__(self, in_channels, conv_block=None):\n        super(InceptionB, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n    def _forward(self, x):",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionC",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionC(nn.Module):\n    def __init__(self, in_channels, channels_7x7, conv_block=None):\n        super(InceptionC, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n        c7 = channels_7x7\n        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionD",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionD(nn.Module):\n    def __init__(self, in_channels, conv_block=None):\n        super(InceptionD, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionE",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionE(nn.Module):\n    def __init__(self, in_channels, conv_block=None):\n        super(InceptionE, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionAux",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionAux(nn.Module):\n    def __init__(self, in_channels, num_classes, conv_block=None):\n        super(InceptionAux, self).__init__()\n        if conv_block is None:\n            conv_block = BasicConv2d\n        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n        self.conv1 = conv_block(128, 768, kernel_size=5)\n        self.conv1.stddev = 0.01\n        self.fc = Linear(768, num_classes)\n        self.fc.stddev = 0.001",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class BasicConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\nclass InceptionV3(nn.Module):",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionV3",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionV3(nn.Module):\n    \"\"\"Inception-V3 with no AuxLogits\n    FIXME two class defs are redundant, but less screwing around with torchsript fussyness and inconsistent returns\n    \"\"\"\n    def __init__(self, num_classes=1000, in_chans=3, drop_rate=0., global_pool='avg', aux_logits=False):\n        super(InceptionV3, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        self.aux_logits = aux_logits\n        self.Conv2d_1a_3x3 = BasicConv2d(in_chans, 32, kernel_size=3, stride=2)",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "InceptionV3Aux",
        "kind": 6,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "class InceptionV3Aux(InceptionV3):\n    \"\"\"InceptionV3 with AuxLogits\n    \"\"\"\n    def __init__(self, num_classes=1000, in_chans=3, drop_rate=0., global_pool='avg', aux_logits=True):\n        super(InceptionV3Aux, self).__init__(\n            num_classes, in_chans, drop_rate, global_pool, aux_logits)\n    def forward_features(self, x):\n        x = self.forward_preaux(x)\n        aux = self.AuxLogits(x) if self.training else None\n        x = self.forward_postaux(x)",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "inception_v3",
        "kind": 2,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "def inception_v3(pretrained=False, **kwargs):\n    # original PyTorch weights, ported from Tensorflow but modified\n    model = _create_inception_v3('inception_v3', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_inception_v3(pretrained=False, **kwargs):\n    # my port of Tensorflow SLIM weights (http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz)\n    model = _create_inception_v3('tf_inception_v3', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "tf_inception_v3",
        "kind": 2,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "def tf_inception_v3(pretrained=False, **kwargs):\n    # my port of Tensorflow SLIM weights (http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz)\n    model = _create_inception_v3('tf_inception_v3', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef adv_inception_v3(pretrained=False, **kwargs):\n    # my port of Tensorflow adversarially trained Inception V3 from\n    # http://download.tensorflow.org/models/adv_inception_v3_2017_08_18.tar.gz\n    model = _create_inception_v3('adv_inception_v3', pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "adv_inception_v3",
        "kind": 2,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "def adv_inception_v3(pretrained=False, **kwargs):\n    # my port of Tensorflow adversarially trained Inception V3 from\n    # http://download.tensorflow.org/models/adv_inception_v3_2017_08_18.tar.gz\n    model = _create_inception_v3('adv_inception_v3', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef gluon_inception_v3(pretrained=False, **kwargs):\n    # from gluon pretrained models, best performing in terms of accuracy/loss metrics\n    # https://gluon-cv.mxnet.io/model_zoo/classification.html\n    model = _create_inception_v3('gluon_inception_v3', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "gluon_inception_v3",
        "kind": 2,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "def gluon_inception_v3(pretrained=False, **kwargs):\n    # from gluon pretrained models, best performing in terms of accuracy/loss metrics\n    # https://gluon-cv.mxnet.io/model_zoo/classification.html\n    model = _create_inception_v3('gluon_inception_v3', pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.inception_v3",
        "description": "timm.models.inception_v3",
        "peekOfCode": "default_cfgs = {\n    # original PyTorch weights, ported from Tensorflow but modified\n    'inception_v3': _cfg(\n        url='https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n        has_aux=True),  # checkpoint has aux logit layer weights\n    # my port of Tensorflow SLIM weights (http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz)\n    'tf_inception_v3': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_inception_v3-e0069de4.pth',\n        num_classes=1000, has_aux=False, label_offset=1),\n    # my port of Tensorflow adversarially trained Inception V3 from",
        "detail": "timm.models.inception_v3",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class BasicConv2d(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(\n            in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_planes, eps=0.001)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "Mixed3a",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class Mixed3a(nn.Module):\n    def __init__(self):\n        super(Mixed3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "Mixed4a",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class Mixed4a(nn.Module):\n    def __init__(self):\n        super(Mixed4a, self).__init__()\n        self.branch0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n        self.branch1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1, 7), stride=1, padding=(0, 3)),",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "Mixed5a",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class Mixed5a(nn.Module):\n    def __init__(self):\n        super(Mixed5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "InceptionA",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class InceptionA(nn.Module):\n    def __init__(self):\n        super(InceptionA, self).__init__()\n        self.branch0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n        self.branch2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "ReductionA",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class ReductionA(nn.Module):\n    def __init__(self):\n        super(ReductionA, self).__init__()\n        self.branch0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        self.branch2 = nn.MaxPool2d(3, stride=2)",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "InceptionB",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class InceptionB(nn.Module):\n    def __init__(self):\n        super(InceptionB, self).__init__()\n        self.branch0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n            BasicConv2d(224, 256, kernel_size=(7, 1), stride=1, padding=(3, 0))\n        )\n        self.branch2 = nn.Sequential(",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "ReductionB",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class ReductionB(nn.Module):\n    def __init__(self):\n        super(ReductionB, self).__init__()\n        self.branch0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1, 7), stride=1, padding=(0, 3)),",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "InceptionC",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class InceptionC(nn.Module):\n    def __init__(self):\n        super(InceptionC, self).__init__()\n        self.branch0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        self.branch1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.branch1_1a = BasicConv2d(384, 256, kernel_size=(1, 3), stride=1, padding=(0, 1))\n        self.branch1_1b = BasicConv2d(384, 256, kernel_size=(3, 1), stride=1, padding=(1, 0))\n        self.branch2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.branch2_1 = BasicConv2d(384, 448, kernel_size=(3, 1), stride=1, padding=(1, 0))\n        self.branch2_2 = BasicConv2d(448, 512, kernel_size=(1, 3), stride=1, padding=(0, 1))",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "InceptionV4",
        "kind": 6,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "class InceptionV4(nn.Module):\n    def __init__(self, num_classes=1000, in_chans=3, output_stride=32, drop_rate=0., global_pool='avg'):\n        super(InceptionV4, self).__init__()\n        assert output_stride == 32\n        self.drop_rate = drop_rate\n        self.num_classes = num_classes\n        self.num_features = 1536\n        self.features = nn.Sequential(\n            BasicConv2d(in_chans, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "inception_v4",
        "kind": 2,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "def inception_v4(pretrained=False, **kwargs):\n    return _create_inception_v4('inception_v4', pretrained, **kwargs)",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "__all__ = ['InceptionV4']\ndefault_cfgs = {\n    'inception_v4': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/inceptionv4-8e4777a0.pth',\n        'num_classes': 1000, 'input_size': (3, 299, 299), 'pool_size': (8, 8),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'features.0.conv', 'classifier': 'last_linear',\n        'label_offset': 1,  # 1001 classes in pretrained weights\n    }",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.inception_v4",
        "description": "timm.models.inception_v4",
        "peekOfCode": "default_cfgs = {\n    'inception_v4': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/inceptionv4-8e4777a0.pth',\n        'num_classes': 1000, 'input_size': (3, 299, 299), 'pool_size': (8, 8),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'features.0.conv', 'classifier': 'last_linear',\n        'label_offset': 1,  # 1001 classes in pretrained weights\n    }\n}",
        "detail": "timm.models.inception_v4",
        "documentation": {}
    },
    {
        "label": "ConvNorm",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class ConvNorm(nn.Sequential):\n    def __init__(\n            self, a, b, ks=1, stride=1, pad=0, dilation=1, groups=1, bn_weight_init=1, resolution=-10000):\n        super().__init__()\n        self.add_module('c', nn.Conv2d(a, b, ks, stride, pad, dilation, groups, bias=False))\n        bn = nn.BatchNorm2d(b)\n        nn.init.constant_(bn.weight, bn_weight_init)\n        nn.init.constant_(bn.bias, 0)\n        self.add_module('bn', bn)\n    @torch.no_grad()",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "LinearNorm",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class LinearNorm(nn.Sequential):\n    def __init__(self, a, b, bn_weight_init=1, resolution=-100000):\n        super().__init__()\n        self.add_module('c', nn.Linear(a, b, bias=False))\n        bn = nn.BatchNorm1d(b)\n        nn.init.constant_(bn.weight, bn_weight_init)\n        nn.init.constant_(bn.bias, 0)\n        self.add_module('bn', bn)\n    @torch.no_grad()\n    def fuse(self):",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "NormLinear",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class NormLinear(nn.Sequential):\n    def __init__(self, a, b, bias=True, std=0.02):\n        super().__init__()\n        self.add_module('bn', nn.BatchNorm1d(a))\n        l = nn.Linear(a, b, bias=bias)\n        trunc_normal_(l.weight, std=std)\n        if bias:\n            nn.init.constant_(l.bias, 0)\n        self.add_module('l', l)\n    @torch.no_grad()",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "Residual",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class Residual(nn.Module):\n    def __init__(self, m, drop):\n        super().__init__()\n        self.m = m\n        self.drop = drop\n    def forward(self, x):\n        if self.training and self.drop > 0:\n            return x + self.m(x) * torch.rand(\n                x.size(0), 1, 1, device=x.device).ge_(self.drop).div(1 - self.drop).detach()\n        else:",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "Subsample",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class Subsample(nn.Module):\n    def __init__(self, stride, resolution):\n        super().__init__()\n        self.stride = stride\n        self.resolution = resolution\n    def forward(self, x):\n        B, N, C = x.shape\n        x = x.view(B, self.resolution, self.resolution, C)[:, ::self.stride, ::self.stride]\n        return x.reshape(B, -1, C)\nclass Attention(nn.Module):",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class Attention(nn.Module):\n    ab: Dict[str, torch.Tensor]\n    def __init__(\n            self, dim, key_dim, num_heads=8, attn_ratio=4, act_layer=None, resolution=14, use_conv=False):\n        super().__init__()\n        self.num_heads = num_heads\n        self.scale = key_dim ** -0.5\n        self.key_dim = key_dim\n        self.nh_kd = nh_kd = key_dim * num_heads\n        self.d = int(attn_ratio * key_dim)",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "AttentionSubsample",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class AttentionSubsample(nn.Module):\n    ab: Dict[str, torch.Tensor]\n    def __init__(\n            self, in_dim, out_dim, key_dim, num_heads=8, attn_ratio=2,\n            act_layer=None, stride=2, resolution=14, resolution_=7, use_conv=False):\n        super().__init__()\n        self.num_heads = num_heads\n        self.scale = key_dim ** -0.5\n        self.key_dim = key_dim\n        self.nh_kd = nh_kd = key_dim * num_heads",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "Levit",
        "kind": 6,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "class Levit(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    NOTE: distillation is defaulted to True since pretrained weights use it, will cause problems\n    w/ train scripts that don't take tuple outputs,\n    \"\"\"\n    def __init__(\n            self,\n            img_size=224,\n            patch_size=16,\n            in_chans=3,",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "levit_128s",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def levit_128s(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_128s', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_128(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_128', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_192(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "levit_128",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def levit_128(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_128', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_192(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_192', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_256(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "levit_192",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def levit_192(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_192', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_256(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_256', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_384(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "levit_256",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def levit_256(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_256', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_384(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_384', pretrained=pretrained, use_conv=use_conv, **kwargs)\nclass ConvNorm(nn.Sequential):\n    def __init__(\n            self, a, b, ks=1, stride=1, pad=0, dilation=1, groups=1, bn_weight_init=1, resolution=-10000):",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "levit_384",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def levit_384(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_384', pretrained=pretrained, use_conv=use_conv, **kwargs)\nclass ConvNorm(nn.Sequential):\n    def __init__(\n            self, a, b, ks=1, stride=1, pad=0, dilation=1, groups=1, bn_weight_init=1, resolution=-10000):\n        super().__init__()\n        self.add_module('c', nn.Conv2d(a, b, ks, stride, pad, dilation, groups, bias=False))\n        bn = nn.BatchNorm2d(b)\n        nn.init.constant_(bn.weight, bn_weight_init)",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "stem_b16",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def stem_b16(in_chs, out_chs, activation, resolution=224):\n    return nn.Sequential(\n        ConvNorm(in_chs, out_chs // 8, 3, 2, 1, resolution=resolution),\n        activation(),\n        ConvNorm(out_chs // 8, out_chs // 4, 3, 2, 1, resolution=resolution // 2),\n        activation(),\n        ConvNorm(out_chs // 4, out_chs // 2, 3, 2, 1, resolution=resolution // 4),\n        activation(),\n        ConvNorm(out_chs // 2, out_chs, 3, 2, 1, resolution=resolution // 8))\nclass Residual(nn.Module):",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    if 'model' in state_dict:\n        # For deit models\n        state_dict = state_dict['model']\n    D = model.state_dict()\n    for k in state_dict.keys():\n        if k in D and D[k].ndim == 4 and state_dict[k].ndim == 2:\n            state_dict[k] = state_dict[k][:, :, None, None]\n    return state_dict\ndef create_levit(variant, pretrained=False, default_cfg=None, fuse=False, **kwargs):",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "create_levit",
        "kind": 2,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "def create_levit(variant, pretrained=False, default_cfg=None, fuse=False, **kwargs):\n    if kwargs.get('features_only', None):\n        raise RuntimeError('features_only not implemented for Vision Transformer models.')\n    model_cfg = dict(**model_cfgs[variant], **kwargs)\n    model = build_model_with_cfg(\n        Levit, variant, pretrained,\n        default_cfg=default_cfgs[variant],\n        pretrained_filter_fn=checkpoint_filter_fn,\n        **model_cfg)\n    #if fuse:",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "default_cfgs = dict(\n    levit_128s=_cfg(\n        url='https://dl.fbaipublicfiles.com/LeViT/LeViT-128S-96703c44.pth'\n    ),\n    levit_128=_cfg(\n        url='https://dl.fbaipublicfiles.com/LeViT/LeViT-128-b88c2750.pth'\n    ),\n    levit_192=_cfg(\n        url='https://dl.fbaipublicfiles.com/LeViT/LeViT-192-92712e41.pth'\n    ),",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "model_cfgs = dict(\n    levit_128s=dict(\n        embed_dim=(128, 256, 384), key_dim=16, num_heads=(4, 6, 8), depth=(2, 3, 4)),\n    levit_128=dict(\n        embed_dim=(128, 256, 384), key_dim=16, num_heads=(4, 8, 12), depth=(4, 4, 4)),\n    levit_192=dict(\n        embed_dim=(192, 288, 384), key_dim=32, num_heads=(3, 5, 6), depth=(4, 4, 4)),\n    levit_256=dict(\n        embed_dim=(256, 384, 512), key_dim=32, num_heads=(4, 6, 8), depth=(4, 4, 4)),\n    levit_384=dict(",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.levit",
        "description": "timm.models.levit",
        "peekOfCode": "__all__ = ['Levit']\n@register_model\ndef levit_128s(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_128s', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model\ndef levit_128(pretrained=False, use_conv=False, **kwargs):\n    return create_levit(\n        'levit_128', pretrained=pretrained, use_conv=use_conv, **kwargs)\n@register_model",
        "detail": "timm.models.levit",
        "documentation": {}
    },
    {
        "label": "MixerBlock",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class MixerBlock(nn.Module):\n    \"\"\" Residual Block w/ token mixing and channel MLPs\n    Based on: 'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    def __init__(\n            self, dim, seq_len, mlp_ratio=(0.5, 4.0), mlp_layer=Mlp,\n            norm_layer=partial(nn.LayerNorm, eps=1e-6), act_layer=nn.GELU, drop=0., drop_path=0.):\n        super().__init__()\n        tokens_dim, channels_dim = [int(x * dim) for x in to_2tuple(mlp_ratio)]\n        self.norm1 = norm_layer(dim)",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "Affine",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class Affine(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.alpha = nn.Parameter(torch.ones((1, 1, dim)))\n        self.beta = nn.Parameter(torch.zeros((1, 1, dim)))\n    def forward(self, x):\n        return torch.addcmul(self.beta, self.alpha, x)\nclass ResBlock(nn.Module):\n    \"\"\" Residual MLP block w/ LayerScale and Affine 'norm'\n    Based on: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "ResBlock",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class ResBlock(nn.Module):\n    \"\"\" Residual MLP block w/ LayerScale and Affine 'norm'\n    Based on: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    def __init__(\n            self, dim, seq_len, mlp_ratio=4, mlp_layer=Mlp, norm_layer=Affine,\n            act_layer=nn.GELU, init_values=1e-4, drop=0., drop_path=0.):\n        super().__init__()\n        channel_dim = int(dim * mlp_ratio)\n        self.norm1 = norm_layer(dim)",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "SpatialGatingUnit",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class SpatialGatingUnit(nn.Module):\n    \"\"\" Spatial Gating Unit\n    Based on: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"\n    def __init__(self, dim, seq_len, norm_layer=nn.LayerNorm):\n        super().__init__()\n        gate_dim = dim // 2\n        self.norm = norm_layer(gate_dim)\n        self.proj = nn.Linear(seq_len, seq_len)\n    def init_weights(self):",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "SpatialGatingBlock",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class SpatialGatingBlock(nn.Module):\n    \"\"\" Residual Block w/ Spatial Gating\n    Based on: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"\n    def __init__(\n            self, dim, seq_len, mlp_ratio=4, mlp_layer=GatedMlp,\n            norm_layer=partial(nn.LayerNorm, eps=1e-6), act_layer=nn.GELU, drop=0., drop_path=0.):\n        super().__init__()\n        channel_dim = int(dim * mlp_ratio)\n        self.norm = norm_layer(dim)",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "MlpMixer",
        "kind": 6,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "class MlpMixer(nn.Module):\n    def __init__(\n            self,\n            num_classes=1000,\n            img_size=224,\n            in_chans=3,\n            patch_size=16,\n            num_blocks=8,\n            embed_dim=512,\n            mlp_ratio=(0.5, 4.0),",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" Remap checkpoints if needed \"\"\"\n    if 'patch_embed.proj.weight' in state_dict:\n        # Remap FB ResMlp models -> timm\n        out_dict = {}\n        for k, v in state_dict.items():\n            k = k.replace('patch_embed.', 'stem.')\n            k = k.replace('attn.', 'linear_tokens.')\n            k = k.replace('mlp.', 'mlp_channels.')\n            k = k.replace('gamma_', 'ls')",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_s32_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_s32_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-S/32 224x224\n    Paper: 'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=32, num_blocks=8, embed_dim=512, **kwargs)\n    model = _create_mixer('mixer_s32_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_s16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-S/16 224x224",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_s16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_s16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-S/16 224x224\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=8, embed_dim=512, **kwargs)\n    model = _create_mixer('mixer_s16_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_b32_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/32 224x224",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_b32_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_b32_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/32 224x224\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=32, num_blocks=12, embed_dim=768, **kwargs)\n    model = _create_mixer('mixer_b32_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_b16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_b16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_b16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=12, embed_dim=768, **kwargs)\n    model = _create_mixer('mixer_b16_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_b16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_b16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_b16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=12, embed_dim=768, **kwargs)\n    model = _create_mixer('mixer_b16_224_in21k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_l32_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/32 224x224.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_l32_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_l32_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/32 224x224.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=32, num_blocks=24, embed_dim=1024, **kwargs)\n    model = _create_mixer('mixer_l32_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_l16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/16 224x224. ImageNet-1k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_l16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_l16_224(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/16 224x224. ImageNet-1k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=24, embed_dim=1024, **kwargs)\n    model = _create_mixer('mixer_l16_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_l16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/16 224x224. ImageNet-21k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_l16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_l16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-L/16 224x224. ImageNet-21k pretrained weights.\n    Paper:  'MLP-Mixer: An all-MLP Architecture for Vision' - https://arxiv.org/abs/2105.01601\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=24, embed_dim=1024, **kwargs)\n    model = _create_mixer('mixer_l16_224_in21k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_b16_224_miil(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_b16_224_miil",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_b16_224_miil(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-21k pretrained weights.\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=12, embed_dim=768, **kwargs)\n    model = _create_mixer('mixer_b16_224_miil', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef mixer_b16_224_miil_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "mixer_b16_224_miil_in21k",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def mixer_b16_224_miil_in21k(pretrained=False, **kwargs):\n    \"\"\" Mixer-B/16 224x224. ImageNet-1k pretrained weights.\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model_args = dict(patch_size=16, num_blocks=12, embed_dim=768, **kwargs)\n    model = _create_mixer('mixer_b16_224_miil_in21k', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef gmixer_12_224(pretrained=False, **kwargs):\n    \"\"\" Glu-Mixer-12 224x224",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "gmixer_12_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def gmixer_12_224(pretrained=False, **kwargs):\n    \"\"\" Glu-Mixer-12 224x224\n    Experiment by Ross Wightman, adding (Si)GLU to MLP-Mixer\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=(1.0, 4.0),\n        mlp_layer=GluMlp, act_layer=nn.SiLU, **kwargs)\n    model = _create_mixer('gmixer_12_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "gmixer_24_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def gmixer_24_224(pretrained=False, **kwargs):\n    \"\"\" Glu-Mixer-24 224x224\n    Experiment by Ross Wightman, adding (Si)GLU to MLP-Mixer\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=24, embed_dim=384, mlp_ratio=(1.0, 4.0),\n        mlp_layer=GluMlp, act_layer=nn.SiLU, **kwargs)\n    model = _create_mixer('gmixer_24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_12_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_12_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=4, block_layer=ResBlock, norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_12_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef resmlp_24_224(pretrained=False, **kwargs):",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_24_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_24_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=24, embed_dim=384, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-5), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_36_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_36_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-36\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=36, embed_dim=384, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_36_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_big_24_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_big_24_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=8, num_blocks=24, embed_dim=768, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_big_24_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_12_distilled_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_12_distilled_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=4, block_layer=ResBlock, norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_12_distilled_224', pretrained=pretrained, **model_args)\n    return model\n@register_model\ndef resmlp_24_distilled_224(pretrained=False, **kwargs):",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_24_distilled_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_24_distilled_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=24, embed_dim=384, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-5), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_24_distilled_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_36_distilled_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_36_distilled_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-36\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=36, embed_dim=384, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_36_distilled_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_big_24_distilled_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_big_24_distilled_224(pretrained=False, **kwargs):\n    \"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=8, num_blocks=24, embed_dim=768, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_big_24_distilled_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_big_24_224_in22ft1k",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_big_24_224_in22ft1k(pretrained=False, **kwargs):\n    \"\"\" ResMLP-B-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    \"\"\"\n    model_args = dict(\n        patch_size=8, num_blocks=24, embed_dim=768, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-6), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_big_24_224_in22ft1k', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_12_224_dino",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_12_224_dino(pretrained=False, **kwargs):\n    \"\"\" ResMLP-12\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    Model pretrained via DINO (self-supervised) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=12, embed_dim=384, mlp_ratio=4, block_layer=ResBlock, norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_12_224_dino', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "resmlp_24_224_dino",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def resmlp_24_224_dino(pretrained=False, **kwargs):\n    \"\"\" ResMLP-24\n    Paper: `ResMLP: Feedforward networks for image classification...` - https://arxiv.org/abs/2105.03404\n    Model pretrained via DINO (self-supervised) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=24, embed_dim=384, mlp_ratio=4,\n        block_layer=partial(ResBlock, init_values=1e-5), norm_layer=Affine, **kwargs)\n    model = _create_mixer('resmlp_24_224_dino', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "gmlp_ti16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def gmlp_ti16_224(pretrained=False, **kwargs):\n    \"\"\" gMLP-Tiny\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=30, embed_dim=128, mlp_ratio=6, block_layer=SpatialGatingBlock,\n        mlp_layer=GatedMlp, **kwargs)\n    model = _create_mixer('gmlp_ti16_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "gmlp_s16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def gmlp_s16_224(pretrained=False, **kwargs):\n    \"\"\" gMLP-Small\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=30, embed_dim=256, mlp_ratio=6, block_layer=SpatialGatingBlock,\n        mlp_layer=GatedMlp, **kwargs)\n    model = _create_mixer('gmlp_s16_224', pretrained=pretrained, **model_args)\n    return model\n@register_model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "gmlp_b16_224",
        "kind": 2,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "def gmlp_b16_224(pretrained=False, **kwargs):\n    \"\"\" gMLP-Base\n    Paper: `Pay Attention to MLPs` - https://arxiv.org/abs/2105.08050\n    \"\"\"\n    model_args = dict(\n        patch_size=16, num_blocks=30, embed_dim=512, mlp_ratio=6, block_layer=SpatialGatingBlock,\n        mlp_layer=GatedMlp, **kwargs)\n    model = _create_mixer('gmlp_b16_224', pretrained=pretrained, **model_args)\n    return model",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.mlp_mixer",
        "description": "timm.models.mlp_mixer",
        "peekOfCode": "default_cfgs = dict(\n    mixer_s32_224=_cfg(),\n    mixer_s16_224=_cfg(),\n    mixer_b32_224=_cfg(),\n    mixer_b16_224=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224-76587d61.pth',\n    ),\n    mixer_b16_224_in21k=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224_in21k-617b3de2.pth',\n        num_classes=21843",
        "detail": "timm.models.mlp_mixer",
        "documentation": {}
    },
    {
        "label": "MobileNetV3",
        "kind": 6,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "class MobileNetV3(nn.Module):\n    \"\"\" MobiletNet-V3\n    Based on my EfficientNet implementation and building blocks, this model utilizes the MobileNet-v3 specific\n    'efficient head', where global pooling is done before the head convolution without a final batch-norm\n    layer before the classifier.\n    Paper: `Searching for MobileNetV3` - https://arxiv.org/abs/1905.02244\n    Other architectures utilizing MobileNet-V3 efficient head that are supported by this impl include:\n      * HardCoRe-NAS - https://arxiv.org/abs/2102.11646 (defn in hardcorenas.py uses this class)\n      * FBNet-V3 - https://arxiv.org/abs/2006.02049\n      * LCNet - https://arxiv.org/abs/2109.15099",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "MobileNetV3Features",
        "kind": 6,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "class MobileNetV3Features(nn.Module):\n    \"\"\" MobileNetV3 Feature Extractor\n    A work-in-progress feature extraction module for MobileNet-V3 to use as a backbone for segmentation\n    and object detection models.\n    \"\"\"\n    def __init__(self, block_args, out_indices=(0, 1, 2, 3, 4), feature_location='bottleneck', in_chans=3,\n                 stem_size=16, fix_stem=False, output_stride=32, pad_type='', round_chs_fn=round_channels,\n                 se_from_exp=True, act_layer=None, norm_layer=None, se_layer=None, drop_rate=0., drop_path_rate=0.):\n        super(MobileNetV3Features, self).__init__()\n        act_layer = act_layer or nn.ReLU",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_large_075",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_large_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_large_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_large_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_large_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_large_100_miil(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_100_miil', 1.0, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_large_100_miil",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_large_100_miil(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_100_miil', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_large_100_miil_in21k(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3, 21k pretraining\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_large_100_miil_in21k",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_large_100_miil_in21k(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3, 21k pretraining\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_large_100_miil_in21k', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_small_050(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_050', 0.50, pretrained=pretrained, **kwargs)",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_small_050",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_small_050(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_050', 0.50, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_small_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_small_075",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_small_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_small_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_small_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_small_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    model = _gen_mobilenet_v3('mobilenetv3_small_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef mobilenetv3_rw(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    if pretrained:\n        # pretrained model trained with non-default BN epsilon\n        kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_rw",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def mobilenetv3_rw(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    if pretrained:\n        # pretrained model trained with non-default BN epsilon\n        kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    model = _gen_mobilenet_v3_rw('mobilenetv3_rw', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_large_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_large_075",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_large_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_large_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_large_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_large_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_large_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_large_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_large_minimal_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_large_minimal_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_large_minimal_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_large_minimal_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_small_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_small_075",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_small_075(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_small_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_small_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_small_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_small_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_small_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef tf_mobilenetv3_small_minimal_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "tf_mobilenetv3_small_minimal_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def tf_mobilenetv3_small_minimal_100(pretrained=False, **kwargs):\n    \"\"\" MobileNet V3 \"\"\"\n    kwargs['bn_eps'] = BN_EPS_TF_DEFAULT\n    kwargs['pad_type'] = 'same'\n    model = _gen_mobilenet_v3('tf_mobilenetv3_small_minimal_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef fbnetv3_b(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-B \"\"\"\n    model = _gen_fbnetv3('fbnetv3_b', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "fbnetv3_b",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def fbnetv3_b(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-B \"\"\"\n    model = _gen_fbnetv3('fbnetv3_b', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef fbnetv3_d(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-D \"\"\"\n    model = _gen_fbnetv3('fbnetv3_d', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "fbnetv3_d",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def fbnetv3_d(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-D \"\"\"\n    model = _gen_fbnetv3('fbnetv3_d', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef fbnetv3_g(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-G \"\"\"\n    model = _gen_fbnetv3('fbnetv3_g', pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "fbnetv3_g",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def fbnetv3_g(pretrained=False, **kwargs):\n    \"\"\" FBNetV3-G \"\"\"\n    model = _gen_fbnetv3('fbnetv3_g', pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef lcnet_035(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 0.35\"\"\"\n    model = _gen_lcnet('lcnet_035', 0.35, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "lcnet_035",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def lcnet_035(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 0.35\"\"\"\n    model = _gen_lcnet('lcnet_035', 0.35, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef lcnet_050(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 0.5\"\"\"\n    model = _gen_lcnet('lcnet_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "lcnet_050",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def lcnet_050(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 0.5\"\"\"\n    model = _gen_lcnet('lcnet_050', 0.5, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef lcnet_075(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.0\"\"\"\n    model = _gen_lcnet('lcnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "lcnet_075",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def lcnet_075(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.0\"\"\"\n    model = _gen_lcnet('lcnet_075', 0.75, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef lcnet_100(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.0\"\"\"\n    model = _gen_lcnet('lcnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "lcnet_100",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def lcnet_100(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.0\"\"\"\n    model = _gen_lcnet('lcnet_100', 1.0, pretrained=pretrained, **kwargs)\n    return model\n@register_model\ndef lcnet_150(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.5\"\"\"\n    model = _gen_lcnet('lcnet_150', 1.5, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "lcnet_150",
        "kind": 2,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "def lcnet_150(pretrained=False, **kwargs):\n    \"\"\" PP-LCNet 1.5\"\"\"\n    model = _gen_lcnet('lcnet_150', 1.5, pretrained=pretrained, **kwargs)\n    return model",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "__all__ = ['MobileNetV3', 'MobileNetV3Features']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (1, 1),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv_stem', 'classifier': 'classifier',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.mobilenetv3",
        "description": "timm.models.mobilenetv3",
        "peekOfCode": "default_cfgs = {\n    'mobilenetv3_large_075': _cfg(url=''),\n    'mobilenetv3_large_100': _cfg(\n        interpolation='bicubic',\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth'),\n    'mobilenetv3_large_100_miil': _cfg(\n        interpolation='bilinear', mean=(0, 0, 0), std=(1, 1, 1),\n        url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/model-zoo/ImageNet_21K_P/models/timm/mobilenetv3_large_100_1k_miil_78_0.pth'),\n    'mobilenetv3_large_100_miil_in21k': _cfg(\n        interpolation='bilinear', mean=(0, 0, 0), std=(1, 1, 1),",
        "detail": "timm.models.mobilenetv3",
        "documentation": {}
    },
    {
        "label": "ActConvBn",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class ActConvBn(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=''):\n        super(ActConvBn, self).__init__()\n        self.act = nn.ReLU()\n        self.conv = create_conv2d(\n            in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1)\n    def forward(self, x):\n        x = self.act(x)\n        x = self.conv(x)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=''):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = create_conv2d(\n            in_channels, in_channels, kernel_size=kernel_size,\n            stride=stride, padding=padding, groups=in_channels)\n        self.pointwise_conv2d = create_conv2d(\n            in_channels, out_channels, kernel_size=1, padding=0)\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "BranchSeparables",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class BranchSeparables(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, pad_type='', stem_cell=False):\n        super(BranchSeparables, self).__init__()\n        middle_channels = out_channels if stem_cell else in_channels\n        self.act_1 = nn.ReLU()\n        self.separable_1 = SeparableConv2d(\n            in_channels, middle_channels, kernel_size, stride=stride, padding=pad_type)\n        self.bn_sep_1 = nn.BatchNorm2d(middle_channels, eps=0.001, momentum=0.1)\n        self.act_2 = nn.ReLU(inplace=True)\n        self.separable_2 = SeparableConv2d(",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "CellStem0",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class CellStem0(nn.Module):\n    def __init__(self, stem_size, num_channels=42, pad_type=''):\n        super(CellStem0, self).__init__()\n        self.num_channels = num_channels\n        self.stem_size = stem_size\n        self.conv_1x1 = ActConvBn(self.stem_size, self.num_channels, 1, stride=1)\n        self.comb_iter_0_left = BranchSeparables(self.num_channels, self.num_channels, 5, 2, pad_type)\n        self.comb_iter_0_right = BranchSeparables(self.stem_size, self.num_channels, 7, 2, pad_type, stem_cell=True)\n        self.comb_iter_1_left = create_pool2d('max', 3, 2, padding=pad_type)\n        self.comb_iter_1_right = BranchSeparables(self.stem_size, self.num_channels, 7, 2, pad_type, stem_cell=True)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "CellStem1",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class CellStem1(nn.Module):\n    def __init__(self, stem_size, num_channels, pad_type=''):\n        super(CellStem1, self).__init__()\n        self.num_channels = num_channels\n        self.stem_size = stem_size\n        self.conv_1x1 = ActConvBn(2 * self.num_channels, self.num_channels, 1, stride=1)\n        self.act = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module('conv', nn.Conv2d(self.stem_size, self.num_channels // 2, 1, stride=1, bias=False))",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "FirstCell",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class FirstCell(nn.Module):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type=''):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = ActConvBn(in_chs_right, out_chs_right, 1, stride=1)\n        self.act = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module('conv', nn.Conv2d(in_chs_left, out_chs_left, 1, stride=1, bias=False))\n        self.path_2 = nn.Sequential()\n        self.path_2.add_module('pad', nn.ZeroPad2d((-1, 1, -1, 1)))",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "NormalCell",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class NormalCell(nn.Module):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type=''):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = ActConvBn(in_chs_left, out_chs_left, 1, stride=1, padding=pad_type)\n        self.conv_1x1 = ActConvBn(in_chs_right, out_chs_right, 1, stride=1, padding=pad_type)\n        self.comb_iter_0_left = BranchSeparables(out_chs_right, out_chs_right, 5, 1, pad_type)\n        self.comb_iter_0_right = BranchSeparables(out_chs_left, out_chs_left, 3, 1, pad_type)\n        self.comb_iter_1_left = BranchSeparables(out_chs_left, out_chs_left, 5, 1, pad_type)\n        self.comb_iter_1_right = BranchSeparables(out_chs_left, out_chs_left, 3, 1, pad_type)\n        self.comb_iter_2_left = create_pool2d('avg', 3, 1, count_include_pad=False, padding=pad_type)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "ReductionCell0",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class ReductionCell0(nn.Module):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type=''):\n        super(ReductionCell0, self).__init__()\n        self.conv_prev_1x1 = ActConvBn(in_chs_left, out_chs_left, 1, stride=1, padding=pad_type)\n        self.conv_1x1 = ActConvBn(in_chs_right, out_chs_right, 1, stride=1, padding=pad_type)\n        self.comb_iter_0_left = BranchSeparables(out_chs_right, out_chs_right, 5, 2, pad_type)\n        self.comb_iter_0_right = BranchSeparables(out_chs_right, out_chs_right, 7, 2, pad_type)\n        self.comb_iter_1_left = create_pool2d('max', 3, 2, padding=pad_type)\n        self.comb_iter_1_right = BranchSeparables(out_chs_right, out_chs_right, 7, 2, pad_type)\n        self.comb_iter_2_left = create_pool2d('avg', 3, 2, count_include_pad=False, padding=pad_type)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "ReductionCell1",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class ReductionCell1(nn.Module):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type=''):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = ActConvBn(in_chs_left, out_chs_left, 1, stride=1, padding=pad_type)\n        self.conv_1x1 = ActConvBn(in_chs_right, out_chs_right, 1, stride=1, padding=pad_type)\n        self.comb_iter_0_left = BranchSeparables(out_chs_right, out_chs_right, 5, 2, pad_type)\n        self.comb_iter_0_right = BranchSeparables(out_chs_right, out_chs_right, 7, 2, pad_type)\n        self.comb_iter_1_left = create_pool2d('max', 3, 2, padding=pad_type)\n        self.comb_iter_1_right = BranchSeparables(out_chs_right, out_chs_right, 7, 2, pad_type)\n        self.comb_iter_2_left = create_pool2d('avg', 3, 2, count_include_pad=False, padding=pad_type)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "NASNetALarge",
        "kind": 6,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "class NASNetALarge(nn.Module):\n    \"\"\"NASNetALarge (6 @ 4032) \"\"\"\n    def __init__(self, num_classes=1000, in_chans=3, stem_size=96, channel_multiplier=2,\n                 num_features=4032, output_stride=32, drop_rate=0., global_pool='avg', pad_type='same'):\n        super(NASNetALarge, self).__init__()\n        self.num_classes = num_classes\n        self.stem_size = stem_size\n        self.num_features = num_features\n        self.channel_multiplier = channel_multiplier\n        self.drop_rate = drop_rate",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "nasnetalarge",
        "kind": 2,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "def nasnetalarge(pretrained=False, **kwargs):\n    \"\"\"NASNet-A large model architecture.\n    \"\"\"\n    model_kwargs = dict(pad_type='same', **kwargs)\n    return _create_nasnet('nasnetalarge', pretrained, **model_kwargs)",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "__all__ = ['NASNetALarge']\ndefault_cfgs = {\n    'nasnetalarge': {\n        'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n        'input_size': (3, 331, 331),\n        'pool_size': (11, 11),\n        'crop_pct': 0.911,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.nasnet",
        "description": "timm.models.nasnet",
        "peekOfCode": "default_cfgs = {\n    'nasnetalarge': {\n        'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n        'input_size': (3, 331, 331),\n        'pool_size': (11, 11),\n        'crop_pct': 0.911,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),\n        'num_classes': 1000,",
        "detail": "timm.models.nasnet",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "class Attention(nn.Module):\n    \"\"\"\n    This is much like `.vision_transformer.Attention` but uses *localised* self attention by accepting an input with\n     an extra \"image block\" dim\n    \"\"\"\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "TransformerLayer",
        "kind": 6,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "class TransformerLayer(nn.Module):\n    \"\"\"\n    This is much like `.vision_transformer.Block` but:\n        - Called TransformerLayer here to allow for \"block\" as defined in the paper (\"non-overlapping image blocks\")\n        - Uses modified Attention layer that handles the \"block\" dimension\n    \"\"\"\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.norm1 = norm_layer(dim)",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "ConvPool",
        "kind": 6,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "class ConvPool(nn.Module):\n    def __init__(self, in_channels, out_channels, norm_layer, pad_type=''):\n        super().__init__()\n        self.conv = create_conv2d(in_channels, out_channels, kernel_size=3, padding=pad_type, bias=True)\n        self.norm = norm_layer(out_channels)\n        self.pool = create_pool2d('max', kernel_size=3, stride=2, padding=pad_type)\n    def forward(self, x):\n        \"\"\"\n        x is expected to have shape (B, C, H, W)\n        \"\"\"",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "NestLevel",
        "kind": 6,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "class NestLevel(nn.Module):\n    \"\"\" Single hierarchical level of a Nested Transformer\n    \"\"\"\n    def __init__(\n            self, num_blocks, block_size, seq_length, num_heads, depth, embed_dim, prev_embed_dim=None,\n            mlp_ratio=4., qkv_bias=True, drop_rate=0., attn_drop_rate=0., drop_path_rates=[],\n            norm_layer=None, act_layer=None, pad_type=''):\n        super().__init__()\n        self.block_size = block_size\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_blocks, seq_length, embed_dim))",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "Nest",
        "kind": 6,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "class Nest(nn.Module):\n    \"\"\" Nested Transformer (NesT)\n    A PyTorch impl of : `Aggregating Nested Transformers`\n        - https://arxiv.org/abs/2105.12723\n    \"\"\"\n    def __init__(self, img_size=224, in_chans=3, patch_size=4, num_levels=3, embed_dims=(128, 256, 512),\n                 num_heads=(4, 8, 16), depths=(2, 2, 20), num_classes=1000, mlp_ratio=4., qkv_bias=True,\n                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.5, norm_layer=None, act_layer=None,\n                 pad_type='', weight_init='', global_pool='avg'):\n        \"\"\"",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "blockify",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def blockify(x, block_size: int):\n    \"\"\"image to blocks\n    Args:\n        x (Tensor): with shape (B, H, W, C)\n        block_size (int): edge length of a single square block in units of H, W\n    \"\"\"\n    B, H, W, C  = x.shape\n    _assert(H % block_size == 0, '`block_size` must divide input height evenly')\n    _assert(W % block_size == 0, '`block_size` must divide input width evenly')\n    grid_height = H // block_size",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "deblockify",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def deblockify(x, block_size: int):\n    \"\"\"blocks to image\n    Args:\n        x (Tensor): with shape (B, T, N, C) where T is number of blocks and N is sequence size per block\n        block_size (int): edge length of a single square block in units of desired H, W\n    \"\"\"\n    B, T, _, C = x.shape\n    grid_size = int(math.sqrt(T))\n    height = width = grid_size * block_size\n    x = x.reshape(B, grid_size, grid_size, block_size, block_size, C)",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "resize_pos_embed",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def resize_pos_embed(posemb, posemb_new):\n    \"\"\"\n    Rescale the grid of position embeddings when loading from state_dict\n    Expected shape of position embeddings is (1, T, N, C), and considers only square images\n    \"\"\"\n    _logger.info('Resized position embedding: %s to %s', posemb.shape, posemb_new.shape)\n    seq_length_old = posemb.shape[2]\n    num_blocks_new, seq_length_new = posemb_new.shape[1:3]\n    size_new = int(math.sqrt(num_blocks_new*seq_length_new))\n    # First change to (1, C, H, W)",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" resize positional embeddings of pretrained weights \"\"\"\n    pos_embed_keys = [k for k in state_dict.keys() if k.startswith('pos_embed_')]\n    for k in pos_embed_keys:\n        if state_dict[k].shape != getattr(model, k).shape:\n            state_dict[k] = resize_pos_embed(state_dict[k], getattr(model, k))\n    return state_dict\ndef _create_nest(variant, pretrained=False, default_cfg=None, **kwargs):\n    default_cfg = default_cfg or default_cfgs[variant]\n    model = build_model_with_cfg(",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "nest_base",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def nest_base(pretrained=False, **kwargs):\n    \"\"\" Nest-B @ 224x224\n    \"\"\"\n    model_kwargs = dict(\n        embed_dims=(128, 256, 512), num_heads=(4, 8, 16), depths=(2, 2, 20), **kwargs)\n    model = _create_nest('nest_base', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef nest_small(pretrained=False, **kwargs):\n    \"\"\" Nest-S @ 224x224",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "nest_small",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def nest_small(pretrained=False, **kwargs):\n    \"\"\" Nest-S @ 224x224\n    \"\"\"\n    model_kwargs = dict(embed_dims=(96, 192, 384), num_heads=(3, 6, 12), depths=(2, 2, 20), **kwargs)\n    model = _create_nest('nest_small', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef nest_tiny(pretrained=False, **kwargs):\n    \"\"\" Nest-T @ 224x224\n    \"\"\"",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "nest_tiny",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def nest_tiny(pretrained=False, **kwargs):\n    \"\"\" Nest-T @ 224x224\n    \"\"\"\n    model_kwargs = dict(embed_dims=(96, 192, 384), num_heads=(3, 6, 12), depths=(2, 2, 8), **kwargs)\n    model = _create_nest('nest_tiny', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef jx_nest_base(pretrained=False, **kwargs):\n    \"\"\" Nest-B @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "jx_nest_base",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def jx_nest_base(pretrained=False, **kwargs):\n    \"\"\" Nest-B @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"\n    kwargs['pad_type'] = 'same'\n    model_kwargs = dict(embed_dims=(128, 256, 512), num_heads=(4, 8, 16), depths=(2, 2, 20), **kwargs)\n    model = _create_nest('jx_nest_base', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef jx_nest_small(pretrained=False, **kwargs):\n    \"\"\" Nest-S @ 224x224, Pretrained weights converted from official Jax impl.",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "jx_nest_small",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def jx_nest_small(pretrained=False, **kwargs):\n    \"\"\" Nest-S @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"\n    kwargs['pad_type'] = 'same'\n    model_kwargs = dict(embed_dims=(96, 192, 384), num_heads=(3, 6, 12), depths=(2, 2, 20), **kwargs)\n    model = _create_nest('jx_nest_small', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef jx_nest_tiny(pretrained=False, **kwargs):\n    \"\"\" Nest-T @ 224x224, Pretrained weights converted from official Jax impl.",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "jx_nest_tiny",
        "kind": 2,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "def jx_nest_tiny(pretrained=False, **kwargs):\n    \"\"\" Nest-T @ 224x224, Pretrained weights converted from official Jax impl.\n    \"\"\"\n    kwargs['pad_type'] = 'same'\n    model_kwargs = dict(embed_dims=(96, 192, 384), num_heads=(3, 6, 12), depths=(2, 2, 8), **kwargs)\n    model = _create_nest('jx_nest_tiny', pretrained=pretrained, **model_kwargs)\n    return model",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': [14, 14],\n        'crop_pct': .875, 'interpolation': 'bicubic', 'fixed_input_size': True,\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n        **kwargs\n    }",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.nest",
        "description": "timm.models.nest",
        "peekOfCode": "default_cfgs = {\n    # (weights from official Google JAX impl)\n    'nest_base': _cfg(),\n    'nest_small': _cfg(),\n    'nest_tiny': _cfg(),\n    'jx_nest_base': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_base-8bc41011.pth'),\n    'jx_nest_small': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_small-422eaded.pth'),\n    'jx_nest_tiny': _cfg(",
        "detail": "timm.models.nest",
        "documentation": {}
    },
    {
        "label": "NfCfg",
        "kind": 6,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "class NfCfg:\n    depths: Tuple[int, int, int, int]\n    channels: Tuple[int, int, int, int]\n    alpha: float = 0.2\n    stem_type: str = '3x3'\n    stem_chs: Optional[int] = None\n    group_size: Optional[int] = None\n    attn_layer: Optional[str] = None\n    attn_kwargs: dict = None\n    attn_gain: float = 2.0  # NF correction gain to apply if attn layer is used",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "GammaAct",
        "kind": 6,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "class GammaAct(nn.Module):\n    def __init__(self, act_type='relu', gamma: float = 1.0, inplace=False):\n        super().__init__()\n        self.act_fn = get_act_fn(act_type)\n        self.gamma = gamma\n        self.inplace = inplace\n    def forward(self, x):\n        return self.act_fn(x, inplace=self.inplace).mul_(self.gamma)\ndef act_with_gamma(act_type, gamma: float = 1.):\n    def _create(inplace=False):",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "DownsampleAvg",
        "kind": 6,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "class DownsampleAvg(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=1, dilation=1, first_dilation=None, conv_layer=ScaledStdConv2d):\n        \"\"\" AvgPool Downsampling as in 'D' ResNet variants. Support for dilation.\"\"\"\n        super(DownsampleAvg, self).__init__()\n        avg_stride = stride if dilation == 1 else 1\n        if stride > 1 or dilation > 1:\n            avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n            self.pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)\n        else:",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "NormFreeBlock",
        "kind": 6,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "class NormFreeBlock(nn.Module):\n    \"\"\"Normalization-Free pre-activation block.\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs=None, stride=1, dilation=1, first_dilation=None,\n            alpha=1.0, beta=1.0, bottle_ratio=0.25, group_size=None, ch_div=1, reg=True, extra_conv=False,\n            skipinit=False, attn_layer=None, attn_gain=2.0, act_layer=None, conv_layer=None, drop_path_rate=0.):\n        super().__init__()\n        first_dilation = first_dilation or dilation\n        out_chs = out_chs or in_chs",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "NormFreeNet",
        "kind": 6,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "class NormFreeNet(nn.Module):\n    \"\"\" Normalization-Free Network\n    As described in :\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    and\n    `High-Performance Large-Scale Image Recognition Without Normalization` - https://arxiv.org/abs/2102.06171\n    This model aims to cover both the NFRegNet-Bx models as detailed in the paper's code snippets and\n    the (preact) ResNet models described earlier in the paper.\n    There are a few differences:",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "act_with_gamma",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def act_with_gamma(act_type, gamma: float = 1.):\n    def _create(inplace=False):\n        return GammaAct(act_type, gamma=gamma, inplace=inplace)\n    return _create\nclass DownsampleAvg(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=1, dilation=1, first_dilation=None, conv_layer=ScaledStdConv2d):\n        \"\"\" AvgPool Downsampling as in 'D' ResNet variants. Support for dilation.\"\"\"\n        super(DownsampleAvg, self).__init__()\n        avg_stride = stride if dilation == 1 else 1",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "create_stem",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def create_stem(in_chs, out_chs, stem_type='', conv_layer=None, act_layer=None, preact_feature=True):\n    stem_stride = 2\n    stem_feature = dict(num_chs=out_chs, reduction=2, module='stem.conv')\n    stem = OrderedDict()\n    assert stem_type in ('', 'deep', 'deep_tiered', 'deep_quad', '3x3', '7x7', 'deep_pool', '3x3_pool', '7x7_pool')\n    if 'deep' in stem_type:\n        if 'quad' in stem_type:\n            # 4 deep conv stack as in NFNet-F models\n            assert not 'pool' in stem_type\n            stem_chs = (out_chs // 8, out_chs // 4, out_chs // 2, out_chs)",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f0",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f0(pretrained=False, **kwargs):\n    \"\"\" NFNet-F0 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f0', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f1(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f1",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f1(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f1', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f2(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f2",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f2(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f2', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f3(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f3",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f3(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f3', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f4(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f4",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f4(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f4', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f5(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f5",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f5(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f5', pretrained=pretrained, **kwargs)\n@register_model\ndef dm_nfnet_f6(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "dm_nfnet_f6",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def dm_nfnet_f6(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6 (DeepMind weight compatible)\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('dm_nfnet_f6', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f0(pretrained=False, **kwargs):\n    \"\"\" NFNet-F0\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f0",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f0(pretrained=False, **kwargs):\n    \"\"\" NFNet-F0\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f0', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f1(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f1",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f1(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f1', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f2(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f2",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f2(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f2', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f3(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f3",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f3(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f3', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f4(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f4",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f4(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f4', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f5(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f5",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f5(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f5', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f6(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f6",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f6(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f6', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f7(pretrained=False, **kwargs):\n    \"\"\" NFNet-F7\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f7",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f7(pretrained=False, **kwargs):\n    \"\"\" NFNet-F7\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f7', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f0s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F0 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f0s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f0s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F0 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f0s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f1s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f1s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f1s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F1 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f1s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f2s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f2s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f2s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F2 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f2s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f3s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f3s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f3s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F3 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f3s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f4s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f4s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f4s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F4 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f4s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f5s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f5s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f5s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F5 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f5s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f6s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f6s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f6s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F6 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f6s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_f7s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F7 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_f7s",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_f7s(pretrained=False, **kwargs):\n    \"\"\" NFNet-F7 w/ SiLU\n    `High-Performance Large-Scale Image Recognition Without Normalization`\n        - https://arxiv.org/abs/2102.06171\n    \"\"\"\n    return _create_normfreenet('nfnet_f7s', pretrained=pretrained, **kwargs)\n@register_model\ndef nfnet_l0(pretrained=False, **kwargs):\n    \"\"\" NFNet-L0b w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & SE ratio",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nfnet_l0",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nfnet_l0(pretrained=False, **kwargs):\n    \"\"\" NFNet-L0b w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & SE ratio\n    \"\"\"\n    return _create_normfreenet('nfnet_l0', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_nfnet_l0(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L0 w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "eca_nfnet_l0",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def eca_nfnet_l0(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L0 w/ SiLU\n    My experimental 'light' model w/ F0 repeats, 1.5x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"\n    return _create_normfreenet('eca_nfnet_l0', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_nfnet_l1(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L1 w/ SiLU\n    My experimental 'light' model w/ F1 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "eca_nfnet_l1",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def eca_nfnet_l1(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L1 w/ SiLU\n    My experimental 'light' model w/ F1 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"\n    return _create_normfreenet('eca_nfnet_l1', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_nfnet_l2(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L2 w/ SiLU\n    My experimental 'light' model w/ F2 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "eca_nfnet_l2",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def eca_nfnet_l2(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L2 w/ SiLU\n    My experimental 'light' model w/ F2 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"\n    return _create_normfreenet('eca_nfnet_l2', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_nfnet_l3(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L3 w/ SiLU\n    My experimental 'light' model w/ F3 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "eca_nfnet_l3",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def eca_nfnet_l3(pretrained=False, **kwargs):\n    \"\"\" ECA-NFNet-L3 w/ SiLU\n    My experimental 'light' model w/ F3 repeats, 2.0x final_conv mult, 64 group_size, .25 bottleneck & ECA attn\n    \"\"\"\n    return _create_normfreenet('eca_nfnet_l3', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b0(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B0\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b0",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b0(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B0\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b0', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b1(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B1\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b1",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b1(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B1\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b1', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b2(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B2\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b2",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b2(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B2\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b2', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b3(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B3\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b3",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b3(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B3\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b3', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b4(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B4\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b4",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b4(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B4\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b4', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_regnet_b5(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B5\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_regnet_b5",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_regnet_b5(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free RegNet-B5\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_regnet_b5', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_resnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-26\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_resnet26",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_resnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-26\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_resnet26', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_resnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-50\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_resnet50",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_resnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-50\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_resnet50', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_resnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-101\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_resnet101",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_resnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ResNet-101\n    `Characterizing signal propagation to close the performance gap in unnormalized ResNets`\n        - https://arxiv.org/abs/2101.08692\n    \"\"\"\n    return _create_normfreenet('nf_resnet101', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_seresnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet26\n    \"\"\"",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_seresnet26",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_seresnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet26\n    \"\"\"\n    return _create_normfreenet('nf_seresnet26', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_seresnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet50\n    \"\"\"\n    return _create_normfreenet('nf_seresnet50', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_seresnet50",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_seresnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet50\n    \"\"\"\n    return _create_normfreenet('nf_seresnet50', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_seresnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet101\n    \"\"\"\n    return _create_normfreenet('nf_seresnet101', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_seresnet101",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_seresnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free SE-ResNet101\n    \"\"\"\n    return _create_normfreenet('nf_seresnet101', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_ecaresnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet26\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet26', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_ecaresnet26",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_ecaresnet26(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet26\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet26', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_ecaresnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet50\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet50', pretrained=pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_ecaresnet50",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_ecaresnet50(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet50\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet50', pretrained=pretrained, **kwargs)\n@register_model\ndef nf_ecaresnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet101\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet101', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "nf_ecaresnet101",
        "kind": 2,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "def nf_ecaresnet101(pretrained=False, **kwargs):\n    \"\"\" Normalization-Free ECA-ResNet101\n    \"\"\"\n    return _create_normfreenet('nf_ecaresnet101', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "default_cfgs = dict(\n    dm_nfnet_f0=_dcfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f0-604f9c3a.pth',\n        pool_size=(6, 6), input_size=(3, 192, 192), test_input_size=(3, 256, 256), crop_pct=.9),\n    dm_nfnet_f1=_dcfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f1-fc540f82.pth',\n        pool_size=(7, 7), input_size=(3, 224, 224), test_input_size=(3, 320, 320), crop_pct=0.91),\n    dm_nfnet_f2=_dcfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f2-89875923.pth',\n        pool_size=(8, 8), input_size=(3, 256, 256), test_input_size=(3, 352, 352), crop_pct=0.92),",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "model_cfgs = dict(\n    # NFNet-F models w/ GELU compatible with DeepMind weights\n    dm_nfnet_f0=_dm_nfnet_cfg(depths=(1, 2, 6, 3)),\n    dm_nfnet_f1=_dm_nfnet_cfg(depths=(2, 4, 12, 6)),\n    dm_nfnet_f2=_dm_nfnet_cfg(depths=(3, 6, 18, 9)),\n    dm_nfnet_f3=_dm_nfnet_cfg(depths=(4, 8, 24, 12)),\n    dm_nfnet_f4=_dm_nfnet_cfg(depths=(5, 10, 30, 15)),\n    dm_nfnet_f5=_dm_nfnet_cfg(depths=(6, 12, 36, 18)),\n    dm_nfnet_f6=_dm_nfnet_cfg(depths=(7, 14, 42, 21)),\n    # NFNet-F models w/ GELU (I will likely deprecate/remove these models and just keep dm_ ver for GELU)",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "_nonlin_gamma",
        "kind": 5,
        "importPath": "timm.models.nfnet",
        "description": "timm.models.nfnet",
        "peekOfCode": "_nonlin_gamma = dict(\n    identity=1.0,\n    celu=1.270926833152771,\n    elu=1.2716004848480225,\n    gelu=1.7015043497085571,\n    leaky_relu=1.70590341091156,\n    log_sigmoid=1.9193484783172607,\n    log_softmax=1.0002083778381348,\n    relu=1.7139588594436646,\n    relu6=1.7131484746932983,",
        "detail": "timm.models.nfnet",
        "documentation": {}
    },
    {
        "label": "SequentialTuple",
        "kind": 6,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "class SequentialTuple(nn.Sequential):\n    \"\"\" This module exists to work around torchscript typing issues list -> list\"\"\"\n    def __init__(self, *args):\n        super(SequentialTuple, self).__init__(*args)\n    def forward(self, x: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n        for module in self:\n            x = module(x)\n        return x\nclass Transformer(nn.Module):\n    def __init__(",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "Transformer",
        "kind": 6,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "class Transformer(nn.Module):\n    def __init__(\n            self, base_dim, depth, heads, mlp_ratio, pool=None, drop_rate=.0, attn_drop_rate=.0, drop_path_prob=None):\n        super(Transformer, self).__init__()\n        self.layers = nn.ModuleList([])\n        embed_dim = base_dim * heads\n        self.blocks = nn.Sequential(*[\n            Block(\n                dim=embed_dim,\n                num_heads=heads,",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "ConvHeadPooling",
        "kind": 6,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "class ConvHeadPooling(nn.Module):\n    def __init__(self, in_feature, out_feature, stride, padding_mode='zeros'):\n        super(ConvHeadPooling, self).__init__()\n        self.conv = nn.Conv2d(\n            in_feature, out_feature, kernel_size=stride + 1, padding=stride // 2, stride=stride,\n            padding_mode=padding_mode, groups=in_feature)\n        self.fc = nn.Linear(in_feature, out_feature)\n    def forward(self, x, cls_token) -> Tuple[torch.Tensor, torch.Tensor]:\n        x = self.conv(x)\n        cls_token = self.fc(cls_token)",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "ConvEmbedding",
        "kind": 6,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "class ConvEmbedding(nn.Module):\n    def __init__(self, in_channels, out_channels, patch_size, stride, padding):\n        super(ConvEmbedding, self).__init__()\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, kernel_size=patch_size, stride=stride, padding=padding, bias=True)\n    def forward(self, x):\n        x = self.conv(x)\n        return x\nclass PoolingVisionTransformer(nn.Module):\n    \"\"\" Pooling-based Vision Transformer",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "PoolingVisionTransformer",
        "kind": 6,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "class PoolingVisionTransformer(nn.Module):\n    \"\"\" Pooling-based Vision Transformer\n    A PyTorch implement of 'Rethinking Spatial Dimensions of Vision Transformers'\n        - https://arxiv.org/abs/2103.16302\n    \"\"\"\n    def __init__(self, img_size, patch_size, stride, base_dims, depth, heads,\n                 mlp_ratio, num_classes=1000, in_chans=3, distilled=False,\n                 attn_drop_rate=.0, drop_rate=.0, drop_path_rate=.0):\n        super(PoolingVisionTransformer, self).__init__()\n        padding = 0",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" preprocess checkpoints \"\"\"\n    out_dict = {}\n    p_blocks = re.compile(r'pools\\.(\\d)\\.')\n    for k, v in state_dict.items():\n        # FIXME need to update resize for PiT impl\n        # if k == 'pos_embed' and v.shape != model.pos_embed.shape:\n        #     # To resize pos embedding when using model at different size from pretrained weights\n        #     v = resize_pos_embed(v, model.pos_embed)\n        k = p_blocks.sub(lambda exp: f'transformers.{int(exp.group(1))}.pool.', k)",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_b_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_b_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=14,\n        stride=7,\n        base_dims=[64, 64, 64],\n        depth=[3, 6, 4],\n        heads=[4, 8, 16],\n        mlp_ratio=4,\n        **kwargs\n    )",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_s_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_s_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[48, 48, 48],\n        depth=[2, 6, 4],\n        heads=[3, 6, 12],\n        mlp_ratio=4,\n        **kwargs\n    )",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_xs_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_xs_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[48, 48, 48],\n        depth=[2, 6, 4],\n        heads=[2, 4, 8],\n        mlp_ratio=4,\n        **kwargs\n    )",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_ti_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_ti_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[32, 32, 32],\n        depth=[2, 6, 4],\n        heads=[2, 4, 8],\n        mlp_ratio=4,\n        **kwargs\n    )",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_b_distilled_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_b_distilled_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=14,\n        stride=7,\n        base_dims=[64, 64, 64],\n        depth=[3, 6, 4],\n        heads=[4, 8, 16],\n        mlp_ratio=4,\n        distilled=True,\n        **kwargs",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_s_distilled_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_s_distilled_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[48, 48, 48],\n        depth=[2, 6, 4],\n        heads=[3, 6, 12],\n        mlp_ratio=4,\n        distilled=True,\n        **kwargs",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_xs_distilled_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_xs_distilled_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[48, 48, 48],\n        depth=[2, 6, 4],\n        heads=[2, 4, 8],\n        mlp_ratio=4,\n        distilled=True,\n        **kwargs",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "pit_ti_distilled_224",
        "kind": 2,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "def pit_ti_distilled_224(pretrained, **kwargs):\n    model_kwargs = dict(\n        patch_size=16,\n        stride=8,\n        base_dims=[32, 32, 32],\n        depth=[2, 6, 4],\n        heads=[2, 4, 8],\n        mlp_ratio=4,\n        distilled=True,\n        **kwargs",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.pit",
        "description": "timm.models.pit",
        "peekOfCode": "default_cfgs = {\n    # deit models (FB weights)\n    'pit_ti_224': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_ti_730.pth'),\n    'pit_xs_224': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_xs_781.pth'),\n    'pit_s_224': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_s_809.pth'),\n    'pit_b_224': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_820.pth'),",
        "detail": "timm.models.pit",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=''):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = create_conv2d(\n            in_channels, in_channels, kernel_size=kernel_size,\n            stride=stride, padding=padding, groups=in_channels)\n        self.pointwise_conv2d = create_conv2d(\n            in_channels, out_channels, kernel_size=1, padding=padding)\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "BranchSeparables",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class BranchSeparables(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, stem_cell=False, padding=''):\n        super(BranchSeparables, self).__init__()\n        middle_channels = out_channels if stem_cell else in_channels\n        self.act_1 = nn.ReLU()\n        self.separable_1 = SeparableConv2d(\n            in_channels, middle_channels, kernel_size, stride=stride, padding=padding)\n        self.bn_sep_1 = nn.BatchNorm2d(middle_channels, eps=0.001)\n        self.act_2 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "ActConvBn",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class ActConvBn(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=''):\n        super(ActConvBn, self).__init__()\n        self.act = nn.ReLU()\n        self.conv = create_conv2d(\n            in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n    def forward(self, x):\n        x = self.act(x)\n        x = self.conv(x)",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "FactorizedReduction",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class FactorizedReduction(nn.Module):\n    def __init__(self, in_channels, out_channels, padding=''):\n        super(FactorizedReduction, self).__init__()\n        self.act = nn.ReLU()\n        self.path_1 = nn.Sequential(OrderedDict([\n            ('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False)),\n            ('conv', create_conv2d(in_channels, out_channels // 2, kernel_size=1, padding=padding)),\n        ]))\n        self.path_2 = nn.Sequential(OrderedDict([\n            ('pad', nn.ZeroPad2d((-1, 1, -1, 1))),  # shift",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "CellBase",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class CellBase(nn.Module):\n    def cell_forward(self, x_left, x_right):\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "CellStem0",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class CellStem0(CellBase):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type=''):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = ActConvBn(in_chs_right, out_chs_right, kernel_size=1, padding=pad_type)\n        self.comb_iter_0_left = BranchSeparables(\n            in_chs_left, out_chs_left, kernel_size=5, stride=2, stem_cell=True, padding=pad_type)\n        self.comb_iter_0_right = nn.Sequential(OrderedDict([\n            ('max_pool', create_pool2d('max', 3, stride=2, padding=pad_type)),\n            ('conv', create_conv2d(in_chs_left, out_chs_left, kernel_size=1, padding=pad_type)),\n            ('bn', nn.BatchNorm2d(out_chs_left, eps=0.001)),",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "Cell",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class Cell(CellBase):\n    def __init__(self, in_chs_left, out_chs_left, in_chs_right, out_chs_right, pad_type='',\n                 is_reduction=False, match_prev_layer_dims=False):\n        super(Cell, self).__init__()\n        # If `is_reduction` is set to `True` stride 2 is used for\n        # convolution and pooling layers to reduce the spatial size of\n        # the output of a cell approximately by a factor of 2.\n        stride = 2 if is_reduction else 1\n        # If `match_prev_layer_dimensions` is set to `True`\n        # `FactorizedReduction` is used to reduce the spatial size",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "PNASNet5Large",
        "kind": 6,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "class PNASNet5Large(nn.Module):\n    def __init__(self, num_classes=1000, in_chans=3, output_stride=32, drop_rate=0., global_pool='avg', pad_type=''):\n        super(PNASNet5Large, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        self.num_features = 4320\n        assert output_stride == 32\n        self.conv_0 = ConvBnAct(\n            in_chans, 96, kernel_size=3, stride=2, padding=0,\n            norm_layer=partial(nn.BatchNorm2d, eps=0.001, momentum=0.1), apply_act=False)",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "pnasnet5large",
        "kind": 2,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "def pnasnet5large(pretrained=False, **kwargs):\n    r\"\"\"PNASNet-5 model architecture from the\n    `\"Progressive Neural Architecture Search\"\n    <https://arxiv.org/abs/1712.00559>`_ paper.\n    \"\"\"\n    model_kwargs = dict(pad_type='same', **kwargs)\n    return _create_pnasnet('pnasnet5large', pretrained, **model_kwargs)",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "__all__ = ['PNASNet5Large']\ndefault_cfgs = {\n    'pnasnet5large': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/pnasnet5large-bf079911.pth',\n        'input_size': (3, 331, 331),\n        'pool_size': (11, 11),\n        'crop_pct': 0.911,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.pnasnet",
        "description": "timm.models.pnasnet",
        "peekOfCode": "default_cfgs = {\n    'pnasnet5large': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/pnasnet5large-bf079911.pth',\n        'input_size': (3, 331, 331),\n        'pool_size': (11, 11),\n        'crop_pct': 0.911,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),\n        'num_classes': 1000,",
        "detail": "timm.models.pnasnet",
        "documentation": {}
    },
    {
        "label": "register_model",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''\n    # add model to __all__ in module\n    model_name = fn.__name__\n    if hasattr(mod, '__all__'):\n        mod.__all__.append(model_name)\n    else:",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "list_models",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def list_models(filter='', module='', pretrained=False, exclude_filters='', name_matches_cfg=False):\n    \"\"\" Return list of available model names, sorted alphabetically\n    Args:\n        filter (str) - Wildcard filter string that works with fnmatch\n        module (str) - Limit model selection to a specific sub-module (ie 'gen_efficientnet')\n        pretrained (bool) - Include only models with pretrained weights if True\n        exclude_filters (str or list[str]) - Wildcard filters to exclude models after including them with filter\n        name_matches_cfg (bool) - Include only models w/ model_name matching default_cfg name (excludes some aliases)\n    Example:\n        model_list('gluon_resnet*') -- returns all models starting with 'gluon_resnet'",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "is_model",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def is_model(model_name):\n    \"\"\" Check if a model name exists\n    \"\"\"\n    return model_name in _model_entrypoints\ndef model_entrypoint(model_name):\n    \"\"\"Fetch a model entrypoint for specified model name\n    \"\"\"\n    return _model_entrypoints[model_name]\ndef list_modules():\n    \"\"\" Return list of module names that contain models / model entrypoints",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "model_entrypoint",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def model_entrypoint(model_name):\n    \"\"\"Fetch a model entrypoint for specified model name\n    \"\"\"\n    return _model_entrypoints[model_name]\ndef list_modules():\n    \"\"\" Return list of module names that contain models / model entrypoints\n    \"\"\"\n    modules = _module_to_models.keys()\n    return list(sorted(modules))\ndef is_model_in_modules(model_name, module_names):",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "list_modules",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def list_modules():\n    \"\"\" Return list of module names that contain models / model entrypoints\n    \"\"\"\n    modules = _module_to_models.keys()\n    return list(sorted(modules))\ndef is_model_in_modules(model_name, module_names):\n    \"\"\"Check if a model exists within a subset of modules\n    Args:\n        model_name (str) - name of model to check\n        module_names (tuple, list, set) - names of modules to search in",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "is_model_in_modules",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def is_model_in_modules(model_name, module_names):\n    \"\"\"Check if a model exists within a subset of modules\n    Args:\n        model_name (str) - name of model to check\n        module_names (tuple, list, set) - names of modules to search in\n    \"\"\"\n    assert isinstance(module_names, (tuple, list, set))\n    return any(model_name in _module_to_models[n] for n in module_names)\ndef has_model_default_key(model_name, cfg_key):\n    \"\"\" Query model default_cfgs for existence of a specific key.",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "has_model_default_key",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def has_model_default_key(model_name, cfg_key):\n    \"\"\" Query model default_cfgs for existence of a specific key.\n    \"\"\"\n    if model_name in _model_default_cfgs and cfg_key in _model_default_cfgs[model_name]:\n        return True\n    return False\ndef is_model_default_key(model_name, cfg_key):\n    \"\"\" Return truthy value for specified model default_cfg key, False if does not exist.\n    \"\"\"\n    if model_name in _model_default_cfgs and _model_default_cfgs[model_name].get(cfg_key, False):",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "is_model_default_key",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def is_model_default_key(model_name, cfg_key):\n    \"\"\" Return truthy value for specified model default_cfg key, False if does not exist.\n    \"\"\"\n    if model_name in _model_default_cfgs and _model_default_cfgs[model_name].get(cfg_key, False):\n        return True\n    return False\ndef get_model_default_value(model_name, cfg_key):\n    \"\"\" Get a specific model default_cfg value by key. None if it doesn't exist.\n    \"\"\"\n    if model_name in _model_default_cfgs:",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "get_model_default_value",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def get_model_default_value(model_name, cfg_key):\n    \"\"\" Get a specific model default_cfg value by key. None if it doesn't exist.\n    \"\"\"\n    if model_name in _model_default_cfgs:\n        return _model_default_cfgs[model_name].get(cfg_key, None)\n    else:\n        return None\ndef is_model_pretrained(model_name):\n    return model_name in _model_has_pretrained",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "is_model_pretrained",
        "kind": 2,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "def is_model_pretrained(model_name):\n    return model_name in _model_has_pretrained",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "__all__ = ['list_models', 'is_model', 'model_entrypoint', 'list_modules', 'is_model_in_modules',\n           'is_model_default_key', 'has_model_default_key', 'get_model_default_value', 'is_model_pretrained']\n_module_to_models = defaultdict(set)  # dict of sets to check membership of model in module\n_model_to_module = {}  # mapping of model names to module names\n_model_entrypoints = {}  # mapping of model names to entrypoint fns\n_model_has_pretrained = set()  # set of model names that have pretrained weight url present\n_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "_module_to_models",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "_module_to_models = defaultdict(set)  # dict of sets to check membership of model in module\n_model_to_module = {}  # mapping of model names to module names\n_model_entrypoints = {}  # mapping of model names to entrypoint fns\n_model_has_pretrained = set()  # set of model names that have pretrained weight url present\n_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "_model_to_module",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "_model_to_module = {}  # mapping of model names to module names\n_model_entrypoints = {}  # mapping of model names to entrypoint fns\n_model_has_pretrained = set()  # set of model names that have pretrained weight url present\n_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''\n    # add model to __all__ in module",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "_model_entrypoints",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "_model_entrypoints = {}  # mapping of model names to entrypoint fns\n_model_has_pretrained = set()  # set of model names that have pretrained weight url present\n_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''\n    # add model to __all__ in module\n    model_name = fn.__name__",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "_model_has_pretrained",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "_model_has_pretrained = set()  # set of model names that have pretrained weight url present\n_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''\n    # add model to __all__ in module\n    model_name = fn.__name__\n    if hasattr(mod, '__all__'):",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "_model_default_cfgs",
        "kind": 5,
        "importPath": "timm.models.registry",
        "description": "timm.models.registry",
        "peekOfCode": "_model_default_cfgs = dict()  # central repo for model default_cfgs\ndef register_model(fn):\n    # lookup containing module\n    mod = sys.modules[fn.__module__]\n    module_name_split = fn.__module__.split('.')\n    module_name = module_name_split[-1] if len(module_name_split) else ''\n    # add model to __all__ in module\n    model_name = fn.__name__\n    if hasattr(mod, '__all__'):\n        mod.__all__.append(model_name)",
        "detail": "timm.models.registry",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "class Bottleneck(nn.Module):\n    \"\"\" RegNet Bottleneck\n    This is almost exactly the same as a ResNet Bottlneck. The main difference is the SE block is moved from\n    after conv3 to after conv2. Otherwise, it's just redefining the arguments for groups/bottleneck channels.\n    \"\"\"\n    def __init__(self, in_chs, out_chs, stride=1, dilation=1, bottleneck_ratio=1, group_width=1, se_ratio=0.25,\n                 downsample=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, aa_layer=None,\n                 drop_block=None, drop_path=None):\n        super(Bottleneck, self).__init__()\n        bottleneck_chs = int(round(out_chs * bottleneck_ratio))",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "RegStage",
        "kind": 6,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "class RegStage(nn.Module):\n    \"\"\"Stage (sequence of blocks w/ the same output shape).\"\"\"\n    def __init__(self, in_chs, out_chs, stride, dilation, depth, bottle_ratio, group_width,\n                 block_fn=Bottleneck, se_ratio=0., drop_path_rates=None, drop_block=None):\n        super(RegStage, self).__init__()\n        block_kwargs = {}  # FIXME setup to pass various aa, norm, act layer common args\n        first_dilation = 1 if dilation in (1, 2) else 2\n        for i in range(depth):\n            block_stride = stride if i == 0 else 1\n            block_in_chs = in_chs if i == 0 else out_chs",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "RegNet",
        "kind": 6,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "class RegNet(nn.Module):\n    \"\"\"RegNet model.\n    Paper: https://arxiv.org/abs/2003.13678\n    Original Impl: https://github.com/facebookresearch/pycls/blob/master/pycls/models/regnet.py\n    \"\"\"\n    def __init__(self, cfg, in_chans=3, num_classes=1000, output_stride=32, global_pool='avg', drop_rate=0.,\n                 drop_path_rate=0., zero_init_last_bn=True):\n        super().__init__()\n        # TODO add drop block, drop path, anti-aliasing, custom bn/act args\n        self.num_classes = num_classes",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "quantize_float",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def quantize_float(f, q):\n    \"\"\"Converts a float to closest non-zero int divisible by q.\"\"\"\n    return int(round(f / q) * q)\ndef adjust_widths_groups_comp(widths, bottle_ratios, groups):\n    \"\"\"Adjusts the compatibility of widths and groups.\"\"\"\n    bottleneck_widths = [int(w * b) for w, b in zip(widths, bottle_ratios)]\n    groups = [min(g, w_bot) for g, w_bot in zip(groups, bottleneck_widths)]\n    bottleneck_widths = [quantize_float(w_bot, g) for w_bot, g in zip(bottleneck_widths, groups)]\n    widths = [int(w_bot / b) for w_bot, b in zip(bottleneck_widths, bottle_ratios)]\n    return widths, groups",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "adjust_widths_groups_comp",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def adjust_widths_groups_comp(widths, bottle_ratios, groups):\n    \"\"\"Adjusts the compatibility of widths and groups.\"\"\"\n    bottleneck_widths = [int(w * b) for w, b in zip(widths, bottle_ratios)]\n    groups = [min(g, w_bot) for g, w_bot in zip(groups, bottleneck_widths)]\n    bottleneck_widths = [quantize_float(w_bot, g) for w_bot, g in zip(bottleneck_widths, groups)]\n    widths = [int(w_bot / b) for w_bot, b in zip(bottleneck_widths, bottle_ratios)]\n    return widths, groups\ndef generate_regnet(width_slope, width_initial, width_mult, depth, q=8):\n    \"\"\"Generates per block widths from RegNet parameters.\"\"\"\n    assert width_slope >= 0 and width_initial > 0 and width_mult > 1 and width_initial % q == 0",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "generate_regnet",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def generate_regnet(width_slope, width_initial, width_mult, depth, q=8):\n    \"\"\"Generates per block widths from RegNet parameters.\"\"\"\n    assert width_slope >= 0 and width_initial > 0 and width_mult > 1 and width_initial % q == 0\n    widths_cont = np.arange(depth) * width_slope + width_initial\n    width_exps = np.round(np.log(widths_cont / width_initial) / np.log(width_mult))\n    widths = width_initial * np.power(width_mult, width_exps)\n    widths = np.round(np.divide(widths, q)) * q\n    num_stages, max_stage = len(np.unique(widths)), width_exps.max() + 1\n    widths, widths_cont = widths.astype(int).tolist(), widths_cont.tolist()\n    return widths, num_stages, max_stage, widths_cont",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "downsample_conv",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def downsample_conv(\n        in_chs, out_chs, kernel_size, stride=1, dilation=1, norm_layer=None):\n    norm_layer = norm_layer or nn.BatchNorm2d\n    kernel_size = 1 if stride == 1 and dilation == 1 else kernel_size\n    dilation = dilation if kernel_size > 1 else 1\n    return ConvBnAct(\n        in_chs, out_chs, kernel_size, stride=stride, dilation=dilation, norm_layer=norm_layer, act_layer=None)\ndef downsample_avg(\n        in_chs, out_chs, kernel_size, stride=1, dilation=1, norm_layer=None):\n    \"\"\" AvgPool Downsampling as in 'D' ResNet variants. This is not in RegNet space but I might experiment.\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "downsample_avg",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def downsample_avg(\n        in_chs, out_chs, kernel_size, stride=1, dilation=1, norm_layer=None):\n    \"\"\" AvgPool Downsampling as in 'D' ResNet variants. This is not in RegNet space but I might experiment.\"\"\"\n    norm_layer = norm_layer or nn.BatchNorm2d\n    avg_stride = stride if dilation == 1 else 1\n    pool = nn.Identity()\n    if stride > 1 or dilation > 1:\n        avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n        pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)\n    return nn.Sequential(*[",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_002",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_002(pretrained=False, **kwargs):\n    \"\"\"RegNetX-200MF\"\"\"\n    return _create_regnet('regnetx_002', pretrained, **kwargs)\n@register_model\ndef regnetx_004(pretrained=False, **kwargs):\n    \"\"\"RegNetX-400MF\"\"\"\n    return _create_regnet('regnetx_004', pretrained, **kwargs)\n@register_model\ndef regnetx_006(pretrained=False, **kwargs):\n    \"\"\"RegNetX-600MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_004",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_004(pretrained=False, **kwargs):\n    \"\"\"RegNetX-400MF\"\"\"\n    return _create_regnet('regnetx_004', pretrained, **kwargs)\n@register_model\ndef regnetx_006(pretrained=False, **kwargs):\n    \"\"\"RegNetX-600MF\"\"\"\n    return _create_regnet('regnetx_006', pretrained, **kwargs)\n@register_model\ndef regnetx_008(pretrained=False, **kwargs):\n    \"\"\"RegNetX-800MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_006",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_006(pretrained=False, **kwargs):\n    \"\"\"RegNetX-600MF\"\"\"\n    return _create_regnet('regnetx_006', pretrained, **kwargs)\n@register_model\ndef regnetx_008(pretrained=False, **kwargs):\n    \"\"\"RegNetX-800MF\"\"\"\n    return _create_regnet('regnetx_008', pretrained, **kwargs)\n@register_model\ndef regnetx_016(pretrained=False, **kwargs):\n    \"\"\"RegNetX-1.6GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_008",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_008(pretrained=False, **kwargs):\n    \"\"\"RegNetX-800MF\"\"\"\n    return _create_regnet('regnetx_008', pretrained, **kwargs)\n@register_model\ndef regnetx_016(pretrained=False, **kwargs):\n    \"\"\"RegNetX-1.6GF\"\"\"\n    return _create_regnet('regnetx_016', pretrained, **kwargs)\n@register_model\ndef regnetx_032(pretrained=False, **kwargs):\n    \"\"\"RegNetX-3.2GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_016",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_016(pretrained=False, **kwargs):\n    \"\"\"RegNetX-1.6GF\"\"\"\n    return _create_regnet('regnetx_016', pretrained, **kwargs)\n@register_model\ndef regnetx_032(pretrained=False, **kwargs):\n    \"\"\"RegNetX-3.2GF\"\"\"\n    return _create_regnet('regnetx_032', pretrained, **kwargs)\n@register_model\ndef regnetx_040(pretrained=False, **kwargs):\n    \"\"\"RegNetX-4.0GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_032",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_032(pretrained=False, **kwargs):\n    \"\"\"RegNetX-3.2GF\"\"\"\n    return _create_regnet('regnetx_032', pretrained, **kwargs)\n@register_model\ndef regnetx_040(pretrained=False, **kwargs):\n    \"\"\"RegNetX-4.0GF\"\"\"\n    return _create_regnet('regnetx_040', pretrained, **kwargs)\n@register_model\ndef regnetx_064(pretrained=False, **kwargs):\n    \"\"\"RegNetX-6.4GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_040",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_040(pretrained=False, **kwargs):\n    \"\"\"RegNetX-4.0GF\"\"\"\n    return _create_regnet('regnetx_040', pretrained, **kwargs)\n@register_model\ndef regnetx_064(pretrained=False, **kwargs):\n    \"\"\"RegNetX-6.4GF\"\"\"\n    return _create_regnet('regnetx_064', pretrained, **kwargs)\n@register_model\ndef regnetx_080(pretrained=False, **kwargs):\n    \"\"\"RegNetX-8.0GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_064",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_064(pretrained=False, **kwargs):\n    \"\"\"RegNetX-6.4GF\"\"\"\n    return _create_regnet('regnetx_064', pretrained, **kwargs)\n@register_model\ndef regnetx_080(pretrained=False, **kwargs):\n    \"\"\"RegNetX-8.0GF\"\"\"\n    return _create_regnet('regnetx_080', pretrained, **kwargs)\n@register_model\ndef regnetx_120(pretrained=False, **kwargs):\n    \"\"\"RegNetX-12GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_080",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_080(pretrained=False, **kwargs):\n    \"\"\"RegNetX-8.0GF\"\"\"\n    return _create_regnet('regnetx_080', pretrained, **kwargs)\n@register_model\ndef regnetx_120(pretrained=False, **kwargs):\n    \"\"\"RegNetX-12GF\"\"\"\n    return _create_regnet('regnetx_120', pretrained, **kwargs)\n@register_model\ndef regnetx_160(pretrained=False, **kwargs):\n    \"\"\"RegNetX-16GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_120",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_120(pretrained=False, **kwargs):\n    \"\"\"RegNetX-12GF\"\"\"\n    return _create_regnet('regnetx_120', pretrained, **kwargs)\n@register_model\ndef regnetx_160(pretrained=False, **kwargs):\n    \"\"\"RegNetX-16GF\"\"\"\n    return _create_regnet('regnetx_160', pretrained, **kwargs)\n@register_model\ndef regnetx_320(pretrained=False, **kwargs):\n    \"\"\"RegNetX-32GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_160",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_160(pretrained=False, **kwargs):\n    \"\"\"RegNetX-16GF\"\"\"\n    return _create_regnet('regnetx_160', pretrained, **kwargs)\n@register_model\ndef regnetx_320(pretrained=False, **kwargs):\n    \"\"\"RegNetX-32GF\"\"\"\n    return _create_regnet('regnetx_320', pretrained, **kwargs)\n@register_model\ndef regnety_002(pretrained=False, **kwargs):\n    \"\"\"RegNetY-200MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnetx_320",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnetx_320(pretrained=False, **kwargs):\n    \"\"\"RegNetX-32GF\"\"\"\n    return _create_regnet('regnetx_320', pretrained, **kwargs)\n@register_model\ndef regnety_002(pretrained=False, **kwargs):\n    \"\"\"RegNetY-200MF\"\"\"\n    return _create_regnet('regnety_002', pretrained, **kwargs)\n@register_model\ndef regnety_004(pretrained=False, **kwargs):\n    \"\"\"RegNetY-400MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_002",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_002(pretrained=False, **kwargs):\n    \"\"\"RegNetY-200MF\"\"\"\n    return _create_regnet('regnety_002', pretrained, **kwargs)\n@register_model\ndef regnety_004(pretrained=False, **kwargs):\n    \"\"\"RegNetY-400MF\"\"\"\n    return _create_regnet('regnety_004', pretrained, **kwargs)\n@register_model\ndef regnety_006(pretrained=False, **kwargs):\n    \"\"\"RegNetY-600MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_004",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_004(pretrained=False, **kwargs):\n    \"\"\"RegNetY-400MF\"\"\"\n    return _create_regnet('regnety_004', pretrained, **kwargs)\n@register_model\ndef regnety_006(pretrained=False, **kwargs):\n    \"\"\"RegNetY-600MF\"\"\"\n    return _create_regnet('regnety_006', pretrained, **kwargs)\n@register_model\ndef regnety_008(pretrained=False, **kwargs):\n    \"\"\"RegNetY-800MF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_006",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_006(pretrained=False, **kwargs):\n    \"\"\"RegNetY-600MF\"\"\"\n    return _create_regnet('regnety_006', pretrained, **kwargs)\n@register_model\ndef regnety_008(pretrained=False, **kwargs):\n    \"\"\"RegNetY-800MF\"\"\"\n    return _create_regnet('regnety_008', pretrained, **kwargs)\n@register_model\ndef regnety_016(pretrained=False, **kwargs):\n    \"\"\"RegNetY-1.6GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_008",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_008(pretrained=False, **kwargs):\n    \"\"\"RegNetY-800MF\"\"\"\n    return _create_regnet('regnety_008', pretrained, **kwargs)\n@register_model\ndef regnety_016(pretrained=False, **kwargs):\n    \"\"\"RegNetY-1.6GF\"\"\"\n    return _create_regnet('regnety_016', pretrained, **kwargs)\n@register_model\ndef regnety_032(pretrained=False, **kwargs):\n    \"\"\"RegNetY-3.2GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_016",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_016(pretrained=False, **kwargs):\n    \"\"\"RegNetY-1.6GF\"\"\"\n    return _create_regnet('regnety_016', pretrained, **kwargs)\n@register_model\ndef regnety_032(pretrained=False, **kwargs):\n    \"\"\"RegNetY-3.2GF\"\"\"\n    return _create_regnet('regnety_032', pretrained, **kwargs)\n@register_model\ndef regnety_040(pretrained=False, **kwargs):\n    \"\"\"RegNetY-4.0GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_032",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_032(pretrained=False, **kwargs):\n    \"\"\"RegNetY-3.2GF\"\"\"\n    return _create_regnet('regnety_032', pretrained, **kwargs)\n@register_model\ndef regnety_040(pretrained=False, **kwargs):\n    \"\"\"RegNetY-4.0GF\"\"\"\n    return _create_regnet('regnety_040', pretrained, **kwargs)\n@register_model\ndef regnety_064(pretrained=False, **kwargs):\n    \"\"\"RegNetY-6.4GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_040",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_040(pretrained=False, **kwargs):\n    \"\"\"RegNetY-4.0GF\"\"\"\n    return _create_regnet('regnety_040', pretrained, **kwargs)\n@register_model\ndef regnety_064(pretrained=False, **kwargs):\n    \"\"\"RegNetY-6.4GF\"\"\"\n    return _create_regnet('regnety_064', pretrained, **kwargs)\n@register_model\ndef regnety_080(pretrained=False, **kwargs):\n    \"\"\"RegNetY-8.0GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_064",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_064(pretrained=False, **kwargs):\n    \"\"\"RegNetY-6.4GF\"\"\"\n    return _create_regnet('regnety_064', pretrained, **kwargs)\n@register_model\ndef regnety_080(pretrained=False, **kwargs):\n    \"\"\"RegNetY-8.0GF\"\"\"\n    return _create_regnet('regnety_080', pretrained, **kwargs)\n@register_model\ndef regnety_120(pretrained=False, **kwargs):\n    \"\"\"RegNetY-12GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_080",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_080(pretrained=False, **kwargs):\n    \"\"\"RegNetY-8.0GF\"\"\"\n    return _create_regnet('regnety_080', pretrained, **kwargs)\n@register_model\ndef regnety_120(pretrained=False, **kwargs):\n    \"\"\"RegNetY-12GF\"\"\"\n    return _create_regnet('regnety_120', pretrained, **kwargs)\n@register_model\ndef regnety_160(pretrained=False, **kwargs):\n    \"\"\"RegNetY-16GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_120",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_120(pretrained=False, **kwargs):\n    \"\"\"RegNetY-12GF\"\"\"\n    return _create_regnet('regnety_120', pretrained, **kwargs)\n@register_model\ndef regnety_160(pretrained=False, **kwargs):\n    \"\"\"RegNetY-16GF\"\"\"\n    return _create_regnet('regnety_160', pretrained, **kwargs)\n@register_model\ndef regnety_320(pretrained=False, **kwargs):\n    \"\"\"RegNetY-32GF\"\"\"",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_160",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_160(pretrained=False, **kwargs):\n    \"\"\"RegNetY-16GF\"\"\"\n    return _create_regnet('regnety_160', pretrained, **kwargs)\n@register_model\ndef regnety_320(pretrained=False, **kwargs):\n    \"\"\"RegNetY-32GF\"\"\"\n    return _create_regnet('regnety_320', pretrained, **kwargs)",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "regnety_320",
        "kind": 2,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "def regnety_320(pretrained=False, **kwargs):\n    \"\"\"RegNetY-32GF\"\"\"\n    return _create_regnet('regnety_320', pretrained, **kwargs)",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "model_cfgs = dict(\n    regnetx_002=_mcfg(w0=24, wa=36.44, wm=2.49, group_w=8, depth=13),\n    regnetx_004=_mcfg(w0=24, wa=24.48, wm=2.54, group_w=16, depth=22),\n    regnetx_006=_mcfg(w0=48, wa=36.97, wm=2.24, group_w=24, depth=16),\n    regnetx_008=_mcfg(w0=56, wa=35.73, wm=2.28, group_w=16, depth=16),\n    regnetx_016=_mcfg(w0=80, wa=34.01, wm=2.25, group_w=24, depth=18),\n    regnetx_032=_mcfg(w0=88, wa=26.31, wm=2.25, group_w=48, depth=25),\n    regnetx_040=_mcfg(w0=96, wa=38.65, wm=2.43, group_w=40, depth=23),\n    regnetx_064=_mcfg(w0=184, wa=60.83, wm=2.07, group_w=56, depth=17),\n    regnetx_080=_mcfg(w0=80, wa=49.56, wm=2.88, group_w=120, depth=23),",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.regnet",
        "description": "timm.models.regnet",
        "peekOfCode": "default_cfgs = dict(\n    regnetx_002=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_002-e7e85e5c.pth'),\n    regnetx_004=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_004-7d0e9424.pth'),\n    regnetx_006=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_006-85ec1baa.pth'),\n    regnetx_008=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_008-d8b470eb.pth'),\n    regnetx_016=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_016-65ca972a.pth'),\n    regnetx_032=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_032-ed0c7f7e.pth'),\n    regnetx_040=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_040-73c2a654.pth'),\n    regnetx_064=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_064-29278baa.pth'),\n    regnetx_080=_cfg(url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_080-7c7fcab1.pth'),",
        "detail": "timm.models.regnet",
        "documentation": {}
    },
    {
        "label": "Bottle2neck",
        "kind": 6,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "class Bottle2neck(nn.Module):\n    \"\"\" Res2Net/Res2NeXT Bottleneck\n    Adapted from https://github.com/gasvn/Res2Net/blob/master/res2net.py\n    \"\"\"\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 cardinality=1, base_width=26, scale=4, dilation=1, first_dilation=None,\n                 act_layer=nn.ReLU, norm_layer=None, attn_layer=None, **_):\n        super(Bottle2neck, self).__init__()\n        self.scale = scale",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net50_26w_4s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net50_26w_4s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-50 26w4s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=4), **kwargs)\n    return _create_res2net('res2net50_26w_4s', pretrained, **model_args)\n@register_model\ndef res2net101_26w_4s(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net101_26w_4s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net101_26w_4s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-101 26w4s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 23, 3], base_width=26, block_args=dict(scale=4), **kwargs)\n    return _create_res2net('res2net101_26w_4s', pretrained, **model_args)\n@register_model\ndef res2net50_26w_6s(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net50_26w_6s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net50_26w_6s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-50 26w6s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=6), **kwargs)\n    return _create_res2net('res2net50_26w_6s', pretrained, **model_args)\n@register_model\ndef res2net50_26w_8s(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net50_26w_8s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net50_26w_8s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-50 26w8s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=8), **kwargs)\n    return _create_res2net('res2net50_26w_8s', pretrained, **model_args)\n@register_model\ndef res2net50_48w_2s(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net50_48w_2s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net50_48w_2s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-50 48w2s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=48, block_args=dict(scale=2), **kwargs)\n    return _create_res2net('res2net50_48w_2s', pretrained, **model_args)\n@register_model\ndef res2net50_14w_8s(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2net50_14w_8s",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2net50_14w_8s(pretrained=False, **kwargs):\n    \"\"\"Constructs a Res2Net-50 14w8s model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=14, block_args=dict(scale=8), **kwargs)\n    return _create_res2net('res2net50_14w_8s', pretrained, **model_args)\n@register_model\ndef res2next50(pretrained=False, **kwargs):",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "res2next50",
        "kind": 2,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "def res2next50(pretrained=False, **kwargs):\n    \"\"\"Construct Res2NeXt-50 4s\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model_args = dict(\n        block=Bottle2neck, layers=[3, 4, 6, 3], base_width=4, cardinality=8, block_args=dict(scale=4), **kwargs)\n    return _create_res2net('res2next50', pretrained, **model_args)",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "__all__ = []\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv1', 'classifier': 'fc',\n        **kwargs\n    }",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.res2net",
        "description": "timm.models.res2net",
        "peekOfCode": "default_cfgs = {\n    'res2net50_26w_4s': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_4s-06e79181.pth'),\n    'res2net50_48w_2s': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_48w_2s-afed724a.pth'),\n    'res2net50_14w_8s': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_14w_8s-6527dddc.pth'),\n    'res2net50_26w_6s': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net50_26w_6s-19041792.pth'),\n    'res2net50_26w_8s': _cfg(",
        "detail": "timm.models.res2net",
        "documentation": {}
    },
    {
        "label": "ResNestBottleneck",
        "kind": 6,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "class ResNestBottleneck(nn.Module):\n    \"\"\"ResNet Bottleneck\n    \"\"\"\n    # pylint: disable=unused-argument\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 radix=1, cardinality=1, base_width=64, avd=False, avd_first=False, is_first=False,\n                 reduce_first=1, dilation=1, first_dilation=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,\n                 attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(ResNestBottleneck, self).__init__()",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest14d",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest14d(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-14d model. Weights ported from GluonCV.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[1, 1, 1, 1],\n        stem_type='deep', stem_width=32, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest14d', pretrained=pretrained, **model_kwargs)\n@register_model\ndef resnest26d(pretrained=False, **kwargs):",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest26d",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest26d(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-26d model. Weights ported from GluonCV.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[2, 2, 2, 2],\n        stem_type='deep', stem_width=32, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest26d', pretrained=pretrained, **model_kwargs)\n@register_model\ndef resnest50d(pretrained=False, **kwargs):",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest50d",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest50d(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-50d model. Matches paper ResNeSt-50 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'd' for deep stem, stem_width 32, avg in downsample.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 4, 6, 3],\n        stem_type='deep', stem_width=32, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest50d', pretrained=pretrained, **model_kwargs)\n@register_model",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest101e",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest101e(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-101e model. Matches paper ResNeSt-101 model, https://arxiv.org/abs/2004.08955\n     Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 4, 23, 3],\n        stem_type='deep', stem_width=64, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest101e', pretrained=pretrained, **model_kwargs)\n@register_model",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest200e",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest200e(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-200e model. Matches paper ResNeSt-200 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 24, 36, 3],\n        stem_type='deep', stem_width=64, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest200e', pretrained=pretrained, **model_kwargs)\n@register_model",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest269e",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest269e(pretrained=False, **kwargs):\n    \"\"\" ResNeSt-269e model. Matches paper ResNeSt-269 model, https://arxiv.org/abs/2004.08955\n    Since this codebase supports all possible variations, 'e' for deep stem, stem_width 64, avg in downsample.\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 30, 48, 8],\n        stem_type='deep', stem_width=64, avg_down=True, base_width=64, cardinality=1,\n        block_args=dict(radix=2, avd=True, avd_first=False), **kwargs)\n    return _create_resnest('resnest269e', pretrained=pretrained, **model_kwargs)\n@register_model",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest50d_4s2x40d",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest50d_4s2x40d(pretrained=False, **kwargs):\n    \"\"\"ResNeSt-50 4s2x40d from https://github.com/zhanghang1989/ResNeSt/blob/master/ablation.md\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 4, 6, 3],\n        stem_type='deep', stem_width=32, avg_down=True, base_width=40, cardinality=2,\n        block_args=dict(radix=4, avd=True, avd_first=True), **kwargs)\n    return _create_resnest('resnest50d_4s2x40d', pretrained=pretrained, **model_kwargs)\n@register_model\ndef resnest50d_1s4x24d(pretrained=False, **kwargs):",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "resnest50d_1s4x24d",
        "kind": 2,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "def resnest50d_1s4x24d(pretrained=False, **kwargs):\n    \"\"\"ResNeSt-50 1s4x24d from https://github.com/zhanghang1989/ResNeSt/blob/master/ablation.md\n    \"\"\"\n    model_kwargs = dict(\n        block=ResNestBottleneck, layers=[3, 4, 6, 3],\n        stem_type='deep', stem_width=32, avg_down=True, base_width=24, cardinality=4,\n        block_args=dict(radix=1, avd=True, avd_first=True), **kwargs)\n    return _create_resnest('resnest50d_1s4x24d', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.resnest",
        "description": "timm.models.resnest",
        "peekOfCode": "default_cfgs = {\n    'resnest14d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest14-9c8fe254.pth'),\n    'resnest26d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest26-50eb607c.pth'),\n    'resnest50d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth'),\n    'resnest101e': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest101-22405ba7.pth',\n        input_size=(3, 256, 256), pool_size=(8, 8)),",
        "detail": "timm.models.resnest",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "class BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, cardinality=1, base_width=64,\n                 reduce_first=1, dilation=1, first_dilation=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,\n                 attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(BasicBlock, self).__init__()\n        assert cardinality == 1, 'BasicBlock only supports cardinality of 1'\n        assert base_width == 64, 'BasicBlock does not support changing base width'\n        first_planes = planes // reduce_first\n        outplanes = planes * self.expansion",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "class Bottleneck(nn.Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None, cardinality=1, base_width=64,\n                 reduce_first=1, dilation=1, first_dilation=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,\n                 attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(Bottleneck, self).__init__()\n        width = int(math.floor(planes * (base_width / 64)) * cardinality)\n        first_planes = width // reduce_first\n        outplanes = planes * self.expansion\n        first_dilation = first_dilation or dilation",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ResNet",
        "kind": 6,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "class ResNet(nn.Module):\n    \"\"\"ResNet / ResNeXt / SE-ResNeXt / SE-Net\n    This class implements all variants of ResNet, ResNeXt, SE-ResNeXt, and SENet that\n      * have > 1 stride in the 3x3 conv layer of bottleneck\n      * have conv-bn-act ordering\n    This ResNet impl supports a number of stem and downsample options based on the v1c, v1d, v1e, and v1s\n    variants included in the MXNet Gluon ResNetV1b model. The C and D variants are also discussed in the\n    'Bag of Tricks' paper: https://arxiv.org/pdf/1812.01187. The B variant is equivalent to torchvision default.\n    ResNet variants (the same modifications can be used in SE/ResNeXt models as well):\n      * normal, b - 7x7 stem, stem_width = 64, same as torchvision ResNet, NVIDIA ResNet 'v1.5', Gluon v1b",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "get_padding",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def get_padding(kernel_size, stride, dilation=1):\n    padding = ((stride - 1) + dilation * (kernel_size - 1)) // 2\n    return padding\ndef create_aa(aa_layer, channels, stride=2, enable=True):\n    if not aa_layer or not enable:\n        return None\n    return aa_layer(stride) if issubclass(aa_layer, nn.AvgPool2d) else aa_layer(channels=channels, stride=stride)\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, cardinality=1, base_width=64,",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "create_aa",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def create_aa(aa_layer, channels, stride=2, enable=True):\n    if not aa_layer or not enable:\n        return None\n    return aa_layer(stride) if issubclass(aa_layer, nn.AvgPool2d) else aa_layer(channels=channels, stride=stride)\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, cardinality=1, base_width=64,\n                 reduce_first=1, dilation=1, first_dilation=None, act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d,\n                 attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(BasicBlock, self).__init__()",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "downsample_conv",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def downsample_conv(\n        in_channels, out_channels, kernel_size, stride=1, dilation=1, first_dilation=None, norm_layer=None):\n    norm_layer = norm_layer or nn.BatchNorm2d\n    kernel_size = 1 if stride == 1 and dilation == 1 else kernel_size\n    first_dilation = (first_dilation or dilation) if kernel_size > 1 else 1\n    p = get_padding(kernel_size, stride, first_dilation)\n    return nn.Sequential(*[\n        nn.Conv2d(\n            in_channels, out_channels, kernel_size, stride=stride, padding=p, dilation=first_dilation, bias=False),\n        norm_layer(out_channels)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "downsample_avg",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def downsample_avg(\n        in_channels, out_channels, kernel_size, stride=1, dilation=1, first_dilation=None, norm_layer=None):\n    norm_layer = norm_layer or nn.BatchNorm2d\n    avg_stride = stride if dilation == 1 else 1\n    if stride == 1 and dilation == 1:\n        pool = nn.Identity()\n    else:\n        avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n        pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)\n    return nn.Sequential(*[",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "drop_blocks",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def drop_blocks(drop_block_rate=0.):\n    return [\n        None, None,\n        DropBlock2d(drop_block_rate, 5, 0.25) if drop_block_rate else None,\n        DropBlock2d(drop_block_rate, 3, 1.00) if drop_block_rate else None]\ndef make_blocks(\n        block_fn, channels, block_repeats, inplanes, reduce_first=1, output_stride=32,\n        down_kernel_size=1, avg_down=False, drop_block_rate=0., drop_path_rate=0., **kwargs):\n    stages = []\n    feature_info = []",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "make_blocks",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def make_blocks(\n        block_fn, channels, block_repeats, inplanes, reduce_first=1, output_stride=32,\n        down_kernel_size=1, avg_down=False, drop_block_rate=0., drop_path_rate=0., **kwargs):\n    stages = []\n    feature_info = []\n    net_num_blocks = sum(block_repeats)\n    net_block_idx = 0\n    net_stride = 4\n    dilation = prev_dilation = 1\n    for stage_idx, (planes, num_blocks, db) in enumerate(zip(channels, block_repeats, drop_blocks(drop_block_rate))):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet18",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], **kwargs)\n    return _create_resnet('resnet18', pretrained, **model_args)\n@register_model\ndef resnet18d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18-D model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet18d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet18d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18-D model.\n    \"\"\"\n    model_args = dict(\n        block=BasicBlock, layers=[2, 2, 2, 2], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet18d', pretrained, **model_args)\n@register_model\ndef resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet34",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], **kwargs)\n    return _create_resnet('resnet34', pretrained, **model_args)\n@register_model\ndef resnet34d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34-D model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet34d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet34d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34-D model.\n    \"\"\"\n    model_args = dict(\n        block=BasicBlock, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet34d', pretrained, **model_args)\n@register_model\ndef resnet26(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26 model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet26",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet26(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[2, 2, 2, 2], **kwargs)\n    return _create_resnet('resnet26', pretrained, **model_args)\n@register_model\ndef resnet26t(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26-T model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet26t",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet26t(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26-T model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], stem_width=32, stem_type='deep_tiered', avg_down=True, **kwargs)\n    return _create_resnet('resnet26t', pretrained, **model_args)\n@register_model\ndef resnet26d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26-D model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet26d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet26d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-26-D model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[2, 2, 2, 2], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet26d', pretrained, **model_args)\n@register_model\ndef resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('resnet50', pretrained, **model_args)\n@register_model\ndef resnet50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet50d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet50d', pretrained, **model_args)\n@register_model\ndef resnet50t(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-T model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet50t",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet50t(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-T model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep_tiered', avg_down=True, **kwargs)\n    return _create_resnet('resnet50t', pretrained, **model_args)\n@register_model\ndef resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet101",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], **kwargs)\n    return _create_resnet('resnet101', pretrained, **model_args)\n@register_model\ndef resnet101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet101d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet101d', pretrained, **model_args)\n@register_model\ndef resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet152",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)\n    return _create_resnet('resnet152', pretrained, **model_args)\n@register_model\ndef resnet152d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152-D model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet152d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet152d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152-D model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet152d', pretrained, **model_args)\n@register_model\ndef resnet200(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200 model.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet200",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet200(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200 model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 24, 36, 3], **kwargs)\n    return _create_resnet('resnet200', pretrained, **model_args)\n@register_model\ndef resnet200d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200-D model.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet200d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet200d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200-D model.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 24, 36, 3], stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnet200d', pretrained, **model_args)\n@register_model\ndef tv_resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model with original Torchvision weights.\n    \"\"\"",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "tv_resnet34",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def tv_resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model with original Torchvision weights.\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], **kwargs)\n    return _create_resnet('tv_resnet34', pretrained, **model_args)\n@register_model\ndef tv_resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model with original Torchvision weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "tv_resnet50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def tv_resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model with original Torchvision weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('tv_resnet50', pretrained, **model_args)\n@register_model\ndef tv_resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model w/ Torchvision pretrained weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "tv_resnet101",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def tv_resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model w/ Torchvision pretrained weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], **kwargs)\n    return _create_resnet('tv_resnet101', pretrained, **model_args)\n@register_model\ndef tv_resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model w/ Torchvision pretrained weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "tv_resnet152",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def tv_resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model w/ Torchvision pretrained weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], **kwargs)\n    return _create_resnet('tv_resnet152', pretrained, **model_args)\n@register_model\ndef wide_resnet50_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a Wide ResNet-50-2 model.\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "wide_resnet50_2",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def wide_resnet50_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a Wide ResNet-50-2 model.\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], base_width=128, **kwargs)\n    return _create_resnet('wide_resnet50_2', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "wide_resnet101_2",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def wide_resnet101_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a Wide ResNet-101-2 model.\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], base_width=128, **kwargs)\n    return _create_resnet('wide_resnet101_2', pretrained, **model_args)\n@register_model\ndef resnet50_gn(pretrained=False, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnet50_gn",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnet50_gn(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model w/ GroupNorm\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('resnet50_gn', pretrained, norm_layer=GroupNorm, **model_args)\n@register_model\ndef resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('resnext50_32x4d', pretrained, **model_args)\n@register_model\ndef resnext50d_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50d-32x4d model. ResNext50 w/ deep stem & avg pool downsample\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnext50d_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnext50d_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50d-32x4d model. ResNext50 w/ deep stem & avg pool downsample\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3],  cardinality=32, base_width=4,\n        stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnext50d_32x4d', pretrained, **model_args)\n@register_model\ndef resnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x4d model.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnext101_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('resnext101_32x4d', pretrained, **model_args)\n@register_model\ndef resnext101_32x8d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnext101_32x8d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnext101_32x8d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8, **kwargs)\n    return _create_resnet('resnext101_32x8d', pretrained, **model_args)\n@register_model\ndef resnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt101-64x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=64, base_width=4, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnext101_64x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnext101_64x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt101-64x4d model.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=64, base_width=4, **kwargs)\n    return _create_resnet('resnext101_64x4d', pretrained, **model_args)\n@register_model\ndef tv_resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model with original Torchvision weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "tv_resnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def tv_resnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNeXt50-32x4d model with original Torchvision weights.\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('tv_resnext50_32x4d', pretrained, **model_args)\n@register_model\ndef ig_resnext101_32x8d(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ig_resnext101_32x8d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ig_resnext101_32x8d(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8, **kwargs)\n    return _create_resnet('ig_resnext101_32x8d', pretrained, **model_args)\n@register_model\ndef ig_resnext101_32x16d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ig_resnext101_32x16d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ig_resnext101_32x16d(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x16 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=16, **kwargs)\n    return _create_resnet('ig_resnext101_32x16d', pretrained, **model_args)\n@register_model\ndef ig_resnext101_32x32d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ig_resnext101_32x32d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ig_resnext101_32x32d(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x32 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=32, **kwargs)\n    return _create_resnet('ig_resnext101_32x32d', pretrained, **model_args)\n@register_model\ndef ig_resnext101_32x48d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ig_resnext101_32x48d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ig_resnext101_32x48d(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x48 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Weights from https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=48, **kwargs)\n    return _create_resnet('ig_resnext101_32x48d', pretrained, **model_args)\n@register_model\ndef ssl_resnet18(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnet18",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnet18(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNet-18 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], **kwargs)\n    return _create_resnet('ssl_resnet18', pretrained, **model_args)\n@register_model\ndef ssl_resnet50(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNet-50 model pre-trained on YFCC100M dataset and finetuned on ImageNet",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnet50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnet50(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNet-50 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('ssl_resnet50', pretrained, **model_args)\n@register_model\ndef ssl_resnext50_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-50 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnext50_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-50 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('ssl_resnext50_32x4d', pretrained, **model_args)\n@register_model\ndef ssl_resnext101_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnext101_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x4 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('ssl_resnext101_32x4d', pretrained, **model_args)\n@register_model\ndef ssl_resnext101_32x8d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x8 model pre-trained on YFCC100M dataset and finetuned on ImageNet",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnext101_32x8d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnext101_32x8d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x8 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8, **kwargs)\n    return _create_resnet('ssl_resnext101_32x8d', pretrained, **model_args)\n@register_model\ndef ssl_resnext101_32x16d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x16 model pre-trained on YFCC100M dataset and finetuned on ImageNet",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ssl_resnext101_32x16d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ssl_resnext101_32x16d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-supervised ResNeXt-101 32x16 model pre-trained on YFCC100M dataset and finetuned on ImageNet\n    `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n    Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=16, **kwargs)\n    return _create_resnet('ssl_resnext101_32x16d', pretrained, **model_args)\n@register_model\ndef swsl_resnet18(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised Resnet-18 model pre-trained on 1B weakly supervised",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnet18",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnet18(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised Resnet-18 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], **kwargs)\n    return _create_resnet('swsl_resnet18', pretrained, **model_args)\n@register_model\ndef swsl_resnet50(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnet50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnet50(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised ResNet-50 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3],  **kwargs)\n    return _create_resnet('swsl_resnet50', pretrained, **model_args)\n@register_model\ndef swsl_resnext50_32x4d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnext50_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised ResNeXt-50 32x4 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('swsl_resnext50_32x4d', pretrained, **model_args)\n@register_model\ndef swsl_resnext101_32x4d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnext101_32x4d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x4 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4, **kwargs)\n    return _create_resnet('swsl_resnext101_32x4d', pretrained, **model_args)\n@register_model\ndef swsl_resnext101_32x8d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnext101_32x8d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnext101_32x8d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x8 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8, **kwargs)\n    return _create_resnet('swsl_resnext101_32x8d', pretrained, **model_args)\n@register_model\ndef swsl_resnext101_32x16d(pretrained=True, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "swsl_resnext101_32x16d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def swsl_resnext101_32x16d(pretrained=True, **kwargs):\n    \"\"\"Constructs a semi-weakly supervised ResNeXt-101 32x16 model pre-trained on 1B weakly supervised\n       image dataset and finetuned on ImageNet.\n       `\"Billion-scale Semi-Supervised Learning for Image Classification\" <https://arxiv.org/abs/1905.00546>`_\n       Weights from https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=16, **kwargs)\n    return _create_resnet('swsl_resnext101_32x16d', pretrained, **model_args)\n@register_model\ndef ecaresnet26t(pretrained=False, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet26t",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet26t(pretrained=False, **kwargs):\n    \"\"\"Constructs an ECA-ResNeXt-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem and ECA attn.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], stem_width=32,\n        stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet26t', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet50d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model with eca.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet50d', pretrained, **model_args)\n@register_model\ndef resnetrs50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-50 model.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-50 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs50', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs101",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-101 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs101', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs152",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-152 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs152', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs200",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs200(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-200 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[3, 24, 36, 3], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs200', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs270",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs270(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-270 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[4, 29, 53, 4], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs270', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs350",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs350(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-350 model.\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[4, 36, 72, 4], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs350', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetrs420",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetrs420(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-RS-420 model\n    Paper: Revisiting ResNets - https://arxiv.org/abs/2103.07579\n    Pretrained weights from https://github.com/tensorflow/tpu/tree/bee9c4f6/models/official/resnet/resnet_rs\n    \"\"\"\n    attn_layer = partial(get_attn('se'), rd_ratio=0.25)\n    model_args = dict(\n        block=Bottleneck, layers=[4, 44, 87, 4], stem_width=32, stem_type='deep', replace_stem_pool=True,\n        avg_down=True,  block_args=dict(attn_layer=attn_layer), **kwargs)\n    return _create_resnet('resnetrs420', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet50d_pruned",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet50d_pruned(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model pruned with eca.\n        The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet50d_pruned', pretrained, pruned=True, **model_args)\n@register_model\ndef ecaresnet50t(pretrained=False, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet50t",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet50t(pretrained=False, **kwargs):\n    \"\"\"Constructs an ECA-ResNet-50-T model.\n    Like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels in the deep stem and ECA attn.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], stem_width=32,\n        stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet50t', pretrained, **model_args)\n@register_model\ndef ecaresnetlight(pretrained=False, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnetlight",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnetlight(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D light model with eca.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[1, 1, 11, 3], stem_width=32, avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnetlight', pretrained, **model_args)\n@register_model\ndef ecaresnet101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with eca.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet101d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with eca.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet101d', pretrained, **model_args)\n@register_model\ndef ecaresnet101d_pruned(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model pruned with eca.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet101d_pruned",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet101d_pruned(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model pruned with eca.\n       The pruning has been obtained using https://arxiv.org/pdf/2002.08258.pdf\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet101d_pruned', pretrained, pruned=True, **model_args)\n@register_model\ndef ecaresnet200d(pretrained=False, **kwargs):",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet200d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet200d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200-D model with ECA.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 24, 36, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet200d', pretrained, **model_args)\n@register_model\ndef ecaresnet269d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-269-D model with ECA.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnet269d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnet269d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-269-D model with ECA.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 30, 48, 8], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnet269d', pretrained, **model_args)\n@register_model\ndef ecaresnext26t_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs an ECA-ResNeXt-26-T model.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnext26t_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnext26t_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs an ECA-ResNeXt-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem. This model replaces SE module with the ECA module\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], cardinality=32, base_width=4, stem_width=32,\n        stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnext26t_32x4d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "ecaresnext50t_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def ecaresnext50t_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs an ECA-ResNeXt-50-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem. This model replaces SE module with the ECA module\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], cardinality=32, base_width=4, stem_width=32,\n        stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'), **kwargs)\n    return _create_resnet('ecaresnext50t_32x4d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetblur18",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetblur18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], aa_layer=BlurPool2d, **kwargs)\n    return _create_resnet('resnetblur18', pretrained, **model_args)\n@register_model\ndef resnetblur50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], aa_layer=BlurPool2d, **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetblur50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetblur50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], aa_layer=BlurPool2d, **kwargs)\n    return _create_resnet('resnetblur50', pretrained, **model_args)\n@register_model\ndef resnetblur50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetblur50d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetblur50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], aa_layer=BlurPool2d,\n        stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnetblur50d', pretrained, **model_args)\n@register_model\ndef resnetblur101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with blur anti-aliasing",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetblur101d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetblur101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with blur anti-aliasing\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], aa_layer=BlurPool2d,\n        stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnetblur101d', pretrained, **model_args)\n@register_model\ndef resnetaa50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model with avgpool anti-aliasing",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetaa50d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetaa50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50-D model with avgpool anti-aliasing\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], aa_layer=nn.AvgPool2d,\n        stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnetaa50d', pretrained, **model_args)\n@register_model\ndef resnetaa101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with avgpool anti-aliasing",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "resnetaa101d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def resnetaa101d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101-D model with avgpool anti-aliasing\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], aa_layer=nn.AvgPool2d,\n        stem_width=32, stem_type='deep', avg_down=True, **kwargs)\n    return _create_resnet('resnetaa101d', pretrained, **model_args)\n@register_model\ndef seresnetaa50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE=ResNet-50-D model with avgpool anti-aliasing",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnetaa50d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnetaa50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE=ResNet-50-D model with avgpool anti-aliasing\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], aa_layer=nn.AvgPool2d,\n        stem_width=32, stem_type='deep', avg_down=True, block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnetaa50d', pretrained, **model_args)\n@register_model\ndef seresnet18(pretrained=False, **kwargs):\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], block_args=dict(attn_layer='se'), **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet18",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet18(pretrained=False, **kwargs):\n    model_args = dict(block=BasicBlock, layers=[2, 2, 2, 2], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet18', pretrained, **model_args)\n@register_model\ndef seresnet34(pretrained=False, **kwargs):\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet34', pretrained, **model_args)\n@register_model\ndef seresnet50(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], block_args=dict(attn_layer='se'), **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet34",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet34(pretrained=False, **kwargs):\n    model_args = dict(block=BasicBlock, layers=[3, 4, 6, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet34', pretrained, **model_args)\n@register_model\ndef seresnet50(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet50', pretrained, **model_args)\n@register_model\ndef seresnet50t(pretrained=False, **kwargs):\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet50",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet50(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 4, 6, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet50', pretrained, **model_args)\n@register_model\ndef seresnet50t(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3],  stem_width=32, stem_type='deep_tiered', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet50t', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet50t",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet50t(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3],  stem_width=32, stem_type='deep_tiered', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet50t', pretrained, **model_args)\n@register_model\ndef seresnet101(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet101', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet101",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet101(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 4, 23, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet101', pretrained, **model_args)\n@register_model\ndef seresnet152(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet152', pretrained, **model_args)\n@register_model\ndef seresnet152d(pretrained=False, **kwargs):\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet152",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet152(pretrained=False, **kwargs):\n    model_args = dict(block=Bottleneck, layers=[3, 8, 36, 3], block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet152', pretrained, **model_args)\n@register_model\ndef seresnet152d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet152d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet152d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet152d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet152d', pretrained, **model_args)\n@register_model\ndef seresnet200d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200-D model with SE attn.\n    \"\"\"\n    model_args = dict(",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet200d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet200d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-200-D model with SE attn.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 24, 36, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet200d', pretrained, **model_args)\n@register_model\ndef seresnet269d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-269-D model with SE attn.",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnet269d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnet269d(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-269-D model with SE attn.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[3, 30, 48, 8], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnet269d', pretrained, **model_args)\n@register_model\ndef seresnext26d_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE-ResNeXt-26-D model.`",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext26d_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext26d_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE-ResNeXt-26-D model.`\n    This is technically a 28 layer ResNet, using the 'D' modifier from Gluon / bag-of-tricks for\n    combination of deep stem and avg_pool in downsample.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], cardinality=32, base_width=4, stem_width=32,\n        stem_type='deep', avg_down=True, block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnext26d_32x4d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext26t_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext26t_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE-ResNet-26-T model.\n    This is technically a 28 layer ResNet, like a 'D' bag-of-tricks model but with tiered 24, 32, 64 channels\n    in the deep stem.\n    \"\"\"\n    model_args = dict(\n        block=Bottleneck, layers=[2, 2, 2, 2], cardinality=32, base_width=4, stem_width=32,\n        stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnext26t_32x4d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext26tn_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext26tn_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a SE-ResNeXt-26-T model.\n    NOTE I deprecated previous 't' model defs and replaced 't' with 'tn', this was the only tn model of note\n    so keeping this def for backwards compat with any uses out there. Old 't' model is lost.\n    \"\"\"\n    return seresnext26t_32x4d(pretrained=pretrained, **kwargs)\n@register_model\ndef seresnext50_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4,",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext50_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnext50_32x4d', pretrained, **model_args)\n@register_model\ndef seresnext101_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4,\n        block_args=dict(attn_layer='se'), **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext101_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=4,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnext101_32x4d', pretrained, **model_args)\n@register_model\ndef seresnext101_32x8d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8,\n        block_args=dict(attn_layer='se'), **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "seresnext101_32x8d",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def seresnext101_32x8d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 4, 23, 3], cardinality=32, base_width=8,\n        block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('seresnext101_32x8d', pretrained, **model_args)\n@register_model\ndef senet154(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], cardinality=64, base_width=4, stem_type='deep',\n        down_kernel_size=3, block_reduce_first=2, block_args=dict(attn_layer='se'), **kwargs)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "senet154",
        "kind": 2,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "def senet154(pretrained=False, **kwargs):\n    model_args = dict(\n        block=Bottleneck, layers=[3, 8, 36, 3], cardinality=64, base_width=4, stem_type='deep',\n        down_kernel_size=3, block_reduce_first=2, block_args=dict(attn_layer='se'), **kwargs)\n    return _create_resnet('senet154', pretrained, **model_args)",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "__all__ = ['ResNet', 'BasicBlock', 'Bottleneck']  # model_registry will add each entrypoint fn to this\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'conv1', 'classifier': 'fc',\n        **kwargs\n    }",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.resnet",
        "description": "timm.models.resnet",
        "peekOfCode": "default_cfgs = {\n    # ResNet and Wide ResNet\n    'resnet18': _cfg(url='https://download.pytorch.org/models/resnet18-5c106cde.pth'),\n    'resnet18d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet18d_ra2-48a79e06.pth',\n        interpolation='bicubic', first_conv='conv1.0'),\n    'resnet34': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth'),\n    'resnet34d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34d_ra2-f8dcfcaf.pth',",
        "detail": "timm.models.resnet",
        "documentation": {}
    },
    {
        "label": "PreActBottleneck",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class PreActBottleneck(nn.Module):\n    \"\"\"Pre-activation (v2) bottleneck block.\n    Follows the implementation of \"Identity Mappings in Deep Residual Networks\":\n    https://github.com/KaimingHe/resnet-1k-layers/blob/master/resnet-pre-act.lua\n    Except it puts the stride on 3x3 conv when available.\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs=None, bottle_ratio=0.25, stride=1, dilation=1, first_dilation=None, groups=1,\n            act_layer=None, conv_layer=None, norm_layer=None, proj_layer=None, drop_path_rate=0.):\n        super().__init__()",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class Bottleneck(nn.Module):\n    \"\"\"Non Pre-activation bottleneck block, equiv to V1.5/V1b Bottleneck. Used for ViT.\n    \"\"\"\n    def __init__(\n            self, in_chs, out_chs=None, bottle_ratio=0.25, stride=1, dilation=1, first_dilation=None, groups=1,\n            act_layer=None, conv_layer=None, norm_layer=None, proj_layer=None, drop_path_rate=0.):\n        super().__init__()\n        first_dilation = first_dilation or dilation\n        act_layer = act_layer or nn.ReLU\n        conv_layer = conv_layer or StdConv2d",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "DownsampleConv",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class DownsampleConv(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=1, dilation=1, first_dilation=None, preact=True,\n            conv_layer=None, norm_layer=None):\n        super(DownsampleConv, self).__init__()\n        self.conv = conv_layer(in_chs, out_chs, 1, stride=stride)\n        self.norm = nn.Identity() if preact else norm_layer(out_chs, apply_act=False)\n    def forward(self, x):\n        return self.norm(self.conv(x))\nclass DownsampleAvg(nn.Module):",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "DownsampleAvg",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class DownsampleAvg(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=1, dilation=1, first_dilation=None,\n            preact=True, conv_layer=None, norm_layer=None):\n        \"\"\" AvgPool Downsampling as in 'D' ResNet variants. This is not in RegNet space but I might experiment.\"\"\"\n        super(DownsampleAvg, self).__init__()\n        avg_stride = stride if dilation == 1 else 1\n        if stride > 1 or dilation > 1:\n            avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n            self.pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "ResNetStage",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class ResNetStage(nn.Module):\n    \"\"\"ResNet Stage.\"\"\"\n    def __init__(self, in_chs, out_chs, stride, dilation, depth, bottle_ratio=0.25, groups=1,\n                 avg_down=False, block_dpr=None, block_fn=PreActBottleneck,\n                 act_layer=None, conv_layer=None, norm_layer=None, **block_kwargs):\n        super(ResNetStage, self).__init__()\n        first_dilation = 1 if dilation in (1, 2) else 2\n        layer_kwargs = dict(act_layer=act_layer, conv_layer=conv_layer, norm_layer=norm_layer)\n        proj_layer = DownsampleAvg if avg_down else DownsampleConv\n        prev_chs = in_chs",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "ResNetV2",
        "kind": 6,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "class ResNetV2(nn.Module):\n    \"\"\"Implementation of Pre-activation (v2) ResNet mode.\n    \"\"\"\n    def __init__(\n            self, layers, channels=(256, 512, 1024, 2048),\n            num_classes=1000, in_chans=3, global_pool='avg', output_stride=32,\n            width_factor=1, stem_chs=64, stem_type='', avg_down=False, preact=True,\n            act_layer=nn.ReLU, conv_layer=StdConv2d, norm_layer=partial(GroupNormAct, num_groups=32),\n            drop_rate=0., drop_path_rate=0., zero_init_last=False):\n        super().__init__()",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "make_div",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def make_div(v, divisor=8):\n    min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\nclass PreActBottleneck(nn.Module):\n    \"\"\"Pre-activation (v2) bottleneck block.\n    Follows the implementation of \"Identity Mappings in Deep Residual Networks\":\n    https://github.com/KaimingHe/resnet-1k-layers/blob/master/resnet-pre-act.lua",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "is_stem_deep",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def is_stem_deep(stem_type):\n    return any([s in stem_type for s in ('deep', 'tiered')])\ndef create_resnetv2_stem(\n        in_chs, out_chs=64, stem_type='', preact=True,\n        conv_layer=StdConv2d, norm_layer=partial(GroupNormAct, num_groups=32)):\n    stem = OrderedDict()\n    assert stem_type in ('', 'fixed', 'same', 'deep', 'deep_fixed', 'deep_same', 'tiered')\n    # NOTE conv padding mode can be changed by overriding the conv_layer def\n    if is_stem_deep(stem_type):\n        # A 3 deep 3x3  conv stack as in ResNet V1D models",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "create_resnetv2_stem",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def create_resnetv2_stem(\n        in_chs, out_chs=64, stem_type='', preact=True,\n        conv_layer=StdConv2d, norm_layer=partial(GroupNormAct, num_groups=32)):\n    stem = OrderedDict()\n    assert stem_type in ('', 'fixed', 'same', 'deep', 'deep_fixed', 'deep_same', 'tiered')\n    # NOTE conv padding mode can be changed by overriding the conv_layer def\n    if is_stem_deep(stem_type):\n        # A 3 deep 3x3  conv stack as in ResNet V1D models\n        if 'tiered' in stem_type:\n            stem_chs = (3 * out_chs // 8, out_chs // 2)  # 'T' resnets in resnet.py",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50x1_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50x1_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x1_bitm', pretrained=pretrained, layers=[3, 4, 6, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_50x3_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x3_bitm', pretrained=pretrained, layers=[3, 4, 6, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_101x1_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50x3_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50x3_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x3_bitm', pretrained=pretrained, layers=[3, 4, 6, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_101x1_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x1_bitm', pretrained=pretrained, layers=[3, 4, 23, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_101x3_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101x1_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101x1_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x1_bitm', pretrained=pretrained, layers=[3, 4, 23, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_101x3_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x3_bitm', pretrained=pretrained, layers=[3, 4, 23, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_152x2_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101x3_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101x3_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x3_bitm', pretrained=pretrained, layers=[3, 4, 23, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_152x2_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bitm', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model\ndef resnetv2_152x4_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x2_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x2_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bitm', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model\ndef resnetv2_152x4_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x4_bitm', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=4, **kwargs)\n@register_model\ndef resnetv2_50x1_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x4_bitm",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x4_bitm(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x4_bitm', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=4, **kwargs)\n@register_model\ndef resnetv2_50x1_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x1_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 6, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_50x3_bitm_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50x1_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50x1_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x1_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 6, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_50x3_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x3_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 6, 3], width_factor=3, **kwargs)\n@register_model",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50x3_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50x3_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_50x3_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 6, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_101x1_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101x1_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 23, 3], width_factor=1, **kwargs)\n@register_model",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101x1_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101x1_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101x1_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 23, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_101x3_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x3_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 23, 3], width_factor=3, **kwargs)\n@register_model",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101x3_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101x3_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_101x3_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 4, 23, 3], width_factor=3, **kwargs)\n@register_model\ndef resnetv2_152x2_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x2_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x2_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model\ndef resnetv2_152x4_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x4_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 8, 36, 3], width_factor=4, **kwargs)\n@register_model",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x4_bitm_in21k",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x4_bitm_in21k(pretrained=False, **kwargs):\n    return _create_resnetv2_bit(\n        'resnetv2_152x4_bitm_in21k', pretrained=pretrained, num_classes=kwargs.pop('num_classes', 21843),\n        layers=[3, 8, 36, 3], width_factor=4, **kwargs)\n@register_model\ndef resnetv2_50x1_bit_distilled(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-50x1-BiT Distilled\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"\n    return _create_resnetv2_bit(",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50x1_bit_distilled",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50x1_bit_distilled(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-50x1-BiT Distilled\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"\n    return _create_resnetv2_bit(\n        'resnetv2_50x1_bit_distilled', pretrained=pretrained, layers=[3, 4, 6, 3], width_factor=1, **kwargs)\n@register_model\ndef resnetv2_152x2_bit_teacher(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-152x2-BiT Teacher\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x2_bit_teacher",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x2_bit_teacher(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-152x2-BiT Teacher\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bit_teacher', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model\ndef resnetv2_152x2_bit_teacher_384(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-152xx-BiT Teacher @ 384x384\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152x2_bit_teacher_384",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152x2_bit_teacher_384(pretrained=False, **kwargs):\n    \"\"\" ResNetV2-152xx-BiT Teacher @ 384x384\n    Paper: Knowledge distillation: A good teacher is patient and consistent - https://arxiv.org/abs/2106.05237\n    \"\"\"\n    return _create_resnetv2_bit(\n        'resnetv2_152x2_bit_teacher_384', pretrained=pretrained, layers=[3, 8, 36, 3], width_factor=2, **kwargs)\n@register_model\ndef resnetv2_50(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50', pretrained=pretrained,",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d, **kwargs)\n@register_model\ndef resnetv2_50d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50d",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)\n@register_model\ndef resnetv2_50t(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50t', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50t",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50t(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50t', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='tiered', avg_down=True, **kwargs)\n@register_model\ndef resnetv2_101(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101', pretrained=pretrained,\n        layers=[3, 4, 23, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101', pretrained=pretrained,\n        layers=[3, 4, 23, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d, **kwargs)\n@register_model\ndef resnetv2_101d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101d', pretrained=pretrained,\n        layers=[3, 4, 23, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_101d",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_101d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_101d', pretrained=pretrained,\n        layers=[3, 4, 23, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)\n@register_model\ndef resnetv2_152(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_152', pretrained=pretrained,\n        layers=[3, 8, 36, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_152', pretrained=pretrained,\n        layers=[3, 8, 36, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d, **kwargs)\n@register_model\ndef resnetv2_152d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_152d', pretrained=pretrained,\n        layers=[3, 8, 36, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_152d",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_152d(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_152d', pretrained=pretrained,\n        layers=[3, 8, 36, 3], conv_layer=create_conv2d, norm_layer=BatchNormAct2d,\n        stem_type='deep', avg_down=True, **kwargs)\n# Experimental configs (may change / be removed)\n@register_model\ndef resnetv2_50d_gn(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_gn', pretrained=pretrained,",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50d_gn",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50d_gn(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_gn', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=GroupNormAct,\n        stem_type='deep', avg_down=True, **kwargs)\n@register_model\ndef resnetv2_50d_evob(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_evob', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=EvoNormBatch2d,",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50d_evob",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50d_evob(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_evob', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=EvoNormBatch2d,\n        stem_type='deep', avg_down=True, **kwargs)\n@register_model\ndef resnetv2_50d_evos(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_evos', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=EvoNormSample2d,",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "resnetv2_50d_evos",
        "kind": 2,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "def resnetv2_50d_evos(pretrained=False, **kwargs):\n    return _create_resnetv2(\n        'resnetv2_50d_evos', pretrained=pretrained,\n        layers=[3, 4, 6, 3], conv_layer=create_conv2d, norm_layer=EvoNormSample2d,\n        stem_type='deep', avg_down=True, **kwargs)",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.resnetv2",
        "description": "timm.models.resnetv2",
        "peekOfCode": "default_cfgs = {\n    # pretrained on imagenet21k, finetuned on imagenet1k\n    'resnetv2_50x1_bitm': _cfg(\n        url='https://storage.googleapis.com/bit_models/BiT-M-R50x1-ILSVRC2012.npz',\n        input_size=(3, 448, 448), pool_size=(14, 14), crop_pct=1.0),\n    'resnetv2_50x3_bitm': _cfg(\n        url='https://storage.googleapis.com/bit_models/BiT-M-R50x3-ILSVRC2012.npz',\n        input_size=(3, 448, 448), pool_size=(14, 14), crop_pct=1.0),\n    'resnetv2_101x1_bitm': _cfg(\n        url='https://storage.googleapis.com/bit_models/BiT-M-R101x1-ILSVRC2012.npz',",
        "detail": "timm.models.resnetv2",
        "documentation": {}
    },
    {
        "label": "LinearBottleneck",
        "kind": 6,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "class LinearBottleneck(nn.Module):\n    def __init__(self, in_chs, out_chs, stride, exp_ratio=1.0, se_ratio=0., ch_div=1,\n                 act_layer='swish', dw_act_layer='relu6', drop_path=None):\n        super(LinearBottleneck, self).__init__()\n        self.use_shortcut = stride == 1 and in_chs <= out_chs\n        self.in_channels = in_chs\n        self.out_channels = out_chs\n        if exp_ratio != 1.:\n            dw_chs = make_divisible(round(in_chs * exp_ratio), divisor=ch_div)\n            self.conv_exp = ConvBnAct(in_chs, dw_chs, act_layer=act_layer)",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "ReXNetV1",
        "kind": 6,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "class ReXNetV1(nn.Module):\n    def __init__(self, in_chans=3, num_classes=1000, global_pool='avg', output_stride=32,\n                 initial_chs=16, final_chs=180, width_mult=1.0, depth_mult=1.0, se_ratio=1/12.,\n                 ch_div=1, act_layer='swish', dw_act_layer='relu6', drop_rate=0.2, drop_path_rate=0.):\n        super(ReXNetV1, self).__init__()\n        self.drop_rate = drop_rate\n        self.num_classes = num_classes\n        assert output_stride == 32  # FIXME support dilation\n        stem_base_chs = 32 / width_mult if width_mult < 1.0 else 32\n        stem_chs = make_divisible(round(stem_base_chs * width_mult), divisor=ch_div)",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnet_100",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnet_100(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.0x\"\"\"\n    return _create_rexnet('rexnet_100', pretrained, **kwargs)\n@register_model\ndef rexnet_130(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.3x\"\"\"\n    return _create_rexnet('rexnet_130', pretrained, width_mult=1.3, **kwargs)\n@register_model\ndef rexnet_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnet_130",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnet_130(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.3x\"\"\"\n    return _create_rexnet('rexnet_130', pretrained, width_mult=1.3, **kwargs)\n@register_model\ndef rexnet_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x\"\"\"\n    return _create_rexnet('rexnet_150', pretrained, width_mult=1.5, **kwargs)\n@register_model\ndef rexnet_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnet_150",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnet_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x\"\"\"\n    return _create_rexnet('rexnet_150', pretrained, width_mult=1.5, **kwargs)\n@register_model\ndef rexnet_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x\"\"\"\n    return _create_rexnet('rexnet_200', pretrained, width_mult=2.0, **kwargs)\n@register_model\ndef rexnetr_100(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.0x w/ rounded (mod 8) channels\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnet_200",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnet_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x\"\"\"\n    return _create_rexnet('rexnet_200', pretrained, width_mult=2.0, **kwargs)\n@register_model\ndef rexnetr_100(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.0x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_100', pretrained, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_130(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.3x w/ rounded (mod 8) channels\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnetr_100",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnetr_100(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.0x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_100', pretrained, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_130(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.3x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_130', pretrained, width_mult=1.3, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x w/ rounded (mod 8) channels\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnetr_130",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnetr_130(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.3x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_130', pretrained, width_mult=1.3, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_150', pretrained, width_mult=1.5, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x w/ rounded (mod 8) channels\"\"\"",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnetr_150",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnetr_150(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 1.5x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_150', pretrained, width_mult=1.5, ch_div=8, **kwargs)\n@register_model\ndef rexnetr_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_200', pretrained, width_mult=2.0, ch_div=8, **kwargs)",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "rexnetr_200",
        "kind": 2,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "def rexnetr_200(pretrained=False, **kwargs):\n    \"\"\"ReXNet V1 2.0x w/ rounded (mod 8) channels\"\"\"\n    return _create_rexnet('rexnetr_200', pretrained, width_mult=2.0, ch_div=8, **kwargs)",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "default_cfgs = dict(\n    rexnet_100=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_100-1b4dddf4.pth'),\n    rexnet_130=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_130-590d768e.pth'),\n    rexnet_150=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_150-bd1a6aa8.pth'),\n    rexnet_200=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_200-8c0b7f2d.pth'),\n    rexnetr_100=_cfg(",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "SEWithNorm",
        "kind": 5,
        "importPath": "timm.models.rexnet",
        "description": "timm.models.rexnet",
        "peekOfCode": "SEWithNorm = partial(SEModule, norm_layer=nn.BatchNorm2d)\nclass LinearBottleneck(nn.Module):\n    def __init__(self, in_chs, out_chs, stride, exp_ratio=1.0, se_ratio=0., ch_div=1,\n                 act_layer='swish', dw_act_layer='relu6', drop_path=None):\n        super(LinearBottleneck, self).__init__()\n        self.use_shortcut = stride == 1 and in_chs <= out_chs\n        self.in_channels = in_chs\n        self.out_channels = out_chs\n        if exp_ratio != 1.:\n            dw_chs = make_divisible(round(in_chs * exp_ratio), divisor=ch_div)",
        "detail": "timm.models.rexnet",
        "documentation": {}
    },
    {
        "label": "SequentialList",
        "kind": 6,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "class SequentialList(nn.Sequential):\n    def __init__(self, *args):\n        super(SequentialList, self).__init__(*args)\n    @torch.jit._overload_method  # noqa: F811\n    def forward(self, x):\n        # type: (List[torch.Tensor]) -> (List[torch.Tensor])\n        pass\n    @torch.jit._overload_method  # noqa: F811\n    def forward(self, x):\n        # type: (torch.Tensor) -> (List[torch.Tensor])",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "SelectSeq",
        "kind": 6,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "class SelectSeq(nn.Module):\n    def __init__(self, mode='index', index=0):\n        super(SelectSeq, self).__init__()\n        self.mode = mode\n        self.index = index\n    @torch.jit._overload_method  # noqa: F811\n    def forward(self, x):\n        # type: (List[torch.Tensor]) -> (torch.Tensor)\n        pass\n    @torch.jit._overload_method  # noqa: F811",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "SelecSLSBlock",
        "kind": 6,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "class SelecSLSBlock(nn.Module):\n    def __init__(self, in_chs, skip_chs, mid_chs, out_chs, is_first, stride, dilation=1):\n        super(SelecSLSBlock, self).__init__()\n        self.stride = stride\n        self.is_first = is_first\n        assert stride in [1, 2]\n        # Process input with 4 conv blocks with the same number of input and output channels\n        self.conv1 = conv_bn(in_chs, mid_chs, 3, stride, dilation=dilation)\n        self.conv2 = conv_bn(mid_chs, mid_chs, 1)\n        self.conv3 = conv_bn(mid_chs, mid_chs // 2, 3)",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "SelecSLS",
        "kind": 6,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "class SelecSLS(nn.Module):\n    \"\"\"SelecSLS42 / SelecSLS60 / SelecSLS84\n    Parameters\n    ----------\n    cfg : network config dictionary specifying block type, feature, and head args\n    num_classes : int, default 1000\n        Number of classification classes.\n    in_chans : int, default 3\n        Number of input (color) channels.\n    drop_rate : float, default 0.",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "conv_bn",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def conv_bn(in_chs, out_chs, k=3, stride=1, padding=None, dilation=1):\n    if padding is None:\n        padding = ((stride - 1) + dilation * (k - 1)) // 2\n    return nn.Sequential(\n        nn.Conv2d(in_chs, out_chs, k, stride, padding=padding, dilation=dilation, bias=False),\n        nn.BatchNorm2d(out_chs),\n        nn.ReLU(inplace=True)\n    )\nclass SelecSLSBlock(nn.Module):\n    def __init__(self, in_chs, skip_chs, mid_chs, out_chs, is_first, stride, dilation=1):",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "selecsls42",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def selecsls42(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS42 model.\n    \"\"\"\n    return _create_selecsls('selecsls42', pretrained, **kwargs)\n@register_model\ndef selecsls42b(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS42_B model.\n    \"\"\"\n    return _create_selecsls('selecsls42b', pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "selecsls42b",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def selecsls42b(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS42_B model.\n    \"\"\"\n    return _create_selecsls('selecsls42b', pretrained, **kwargs)\n@register_model\ndef selecsls60(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS60 model.\n    \"\"\"\n    return _create_selecsls('selecsls60', pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "selecsls60",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def selecsls60(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS60 model.\n    \"\"\"\n    return _create_selecsls('selecsls60', pretrained, **kwargs)\n@register_model\ndef selecsls60b(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS60_B model.\n    \"\"\"\n    return _create_selecsls('selecsls60b', pretrained, **kwargs)\n@register_model",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "selecsls60b",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def selecsls60b(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS60_B model.\n    \"\"\"\n    return _create_selecsls('selecsls60b', pretrained, **kwargs)\n@register_model\ndef selecsls84(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS84 model.\n    \"\"\"\n    return _create_selecsls('selecsls84', pretrained, **kwargs)",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "selecsls84",
        "kind": 2,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "def selecsls84(pretrained=False, **kwargs):\n    \"\"\"Constructs a SelecSLS84 model.\n    \"\"\"\n    return _create_selecsls('selecsls84', pretrained, **kwargs)",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "__all__ = ['SelecSLS']  # model_registry will add each entrypoint fn to this\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (4, 4),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.0', 'classifier': 'fc',\n        **kwargs\n    }",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.selecsls",
        "description": "timm.models.selecsls",
        "peekOfCode": "default_cfgs = {\n    'selecsls42': _cfg(\n        url='',\n        interpolation='bicubic'),\n    'selecsls42b': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls42b-8af30141.pth',\n        interpolation='bicubic'),\n    'selecsls60': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls60-bbf87526.pth',\n        interpolation='bicubic'),",
        "detail": "timm.models.selecsls",
        "documentation": {}
    },
    {
        "label": "SEModule",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SEModule(nn.Module):\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        module_input = x\n        x = x.mean((2, 3), keepdim=True)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class Bottleneck(nn.Module):\n    \"\"\"\n    Base class for bottlenecks that implements `forward()` method.\n    \"\"\"\n    def forward(self, x):\n        shortcut = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SEBottleneck",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SEBottleneck(Bottleneck):\n    \"\"\"\n    Bottleneck for SENet154.\n    \"\"\"\n    expansion = 4\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SEResNetBottleneck",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SEResNetBottleneck(Bottleneck):\n    \"\"\"\n    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n    (the latter is used in the torchvision implementation of ResNet).\n    \"\"\"\n    expansion = 4\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEResNetBottleneck, self).__init__()",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SEResNeXtBottleneck",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SEResNeXtBottleneck(Bottleneck):\n    \"\"\"\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    \"\"\"\n    expansion = 4\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None, base_width=4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width / 64)) * groups\n        self.conv1 = nn.Conv2d(",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SEResNetBlock",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SEResNetBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, groups, reduction, stride=1, downsample=None):\n        super(SEResNetBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            inplanes, planes, kernel_size=3, padding=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, padding=1, groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SENet",
        "kind": 6,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "class SENet(nn.Module):\n    def __init__(self, block, layers, groups, reduction, drop_rate=0.2,\n                 in_chans=3, inplanes=64, input_3x3=False, downsample_kernel_size=1,\n                 downsample_padding=0, num_classes=1000, global_pool='avg'):\n        \"\"\"\n        Parameters\n        ----------\n        block (nn.Module): Bottleneck class.\n            - For SENet154: SEBottleneck\n            - For SE-ResNet models: SEResNetBottleneck",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnet18",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnet18(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBlock, layers=[2, 2, 2, 2], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet18', pretrained, **model_args)\n@register_model\ndef legacy_seresnet34(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBlock, layers=[3, 4, 6, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet34', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnet34",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnet34(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBlock, layers=[3, 4, 6, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet34', pretrained, **model_args)\n@register_model\ndef legacy_seresnet50(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 4, 6, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet50', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnet50",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnet50(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 4, 6, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet50', pretrained, **model_args)\n@register_model\ndef legacy_seresnet101(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 4, 23, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet101', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnet101",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnet101(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 4, 23, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet101', pretrained, **model_args)\n@register_model\ndef legacy_seresnet152(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 8, 36, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet152', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnet152",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnet152(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNetBottleneck, layers=[3, 8, 36, 3], groups=1, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnet152', pretrained, **model_args)\n@register_model\ndef legacy_senet154(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEBottleneck, layers=[3, 8, 36, 3], groups=64, reduction=16,\n        downsample_kernel_size=3, downsample_padding=1,  inplanes=128, input_3x3=True, **kwargs)\n    return _create_senet('legacy_senet154', pretrained, **model_args)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_senet154",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_senet154(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEBottleneck, layers=[3, 8, 36, 3], groups=64, reduction=16,\n        downsample_kernel_size=3, downsample_padding=1,  inplanes=128, input_3x3=True, **kwargs)\n    return _create_senet('legacy_senet154', pretrained, **model_args)\n@register_model\ndef legacy_seresnext26_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[2, 2, 2, 2], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext26_32x4d', pretrained, **model_args)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnext26_32x4d",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnext26_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[2, 2, 2, 2], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext26_32x4d', pretrained, **model_args)\n@register_model\ndef legacy_seresnext50_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[3, 4, 6, 3], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext50_32x4d', pretrained, **model_args)\n@register_model",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnext50_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[3, 4, 6, 3], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext50_32x4d', pretrained, **model_args)\n@register_model\ndef legacy_seresnext101_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[3, 4, 23, 3], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext101_32x4d', pretrained, **model_args)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "legacy_seresnext101_32x4d",
        "kind": 2,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "def legacy_seresnext101_32x4d(pretrained=False, **kwargs):\n    model_args = dict(\n        block=SEResNeXtBottleneck, layers=[3, 4, 23, 3], groups=32, reduction=16, **kwargs)\n    return _create_senet('legacy_seresnext101_32x4d', pretrained, **model_args)",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "__all__ = ['SENet']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'layer0.conv1', 'classifier': 'last_linear',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.senet",
        "description": "timm.models.senet",
        "peekOfCode": "default_cfgs = {\n    'legacy_senet154':\n        _cfg(url='http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth'),\n    'legacy_seresnet18': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet18-4bb0ce65.pth',\n        interpolation='bicubic'),\n    'legacy_seresnet34': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet34-a4004e63.pth'),\n    'legacy_seresnet50': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet50-ce0d4300.pth'),",
        "detail": "timm.models.senet",
        "documentation": {}
    },
    {
        "label": "SelectiveKernelBasic",
        "kind": 6,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "class SelectiveKernelBasic(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, cardinality=1, base_width=64,\n                 sk_kwargs=None, reduce_first=1, dilation=1, first_dilation=None, act_layer=nn.ReLU,\n                 norm_layer=nn.BatchNorm2d, attn_layer=None, aa_layer=None, drop_block=None, drop_path=None):\n        super(SelectiveKernelBasic, self).__init__()\n        sk_kwargs = sk_kwargs or {}\n        conv_kwargs = dict(drop_block=drop_block, act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer)\n        assert cardinality == 1, 'BasicBlock only supports cardinality of 1'\n        assert base_width == 64, 'BasicBlock doest not support changing base width'",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "SelectiveKernelBottleneck",
        "kind": 6,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "class SelectiveKernelBottleneck(nn.Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 cardinality=1, base_width=64, sk_kwargs=None, reduce_first=1, dilation=1, first_dilation=None,\n                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, attn_layer=None, aa_layer=None,\n                 drop_block=None, drop_path=None):\n        super(SelectiveKernelBottleneck, self).__init__()\n        sk_kwargs = sk_kwargs or {}\n        conv_kwargs = dict(drop_block=drop_block, act_layer=act_layer, norm_layer=norm_layer, aa_layer=aa_layer)\n        width = int(math.floor(planes * (base_width / 64)) * cardinality)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "skresnet18",
        "kind": 2,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "def skresnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a Selective Kernel ResNet-18 model.\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"\n    sk_kwargs = dict(rd_ratio=1 / 8, rd_divisor=16, split_input=True)\n    model_args = dict(\n        block=SelectiveKernelBasic, layers=[2, 2, 2, 2], block_args=dict(sk_kwargs=sk_kwargs),\n        zero_init_last_bn=False, **kwargs)\n    return _create_skresnet('skresnet18', pretrained, **model_args)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "skresnet34",
        "kind": 2,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "def skresnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a Selective Kernel ResNet-34 model.\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"\n    sk_kwargs = dict(rd_ratio=1 / 8, rd_divisor=16, split_input=True)\n    model_args = dict(\n        block=SelectiveKernelBasic, layers=[3, 4, 6, 3], block_args=dict(sk_kwargs=sk_kwargs),\n        zero_init_last_bn=False, **kwargs)\n    return _create_skresnet('skresnet34', pretrained, **model_args)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "skresnet50",
        "kind": 2,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "def skresnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a Select Kernel ResNet-50 model.\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"\n    sk_kwargs = dict(split_input=True)\n    model_args = dict(\n        block=SelectiveKernelBottleneck, layers=[3, 4, 6, 3], block_args=dict(sk_kwargs=sk_kwargs),\n        zero_init_last_bn=False, **kwargs)\n    return _create_skresnet('skresnet50', pretrained, **model_args)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "skresnet50d",
        "kind": 2,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "def skresnet50d(pretrained=False, **kwargs):\n    \"\"\"Constructs a Select Kernel ResNet-50-D model.\n    Different from configs in Select Kernel paper or \"Compounding the Performance Improvements...\" this\n    variation splits the input channels to the selective convolutions to keep param count down.\n    \"\"\"\n    sk_kwargs = dict(split_input=True)\n    model_args = dict(\n        block=SelectiveKernelBottleneck, layers=[3, 4, 6, 3], stem_width=32, stem_type='deep', avg_down=True,\n        block_args=dict(sk_kwargs=sk_kwargs), zero_init_last_bn=False, **kwargs)\n    return _create_skresnet('skresnet50d', pretrained, **model_args)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "skresnext50_32x4d",
        "kind": 2,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "def skresnext50_32x4d(pretrained=False, **kwargs):\n    \"\"\"Constructs a Select Kernel ResNeXt50-32x4d model. This should be equivalent to\n    the SKNet-50 model in the Select Kernel Paper\n    \"\"\"\n    sk_kwargs = dict(rd_ratio=1/16, rd_divisor=32, split_input=False)\n    model_args = dict(\n        block=SelectiveKernelBottleneck, layers=[3, 4, 6, 3], cardinality=32, base_width=4,\n        block_args=dict(sk_kwargs=sk_kwargs), zero_init_last_bn=False, **kwargs)\n    return _create_skresnet('skresnext50_32x4d', pretrained, **model_args)",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.sknet",
        "description": "timm.models.sknet",
        "peekOfCode": "default_cfgs = {\n    'skresnet18': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet18_ra-4eec2804.pth'),\n    'skresnet34': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet34_ra-bdc0ccde.pth'),\n    'skresnet50': _cfg(),\n    'skresnet50d': _cfg(\n        first_conv='conv1.0'),\n    'skresnext50_32x4d': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnext50_ra-f40e40bf.pth'),",
        "detail": "timm.models.sknet",
        "documentation": {}
    },
    {
        "label": "WindowAttention",
        "kind": 6,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "class WindowAttention(nn.Module):\n    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n    It supports both of shifted and non-shifted window.\n    Args:\n        dim (int): Number of input channels.\n        window_size (tuple[int]): The height and width of the window.\n        num_heads (int): Number of attention heads.\n        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n        proj_drop (float, optional): Dropout ratio of output. Default: 0.0",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "SwinTransformerBlock",
        "kind": 6,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "class SwinTransformerBlock(nn.Module):\n    r\"\"\" Swin Transformer Block.\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resulotion.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "PatchMerging",
        "kind": 6,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "class PatchMerging(nn.Module):\n    r\"\"\" Patch Merging Layer.\n    Args:\n        input_resolution (tuple[int]): Resolution of input feature.\n        dim (int): Number of input channels.\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.input_resolution = input_resolution",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "BasicLayer",
        "kind": 6,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "class BasicLayer(nn.Module):\n    \"\"\" A basic Swin Transformer layer for one stage.\n    Args:\n        dim (int): Number of input channels.\n        input_resolution (tuple[int]): Input resolution.\n        depth (int): Number of blocks.\n        num_heads (int): Number of attention heads.\n        window_size (int): Local window size.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "SwinTransformer",
        "kind": 6,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "class SwinTransformer(nn.Module):\n    r\"\"\" Swin Transformer\n        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n          https://arxiv.org/pdf/2103.14030\n    Args:\n        img_size (int | tuple(int)): Input image size. Default 224\n        patch_size (int | tuple(int)): Patch size. Default: 4\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        embed_dim (int): Patch embedding dimension. Default: 96",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "window_partition",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def window_partition(x, window_size: int):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "window_reverse",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def window_reverse(windows, window_size: int, H: int, W: int):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_base_patch4_window12_384",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_base_patch4_window12_384(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 384x384, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=12, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n    return _create_swin_transformer('swin_base_patch4_window12_384', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_base_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_base_patch4_window7_224",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_base_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n    return _create_swin_transformer('swin_base_patch4_window7_224', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_large_patch4_window12_384(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 384x384, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_large_patch4_window12_384",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_large_patch4_window12_384(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 384x384, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=12, embed_dim=192, depths=(2, 2, 18, 2), num_heads=(6, 12, 24, 48), **kwargs)\n    return _create_swin_transformer('swin_large_patch4_window12_384', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_large_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_large_patch4_window7_224",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_large_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 224x224, pretrained ImageNet-22k, fine tune 1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=192, depths=(2, 2, 18, 2), num_heads=(6, 12, 24, 48), **kwargs)\n    return _create_swin_transformer('swin_large_patch4_window7_224', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_small_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-S @ 224x224, trained ImageNet-1k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_small_patch4_window7_224",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_small_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-S @ 224x224, trained ImageNet-1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=96, depths=(2, 2, 18, 2), num_heads=(3, 6, 12, 24), **kwargs)\n    return _create_swin_transformer('swin_small_patch4_window7_224', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_tiny_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-T @ 224x224, trained ImageNet-1k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_tiny_patch4_window7_224",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_tiny_patch4_window7_224(pretrained=False, **kwargs):\n    \"\"\" Swin-T @ 224x224, trained ImageNet-1k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=96, depths=(2, 2, 6, 2), num_heads=(3, 6, 12, 24), **kwargs)\n    return _create_swin_transformer('swin_tiny_patch4_window7_224', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_base_patch4_window12_384_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 384x384, trained ImageNet-22k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_base_patch4_window12_384_in22k",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_base_patch4_window12_384_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 384x384, trained ImageNet-22k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=12, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n    return _create_swin_transformer('swin_base_patch4_window12_384_in22k', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_base_patch4_window7_224_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 224x224, trained ImageNet-22k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_base_patch4_window7_224_in22k",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_base_patch4_window7_224_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-B @ 224x224, trained ImageNet-22k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n    return _create_swin_transformer('swin_base_patch4_window7_224_in22k', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_large_patch4_window12_384_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 384x384, trained ImageNet-22k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_large_patch4_window12_384_in22k",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_large_patch4_window12_384_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 384x384, trained ImageNet-22k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=12, embed_dim=192, depths=(2, 2, 18, 2), num_heads=(6, 12, 24, 48), **kwargs)\n    return _create_swin_transformer('swin_large_patch4_window12_384_in22k', pretrained=pretrained, **model_kwargs)\n@register_model\ndef swin_large_patch4_window7_224_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 224x224, trained ImageNet-22k\n    \"\"\"",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "swin_large_patch4_window7_224_in22k",
        "kind": 2,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "def swin_large_patch4_window7_224_in22k(pretrained=False, **kwargs):\n    \"\"\" Swin-L @ 224x224, trained ImageNet-22k\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=4, window_size=7, embed_dim=192, depths=(2, 2, 18, 2), num_heads=(6, 12, 24, 48), **kwargs)\n    return _create_swin_transformer('swin_large_patch4_window7_224_in22k', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n        'crop_pct': .9, 'interpolation': 'bicubic', 'fixed_input_size': True,\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n        **kwargs\n    }",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.swin_transformer",
        "description": "timm.models.swin_transformer",
        "peekOfCode": "default_cfgs = {\n    # patch models (my experiments)\n    'swin_base_patch4_window12_384': _cfg(\n        url='https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22kto1k.pth',\n        input_size=(3, 384, 384), crop_pct=1.0),\n    'swin_base_patch4_window7_224': _cfg(\n        url='https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth',\n    ),\n    'swin_large_patch4_window12_384': _cfg(\n        url='https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth',",
        "detail": "timm.models.swin_transformer",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "class Attention(nn.Module):\n    \"\"\" Multi-Head Attention\n    \"\"\"\n    def __init__(self, dim, hidden_dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.num_heads = num_heads\n        head_dim = hidden_dim // num_heads\n        self.head_dim = head_dim\n        self.scale = head_dim ** -0.5",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "class Block(nn.Module):\n    \"\"\" TNT Block\n    \"\"\"\n    def __init__(self, dim, in_dim, num_pixel, num_heads=12, in_num_head=4, mlp_ratio=4.,\n            qkv_bias=False, drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        # Inner transformer\n        self.norm_in = norm_layer(in_dim)\n        self.attn_in = Attention(\n            in_dim, in_dim, num_heads=in_num_head, qkv_bias=qkv_bias,",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "PixelEmbed",
        "kind": 6,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "class PixelEmbed(nn.Module):\n    \"\"\" Image to Pixel Embedding\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, in_dim=48, stride=4):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        # grid_size property necessary for resizing positional embedding\n        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n        num_patches = (self.grid_size[0]) * (self.grid_size[1])",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "TNT",
        "kind": 6,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "class TNT(nn.Module):\n    \"\"\" Transformer in Transformer - https://arxiv.org/abs/2103.00112\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, in_dim=48, depth=12,\n                 num_heads=12, in_num_head=4, mlp_ratio=4., qkv_bias=False, drop_rate=0., attn_drop_rate=0.,\n                 drop_path_rate=0., norm_layer=nn.LayerNorm, first_stride=4):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n        self.pixel_embed = PixelEmbed(",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n    if state_dict['patch_pos'].shape != model.patch_pos.shape:\n        state_dict['patch_pos'] = resize_pos_embed(state_dict['patch_pos'],\n            model.patch_pos, getattr(model, 'num_tokens', 1), model.pixel_embed.grid_size)\n    return state_dict\ndef _create_tnt(variant, pretrained=False, **kwargs):\n    if kwargs.get('features_only', None):\n        raise RuntimeError('features_only not implemented for Vision Transformer models.')\n    model = build_model_with_cfg(",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "tnt_s_patch16_224",
        "kind": 2,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "def tnt_s_patch16_224(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=16, embed_dim=384, in_dim=24, depth=12, num_heads=6, in_num_head=4,\n        qkv_bias=False, **kwargs)\n    model = _create_tnt('tnt_s_patch16_224', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef tnt_b_patch16_224(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=16, embed_dim=640, in_dim=40, depth=12, num_heads=10, in_num_head=4,",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "tnt_b_patch16_224",
        "kind": 2,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "def tnt_b_patch16_224(pretrained=False, **kwargs):\n    model_cfg = dict(\n        patch_size=16, embed_dim=640, in_dim=40, depth=12, num_heads=10, in_num_head=4,\n        qkv_bias=False, **kwargs)\n    model = _create_tnt('tnt_b_patch16_224', pretrained=pretrained, **model_cfg)\n    return model",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.tnt",
        "description": "timm.models.tnt",
        "peekOfCode": "default_cfgs = {\n    'tnt_s_patch16_224': _cfg(\n        url='https://github.com/contrastive/pytorch-image-models/releases/download/TNT/tnt_s_patch16_224.pth.tar',\n        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n    ),\n    'tnt_b_patch16_224': _cfg(\n        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n    ),\n}\nclass Attention(nn.Module):",
        "detail": "timm.models.tnt",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "class BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, use_se=True, aa_layer=None):\n        super(BasicBlock, self).__init__()\n        if stride == 1:\n            self.conv1 = conv2d_iabn(inplanes, planes, stride=1, act_param=1e-3)\n        else:\n            if aa_layer is None:\n                self.conv1 = conv2d_iabn(inplanes, planes, stride=2, act_param=1e-3)\n            else:",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "class Bottleneck(nn.Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None, use_se=True,\n                 act_layer=\"leaky_relu\", aa_layer=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = conv2d_iabn(\n            inplanes, planes, kernel_size=1, stride=1, act_layer=act_layer, act_param=1e-3)\n        if stride == 1:\n            self.conv2 = conv2d_iabn(\n                planes, planes, kernel_size=3, stride=1, act_layer=act_layer, act_param=1e-3)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "TResNet",
        "kind": 6,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "class TResNet(nn.Module):\n    def __init__(self, layers, in_chans=3, num_classes=1000, width_factor=1.0, global_pool='fast', drop_rate=0.):\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        super(TResNet, self).__init__()\n        aa_layer = BlurPool2d\n        # TResnet stages\n        self.inplanes = int(64 * width_factor)\n        self.planes = int(64 * width_factor)\n        conv1 = conv2d_iabn(in_chans * 16, self.planes, stride=1, kernel_size=3)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "IABN2Float",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def IABN2Float(module: nn.Module) -> nn.Module:\n    \"\"\"If `module` is IABN don't use half precision.\"\"\"\n    if isinstance(module, InplaceAbn):\n        module.float()\n    for child in module.children():\n        IABN2Float(child)\n    return module\ndef conv2d_iabn(ni, nf, stride, kernel_size=3, groups=1, act_layer=\"leaky_relu\", act_param=1e-2):\n    return nn.Sequential(\n        nn.Conv2d(",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "conv2d_iabn",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def conv2d_iabn(ni, nf, stride, kernel_size=3, groups=1, act_layer=\"leaky_relu\", act_param=1e-2):\n    return nn.Sequential(\n        nn.Conv2d(\n            ni, nf, kernel_size=kernel_size, stride=stride, padding=kernel_size // 2, groups=groups, bias=False),\n        InplaceAbn(nf, act_layer=act_layer, act_param=act_param)\n    )\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None, use_se=True, aa_layer=None):\n        super(BasicBlock, self).__init__()",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_m",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_m(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)\n    return _create_tresnet('tresnet_m', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_m_miil_in21k(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)\n    return _create_tresnet('tresnet_m_miil_in21k', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_l(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_m_miil_in21k",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_m_miil_in21k(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)\n    return _create_tresnet('tresnet_m_miil_in21k', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_l(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)\n    return _create_tresnet('tresnet_l', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_xl(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_l",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_l(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)\n    return _create_tresnet('tresnet_l', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_xl(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)\n    return _create_tresnet('tresnet_xl', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_m_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_xl",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_xl(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)\n    return _create_tresnet('tresnet_xl', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_m_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)\n    return _create_tresnet('tresnet_m_448', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_l_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_m_448",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_m_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[3, 4, 11, 3], **kwargs)\n    return _create_tresnet('tresnet_m_448', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_l_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)\n    return _create_tresnet('tresnet_l_448', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_xl_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_l_448",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_l_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 18, 3], width_factor=1.2, **kwargs)\n    return _create_tresnet('tresnet_l_448', pretrained=pretrained, **model_kwargs)\n@register_model\ndef tresnet_xl_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)\n    return _create_tresnet('tresnet_xl_448', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "tresnet_xl_448",
        "kind": 2,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "def tresnet_xl_448(pretrained=False, **kwargs):\n    model_kwargs = dict(layers=[4, 5, 24, 3], width_factor=1.3, **kwargs)\n    return _create_tresnet('tresnet_xl_448', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "__all__ = ['tresnet_m', 'tresnet_l', 'tresnet_xl']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': (0, 0, 0), 'std': (1, 1, 1),\n        'first_conv': 'body.conv1.0', 'classifier': 'head.fc',\n        **kwargs\n    }\ndefault_cfgs = {",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.tresnet",
        "description": "timm.models.tresnet",
        "peekOfCode": "default_cfgs = {\n    'tresnet_m': _cfg(\n        url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/model-zoo/ImageNet_21K_P/models/timm/tresnet_m_1k_miil_83_1.pth'),\n    'tresnet_m_miil_in21k': _cfg(\n        url='https://miil-public-eu.oss-eu-central-1.aliyuncs.com/model-zoo/ImageNet_21K_P/models/timm/tresnet_m_miil_in21k.pth', num_classes=11221),\n    'tresnet_l': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_81_5-235b486c.pth'),\n    'tresnet_xl': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_82_0-a2d51b00.pth'),\n    'tresnet_m_448': _cfg(",
        "detail": "timm.models.tresnet",
        "documentation": {}
    },
    {
        "label": "LocallyGroupedAttn",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class LocallyGroupedAttn(nn.Module):\n    \"\"\" LSA: self attention within a group\n    \"\"\"\n    def __init__(self, dim, num_heads=8, attn_drop=0., proj_drop=0., ws=1):\n        assert ws != 1\n        super(LocallyGroupedAttn, self).__init__()\n        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n        self.dim = dim\n        self.num_heads = num_heads\n        head_dim = dim // num_heads",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "GlobalSubSampleAttn",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class GlobalSubSampleAttn(nn.Module):\n    \"\"\" GSA: using a  key to summarize the information for a group to be efficient.\n    \"\"\"\n    def __init__(self, dim, num_heads=8, attn_drop=0., proj_drop=0., sr_ratio=1):\n        super().__init__()\n        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n        self.dim = dim\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, sr_ratio=1, ws=None):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        if ws is None:\n            self.attn = Attention(dim, num_heads, False, None, attn_drop, drop)\n        elif ws == 1:\n            self.attn = GlobalSubSampleAttn(dim, num_heads, attn_drop, drop, sr_ratio)\n        else:",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "PosConv",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class PosConv(nn.Module):\n    # PEG  from https://arxiv.org/abs/2102.10882\n    def __init__(self, in_chans, embed_dim=768, stride=1):\n        super(PosConv, self).__init__()\n        self.proj = nn.Sequential(nn.Conv2d(in_chans, embed_dim, 3, stride, 1, bias=True, groups=embed_dim), )\n        self.stride = stride\n    def forward(self, x, size: Size_):\n        B, N, C = x.shape\n        cnn_feat_token = x.transpose(1, 2).view(B, C, *size)\n        x = self.proj(cnn_feat_token)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "PatchEmbed",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class PatchEmbed(nn.Module):\n    \"\"\" Image to Patch Embedding\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        self.img_size = img_size\n        self.patch_size = patch_size\n        assert img_size[0] % patch_size[0] == 0 and img_size[1] % patch_size[1] == 0, \\",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "Twins",
        "kind": 6,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "class Twins(nn.Module):\n    \"\"\" Twins Vision Transfomer (Revisiting Spatial Attention)\n    Adapted from PVT (PyramidVisionTransformer) class at https://github.com/whai362/PVT.git\n    \"\"\"\n    def __init__(\n            self, img_size=224, patch_size=4, in_chans=3, num_classes=1000, embed_dims=(64, 128, 256, 512),\n            num_heads=(1, 2, 4, 8), mlp_ratios=(4, 4, 4, 4), drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n            norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=(3, 4, 6, 3), sr_ratios=(8, 4, 2, 1), wss=None,\n            block_cls=Block):\n        super().__init__()",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_pcpvt_small",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_pcpvt_small(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4],\n        depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_pcpvt_small', pretrained=pretrained, **model_kwargs)\n@register_model\ndef twins_pcpvt_base(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4],\n        depths=[3, 4, 18, 3], sr_ratios=[8, 4, 2, 1], **kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_pcpvt_base",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_pcpvt_base(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4],\n        depths=[3, 4, 18, 3], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_pcpvt_base', pretrained=pretrained, **model_kwargs)\n@register_model\ndef twins_pcpvt_large(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4],\n        depths=[3, 8, 27, 3], sr_ratios=[8, 4, 2, 1], **kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_pcpvt_large",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_pcpvt_large(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4],\n        depths=[3, 8, 27, 3], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_pcpvt_large', pretrained=pretrained, **model_kwargs)\n@register_model\ndef twins_svt_small(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 256, 512], num_heads=[2, 4, 8, 16], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 10, 4], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_svt_small",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_svt_small(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[64, 128, 256, 512], num_heads=[2, 4, 8, 16], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 10, 4], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_svt_small', pretrained=pretrained, **model_kwargs)\n@register_model\ndef twins_svt_base(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[96, 192, 384, 768], num_heads=[3, 6, 12, 24], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 18, 2], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_svt_base",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_svt_base(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[96, 192, 384, 768], num_heads=[3, 6, 12, 24], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 18, 2], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_svt_base', pretrained=pretrained, **model_kwargs)\n@register_model\ndef twins_svt_large(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[128, 256, 512, 1024], num_heads=[4, 8, 16, 32], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 18, 2], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "twins_svt_large",
        "kind": 2,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "def twins_svt_large(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=4, embed_dims=[128, 256, 512, 1024], num_heads=[4, 8, 16, 32], mlp_ratios=[4, 4, 4, 4],\n        depths=[2, 2, 18, 2], wss=[7, 7, 7, 7], sr_ratios=[8, 4, 2, 1], **kwargs)\n    return _create_twins('twins_svt_large', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "default_cfgs = {\n    'twins_pcpvt_small': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_small-e70e7e7a.pth',\n        ),\n    'twins_pcpvt_base': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_base-e5ecb09b.pth',\n        ),\n    'twins_pcpvt_large': _cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_large-d273f802.pth',\n        ),",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "Size_",
        "kind": 5,
        "importPath": "timm.models.twins",
        "description": "timm.models.twins",
        "peekOfCode": "Size_ = Tuple[int, int]\n@register_notrace_module  # reason: FX can't symbolically trace control flow in forward method\nclass LocallyGroupedAttn(nn.Module):\n    \"\"\" LSA: self attention within a group\n    \"\"\"\n    def __init__(self, dim, num_heads=8, attn_drop=0., proj_drop=0., ws=1):\n        assert ws != 1\n        super(LocallyGroupedAttn, self).__init__()\n        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n        self.dim = dim",
        "detail": "timm.models.twins",
        "documentation": {}
    },
    {
        "label": "ConvMlp",
        "kind": 6,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "class ConvMlp(nn.Module):\n    def __init__(self, in_features=512, out_features=4096, kernel_size=7, mlp_ratio=1.0,\n                 drop_rate: float = 0.2, act_layer: nn.Module = None, conv_layer: nn.Module = None):\n        super(ConvMlp, self).__init__()\n        self.input_kernel_size = kernel_size\n        mid_features = int(out_features * mlp_ratio)\n        self.fc1 = conv_layer(in_features, mid_features, kernel_size, bias=True)\n        self.act1 = act_layer(True)\n        self.drop = nn.Dropout(drop_rate)\n        self.fc2 = conv_layer(mid_features, out_features, 1, bias=True)",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "VGG",
        "kind": 6,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "class VGG(nn.Module):\n    def __init__(\n        self,\n        cfg: List[Any],\n        num_classes: int = 1000,\n        in_chans: int = 3,\n        output_stride: int = 32,\n        mlp_ratio: float = 1.0,\n        act_layer: nn.Module = nn.ReLU,\n        conv_layer: nn.Module = nn.Conv2d,",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg11",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg11(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 11-layer model (configuration \"A\") from\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(**kwargs)\n    return _create_vgg('vgg11', pretrained=pretrained, **model_args)\n@register_model\ndef vgg11_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg11_bn",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg11_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)\n    return _create_vgg('vgg11_bn', pretrained=pretrained, **model_args)\n@register_model\ndef vgg13(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 13-layer model (configuration \"B\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg13",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg13(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 13-layer model (configuration \"B\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(**kwargs)\n    return _create_vgg('vgg13', pretrained=pretrained, **model_args)\n@register_model\ndef vgg13_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg13_bn",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg13_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)\n    return _create_vgg('vgg13_bn', pretrained=pretrained, **model_args)\n@register_model\ndef vgg16(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 16-layer model (configuration \"D\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg16",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg16(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 16-layer model (configuration \"D\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(**kwargs)\n    return _create_vgg('vgg16', pretrained=pretrained, **model_args)\n@register_model\ndef vgg16_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg16_bn",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg16_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)\n    return _create_vgg('vgg16_bn', pretrained=pretrained, **model_args)\n@register_model\ndef vgg19(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 19-layer model (configuration \"E\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg19",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg19(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 19-layer model (configuration \"E\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(**kwargs)\n    return _create_vgg('vgg19', pretrained=pretrained, **model_args)\n@register_model\ndef vgg19_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "vgg19_bn",
        "kind": 2,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "def vgg19_bn(pretrained: bool = False, **kwargs: Any) -> VGG:\n    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    \"\"\"\n    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)\n    return _create_vgg('vgg19_bn', pretrained=pretrained, **model_args)",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "__all__ = [\n    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n    'vgg19_bn', 'vgg19',\n]\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (1, 1),\n        'crop_pct': 0.875, 'interpolation': 'bilinear',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.vgg",
        "description": "timm.models.vgg",
        "peekOfCode": "default_cfgs = {\n    'vgg11': _cfg(url='https://download.pytorch.org/models/vgg11-bbd30ac9.pth'),\n    'vgg13': _cfg(url='https://download.pytorch.org/models/vgg13-c768596a.pth'),\n    'vgg16': _cfg(url='https://download.pytorch.org/models/vgg16-397923af.pth'),\n    'vgg19': _cfg(url='https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'),\n    'vgg11_bn': _cfg(url='https://download.pytorch.org/models/vgg11_bn-6002323d.pth'),\n    'vgg13_bn': _cfg(url='https://download.pytorch.org/models/vgg13_bn-abd245e5.pth'),\n    'vgg16_bn': _cfg(url='https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'),\n    'vgg19_bn': _cfg(url='https://download.pytorch.org/models/vgg19_bn-c79401a0.pth'),\n}",
        "detail": "timm.models.vgg",
        "documentation": {}
    },
    {
        "label": "SpatialMlp",
        "kind": 6,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "class SpatialMlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None,\n                 act_layer=nn.GELU, drop=0., group=8, spatial_conv=False):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        drop_probs = to_2tuple(drop)\n        self.in_features = in_features\n        self.out_features = out_features\n        self.spatial_conv = spatial_conv",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "class Attention(nn.Module):\n    def __init__(self, dim, num_heads=8, head_dim_ratio=1., attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        head_dim = round(dim // num_heads * head_dim_ratio)\n        self.head_dim = head_dim\n        self.scale = head_dim ** -0.5\n        self.qkv = nn.Conv2d(dim, head_dim * num_heads * 3, 1, stride=1, padding=0, bias=False)\n        self.attn_drop = nn.Dropout(attn_drop)",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, dim, num_heads, head_dim_ratio=1., mlp_ratio=4.,\n                 drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=LayerNorm2d,\n                 group=8, attn_disabled=False, spatial_conv=False):\n        super().__init__()\n        self.spatial_conv = spatial_conv\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        if attn_disabled:\n            self.norm1 = None\n            self.attn = None",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "Visformer",
        "kind": 6,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "class Visformer(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, init_channels=32, embed_dim=384,\n                 depth=12, num_heads=6, mlp_ratio=4., drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n                 norm_layer=LayerNorm2d, attn_stage='111', pos_embed=True, spatial_conv='111',\n                 vit_stem=False, group=8, global_pool='avg', conv_init=False, embed_norm=None):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.init_channels = init_channels",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "visformer_tiny",
        "kind": 2,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "def visformer_tiny(pretrained=False, **kwargs):\n    model_cfg = dict(\n        init_channels=16, embed_dim=192, depth=(7, 4, 4), num_heads=3, mlp_ratio=4., group=8,\n        attn_stage='011', spatial_conv='100', norm_layer=nn.BatchNorm2d, conv_init=True,\n        embed_norm=nn.BatchNorm2d, **kwargs)\n    model = _create_visformer('visformer_tiny', pretrained=pretrained, **model_cfg)\n    return model\n@register_model\ndef visformer_small(pretrained=False, **kwargs):\n    model_cfg = dict(",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "visformer_small",
        "kind": 2,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "def visformer_small(pretrained=False, **kwargs):\n    model_cfg = dict(\n        init_channels=32, embed_dim=384, depth=(7, 4, 4), num_heads=6, mlp_ratio=4., group=8,\n        attn_stage='011', spatial_conv='100', norm_layer=nn.BatchNorm2d, conv_init=True,\n        embed_norm=nn.BatchNorm2d, **kwargs)\n    model = _create_visformer('visformer_small', pretrained=pretrained, **model_cfg)\n    return model\n# @register_model\n# def visformer_net1(pretrained=False, **kwargs):\n#     model = Visformer(",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "__all__ = ['Visformer']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': .9, 'interpolation': 'bicubic', 'fixed_input_size': True,\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.0', 'classifier': 'head',\n        **kwargs\n    }",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.visformer",
        "description": "timm.models.visformer",
        "peekOfCode": "default_cfgs = dict(\n    visformer_tiny=_cfg(),\n    visformer_small=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/visformer_small-839e1f5b.pth'\n    ),\n)\nclass SpatialMlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None,\n                 act_layer=nn.GELU, drop=0., group=8, spatial_conv=False):\n        super().__init__()",
        "detail": "timm.models.visformer",
        "documentation": {}
    },
    {
        "label": "RandomMaskingGenerator",
        "kind": 6,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "class RandomMaskingGenerator:\n    def __init__(self, input_size, mask_ratio):\n        if not isinstance(input_size, tuple):\n            input_size = (input_size,) * 2\n        self.height, self.width = input_size\n        self.num_patches = self.height * self.width  # patch的总数即196\n        self.num_mask = int(mask_ratio * self.num_patches)  # 196 * 0.75\n    def __repr__(self):\n        repr_str = \"Maks: total patches {}, mask patches {}\".format(\n            self.num_patches, self.num_mask",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "class Attention(nn.Module):\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        assert dim % num_heads == 0, 'dim should be divisible by num_heads'\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "VisionTransformer",
        "kind": 6,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "class VisionTransformer(nn.Module):\n    \"\"\" Vision Transformer\n    A PyTorch impl of : `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale`\n        - https://arxiv.org/abs/2010.11929\n    Includes distillation token & head support for `DeiT: Data-efficient Image Transformers`\n        - https://arxiv.org/abs/2012.12877\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n                 num_heads=12, mlp_ratio=4., qkv_bias=True, representation_size=None, distilled=False,\n                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0., embed_layer=PatchEmbed, norm_layer=None,",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "resize_pos_embed",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def resize_pos_embed(posemb, posemb_new, num_tokens=1, gs_new=()):\n    # Rescale the grid of position embeddings when loading from state_dict. Adapted from\n    # https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224\n    _logger.info('Resized position embedding: %s to %s', posemb.shape, posemb_new.shape)\n    ntok_new = posemb_new.shape[1]\n    if num_tokens:\n        posemb_tok, posemb_grid = posemb[:, :num_tokens], posemb[0, num_tokens:]\n        ntok_new -= num_tokens\n    else:\n        posemb_tok, posemb_grid = posemb[:, :0], posemb[0]",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n    out_dict = {}\n    if 'model' in state_dict:\n        # For deit models\n        state_dict = state_dict['model']\n    for k, v in state_dict.items():\n        if 'patch_embed.proj.weight' in k and len(v.shape) < 4:\n            # For old models that I trained prior to conv based patchification\n            O, I, H, W = model.patch_embed.proj.weight.shape",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_tiny_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_tiny_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Tiny (Vit-Ti/16)\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer('vit_tiny_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_tiny_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Tiny (Vit-Ti/16) @ 384x384.\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_tiny_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_tiny_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Tiny (Vit-Ti/16) @ 384x384.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer('vit_tiny_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/32)\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/32)\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch32_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/32) at 384x384.\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch32_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/32) at 384x384.\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch32_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)\n    NOTE I've replaced my previous 'small' model definition and weights with the small variant from the DeiT paper",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)\n    NOTE I've replaced my previous 'small' model definition and weights with the small variant from the DeiT paper\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)\n    NOTE I've replaced my previous 'small' model definition and weights with the small variant from the DeiT paper\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch32_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base2_patch32_256(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32)",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base2_patch32_256",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base2_patch32_256(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32)\n    # FIXME experiment\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=896, depth=12, num_heads=14, **kwargs)\n    model = _create_vision_transformer('vit_base2_patch32_256', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch32_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch32_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch8_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/8) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch8_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch8_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/8) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=8, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_large_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929). No pretrained weights.",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch32_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929). No pretrained weights.\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_large_patch32_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_large_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch32_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch32_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_large_patch32_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_large_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch16_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_large_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_large_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch16_384(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_large_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_huge_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_huge_patch14_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_huge_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).\n    \"\"\"\n    model_kwargs = dict(patch_size=14, embed_dim=1280, depth=32, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_huge_patch14_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_giant_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Giant model (ViT-g/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_giant_patch14_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_giant_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Giant model (ViT-g/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"\n    model_kwargs = dict(patch_size=14, embed_dim=1408, mlp_ratio=48/11, depth=40, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_giant_patch14_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_gigantic_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Gigantic model (ViT-G/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_gigantic_patch14_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_gigantic_patch14_224(pretrained=False, **kwargs):\n    \"\"\" ViT-Gigantic model (ViT-G/14) from `Scaling Vision Transformers` - https://arxiv.org/abs/2106.04560\n    \"\"\"\n    model_kwargs = dict(patch_size=14, embed_dim=1664, mlp_ratio=64/13, depth=48, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_gigantic_patch14_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_tiny_patch16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Tiny (Vit-Ti/16).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_tiny_patch16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_tiny_patch16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Tiny (Vit-Ti/16).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer('vit_tiny_patch16_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch32_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch32_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(patch_size=32, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch32_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch16_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16)\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch16_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch32_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch32_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=32, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch32_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch8_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch8_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Base model (ViT-B/8) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch8_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch32_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/32) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has a representation layer but the 21k classifier head is zero'd out in original weights\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=32, embed_dim=1024, depth=24, num_heads=16, representation_size=1024, **kwargs)\n    model = _create_vision_transformer('vit_large_patch32_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_large_patch16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_large_patch16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Large model (ViT-L/16) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has valid 21k classifier head and no representation (pre-logits) layer\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=16, embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer('vit_large_patch16_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_huge_patch14_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_huge_patch14_224_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Huge model (ViT-H/14) from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    NOTE: this model has a representation layer but the 21k classifier head is zero'd out in original weights\n    \"\"\"\n    model_kwargs = dict(\n        patch_size=14, embed_dim=1280, depth=32, num_heads=16, representation_size=1280, **kwargs)\n    model = _create_vision_transformer('vit_huge_patch14_224_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224_sam",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224_sam(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) w/ SAM pretrained weights. Paper: https://arxiv.org/abs/2106.01548\n    \"\"\"\n    # NOTE original SAM weights release worked with representation_size=768\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224_sam', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch32_224_sam(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32) w/ SAM pretrained weights. Paper: https://arxiv.org/abs/2106.01548",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch32_224_sam",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch32_224_sam(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/32) w/ SAM pretrained weights. Paper: https://arxiv.org/abs/2106.01548\n    \"\"\"\n    # NOTE original SAM weights release worked with representation_size=768\n    model_kwargs = dict(patch_size=32, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch32_224_sam', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch16_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch16_224_dino",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch16_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/16) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch16_224_dino', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_patch8_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_small_patch8_224_dino",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_small_patch8_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Small (ViT-S/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_kwargs = dict(patch_size=8, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('vit_small_patch8_224_dino', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch16_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) /w DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224_dino",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) /w DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224_dino', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch8_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch8_224_dino",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch8_224_dino(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/8) w/ DINO pretrained weights (no head) - https://arxiv.org/abs/2104.14294\n    \"\"\"\n    model_kwargs = dict(patch_size=8, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('vit_base_patch8_224_dino', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef deit_tiny_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-tiny model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_tiny_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_tiny_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-tiny model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer('deit_tiny_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef deit_small_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-small model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_small_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_small_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-small model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer('deit_small_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef deit_base_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT base model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_base_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_base_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT base model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('deit_base_patch16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef deit_base_patch16_384(pretrained=False, **kwargs):\n    \"\"\" DeiT base model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_base_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_base_patch16_384(pretrained=False, **kwargs):\n    \"\"\" DeiT base model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer('deit_base_patch16_384', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-tiny distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_tiny_distilled_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-tiny distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer(\n        'deit_tiny_distilled_patch16_224', pretrained=pretrained,  distilled=True, **model_kwargs)\n    return model\n@register_model\ndef deit_small_distilled_patch16_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_small_distilled_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-small distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer(\n        'deit_small_distilled_patch16_224', pretrained=pretrained,  distilled=True, **model_kwargs)\n    return model\n@register_model\ndef deit_base_distilled_patch16_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_base_distilled_patch16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n    \"\"\" DeiT-base distilled model @ 224x224 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer(\n        'deit_base_distilled_patch16_224', pretrained=pretrained,  distilled=True, **model_kwargs)\n    return model\n@register_model\ndef deit_base_distilled_patch16_384(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "deit_base_distilled_patch16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n    \"\"\" DeiT-base distilled model @ 384x384 from paper (https://arxiv.org/abs/2012.12877).\n    ImageNet-1k weights from https://github.com/facebookresearch/deit.\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer(\n        'deit_base_distilled_patch16_384', pretrained=pretrained, distilled=True, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch16_224_miil_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224_miil_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224_miil_in21k(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, qkv_bias=False, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224_miil_in21k', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_patch16_224_miil(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "vit_base_patch16_224_miil",
        "kind": 2,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "def vit_base_patch16_224_miil(pretrained=False, **kwargs):\n    \"\"\" ViT-Base (ViT-B/16) from original paper (https://arxiv.org/abs/2010.11929).\n    Weights taken from: https://github.com/Alibaba-MIIL/ImageNet21K\n    \"\"\"\n    model_kwargs = dict(patch_size=16, embed_dim=768, depth=12, num_heads=12, qkv_bias=False, **kwargs)\n    model = _create_vision_transformer('vit_base_patch16_224_miil', pretrained=pretrained, **model_kwargs)\n    return model",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "_logger = logging.getLogger(__name__)\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n        'crop_pct': .9, 'interpolation': 'bicubic', 'fixed_input_size': True,\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n        **kwargs\n    }",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.vision_transformer",
        "description": "timm.models.vision_transformer",
        "peekOfCode": "default_cfgs = {\n    # patch models (weights from official Google JAX impl)\n    'vit_tiny_patch16_224': _cfg(\n        url='https://storage.googleapis.com/vit_models/augreg/'\n            'Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz'),\n    'vit_tiny_patch16_384': _cfg(\n        url='https://storage.googleapis.com/vit_models/augreg/'\n            'Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz',\n        input_size=(3, 384, 384), crop_pct=1.0),\n    'vit_small_patch32_224': _cfg(",
        "detail": "timm.models.vision_transformer",
        "documentation": {}
    },
    {
        "label": "HybridEmbed",
        "kind": 6,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "class HybridEmbed(nn.Module):\n    \"\"\" CNN Feature Map Embedding\n    Extract feature map from CNN, flatten, project to embedding dim.\n    \"\"\"\n    def __init__(self, backbone, img_size=224, patch_size=1, feature_size=None, in_chans=3, embed_dim=768):\n        super().__init__()\n        assert isinstance(backbone, nn.Module)\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        self.img_size = img_size",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_tiny_r_s16_p8_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_tiny_r_s16_p8_224(pretrained=False, **kwargs):\n    \"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid @ 224 x 224.\n    \"\"\"\n    backbone = _resnetv2(layers=(), **kwargs)\n    model_kwargs = dict(patch_size=8, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_tiny_r_s16_p8_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_tiny_r_s16_p8_384(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_tiny_r_s16_p8_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_tiny_r_s16_p8_384(pretrained=False, **kwargs):\n    \"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid @ 384 x 384.\n    \"\"\"\n    backbone = _resnetv2(layers=(), **kwargs)\n    model_kwargs = dict(patch_size=8, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_tiny_r_s16_p8_384', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_r26_s32_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_small_r26_s32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_small_r26_s32_224(pretrained=False, **kwargs):\n    \"\"\" R26+ViT-S/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((2, 2, 2, 2), **kwargs)\n    model_kwargs = dict(embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_small_r26_s32_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_r26_s32_384(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_small_r26_s32_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_small_r26_s32_384(pretrained=False, **kwargs):\n    \"\"\" R26+ViT-S/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((2, 2, 2, 2), **kwargs)\n    model_kwargs = dict(embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_small_r26_s32_384', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_r26_s32_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_r26_s32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_r26_s32_224(pretrained=False, **kwargs):\n    \"\"\" R26+ViT-B/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((2, 2, 2, 2), **kwargs)\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_r26_s32_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_r50_s16_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_r50_s16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_r50_s16_224(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-B/S16 hybrid from original paper (https://arxiv.org/abs/2010.11929).\n    \"\"\"\n    backbone = _resnetv2((3, 4, 9), **kwargs)\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_r50_s16_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_r50_s16_384(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_r50_s16_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_r50_s16_384(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-B/16 hybrid from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-1k weights fine-tuned from in21k @ 384x384, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 9), **kwargs)\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_r50_s16_384', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_resnet50_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_resnet50_384(pretrained=False, **kwargs):\n    # DEPRECATED this is forwarding to model def above for backwards compatibility\n    return vit_base_r50_s16_384(pretrained=pretrained, **kwargs)\n@register_model\ndef vit_large_r50_s32_224(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-L/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 6, 3), **kwargs)\n    model_kwargs = dict(embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer_hybrid(",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_large_r50_s32_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_large_r50_s32_224(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-L/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 6, 3), **kwargs)\n    model_kwargs = dict(embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_large_r50_s32_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_large_r50_s32_384(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_large_r50_s32_384",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_large_r50_s32_384(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-L/S32 hybrid.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 6, 3), **kwargs)\n    model_kwargs = dict(embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_large_r50_s32_384', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_tiny_r_s16_p8_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_tiny_r_s16_p8_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_tiny_r_s16_p8_224_in21k(pretrained=False, **kwargs):\n    \"\"\" R+ViT-Ti/S16 w/ 8x8 patch hybrid.  ImageNet-21k.\n    \"\"\"\n    backbone = _resnetv2(layers=(), **kwargs)\n    model_kwargs = dict(patch_size=8, embed_dim=192, depth=12, num_heads=3, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_tiny_r_s16_p8_224_in21k', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_r26_s32_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_small_r26_s32_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_small_r26_s32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" R26+ViT-S/S32 hybrid. ImageNet-21k.\n    \"\"\"\n    backbone = _resnetv2((2, 2, 2, 2), **kwargs)\n    model_kwargs = dict(embed_dim=384, depth=12, num_heads=6, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_small_r26_s32_224_in21k', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_r50_s16_224_in21k(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_r50_s16_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_r50_s16_224_in21k(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-B/16 hybrid model from original paper (https://arxiv.org/abs/2010.11929).\n    ImageNet-21k weights @ 224x224, source https://github.com/google-research/vision_transformer.\n    \"\"\"\n    backbone = _resnetv2(layers=(3, 4, 9), **kwargs)\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, representation_size=768, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_r50_s16_224_in21k', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_resnet50_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_resnet50_224_in21k(pretrained=False, **kwargs):\n    # DEPRECATED this is forwarding to model def above for backwards compatibility\n    return vit_base_r50_s16_224_in21k(pretrained=pretrained, **kwargs)\n@register_model\ndef vit_large_r50_s32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-L/S32 hybrid. ImageNet-21k.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 6, 3), **kwargs)\n    model_kwargs = dict(embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer_hybrid(",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_large_r50_s32_224_in21k",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_large_r50_s32_224_in21k(pretrained=False, **kwargs):\n    \"\"\" R50+ViT-L/S32 hybrid. ImageNet-21k.\n    \"\"\"\n    backbone = _resnetv2((3, 4, 6, 3), **kwargs)\n    model_kwargs = dict(embed_dim=1024, depth=24, num_heads=16, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_large_r50_s32_224_in21k', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_resnet26d_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_small_resnet26d_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_small_resnet26d_224(pretrained=False, **kwargs):\n    \"\"\" Custom ViT small hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"\n    backbone = resnet26d(pretrained=pretrained, in_chans=kwargs.get('in_chans', 3), features_only=True, out_indices=[4])\n    model_kwargs = dict(embed_dim=768, depth=8, num_heads=8, mlp_ratio=3, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_small_resnet26d_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_small_resnet50d_s16_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_small_resnet50d_s16_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_small_resnet50d_s16_224(pretrained=False, **kwargs):\n    \"\"\" Custom ViT small hybrid w/ ResNet50D 3-stages, stride 16. No pretrained weights.\n    \"\"\"\n    backbone = resnet50d(pretrained=pretrained, in_chans=kwargs.get('in_chans', 3), features_only=True, out_indices=[3])\n    model_kwargs = dict(embed_dim=768, depth=8, num_heads=8, mlp_ratio=3, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_small_resnet50d_s16_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_resnet26d_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_resnet26d_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_resnet26d_224(pretrained=False, **kwargs):\n    \"\"\" Custom ViT base hybrid w/ ResNet26D stride 32. No pretrained weights.\n    \"\"\"\n    backbone = resnet26d(pretrained=pretrained, in_chans=kwargs.get('in_chans', 3), features_only=True, out_indices=[4])\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_resnet26d_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef vit_base_resnet50d_224(pretrained=False, **kwargs):",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "vit_base_resnet50d_224",
        "kind": 2,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "def vit_base_resnet50d_224(pretrained=False, **kwargs):\n    \"\"\" Custom ViT base hybrid w/ ResNet50D stride 32. No pretrained weights.\n    \"\"\"\n    backbone = resnet50d(pretrained=pretrained, in_chans=kwargs.get('in_chans', 3), features_only=True, out_indices=[4])\n    model_kwargs = dict(embed_dim=768, depth=12, num_heads=12, **kwargs)\n    model = _create_vision_transformer_hybrid(\n        'vit_base_resnet50d_224', backbone=backbone, pretrained=pretrained, **model_kwargs)\n    return model",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.vision_transformer_hybrid",
        "description": "timm.models.vision_transformer_hybrid",
        "peekOfCode": "default_cfgs = {\n    # hybrid in-1k models (weights from official JAX impl where they exist)\n    'vit_tiny_r_s16_p8_224': _cfg(\n        url='https://storage.googleapis.com/vit_models/augreg/'\n            'R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_224.npz',\n        first_conv='patch_embed.backbone.conv'),\n    'vit_tiny_r_s16_p8_384': _cfg(\n        url='https://storage.googleapis.com/vit_models/augreg/'\n            'R_Ti_16-i21k-300ep-lr_0.001-aug_none-wd_0.03-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.03-res_384.npz',\n        first_conv='patch_embed.backbone.conv', input_size=(3, 384, 384), crop_pct=1.0),",
        "detail": "timm.models.vision_transformer_hybrid",
        "documentation": {}
    },
    {
        "label": "SequentialAppendList",
        "kind": 6,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "class SequentialAppendList(nn.Sequential):\n    def __init__(self, *args):\n        super(SequentialAppendList, self).__init__(*args)\n    def forward(self, x: torch.Tensor, concat_list: List[torch.Tensor]) -> torch.Tensor:\n        for i, module in enumerate(self):\n            if i == 0:\n                concat_list.append(module(x))\n            else:\n                concat_list.append(module(concat_list[-1]))\n        x = torch.cat(concat_list, dim=1)",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "OsaBlock",
        "kind": 6,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "class OsaBlock(nn.Module):\n    def __init__(self, in_chs, mid_chs, out_chs, layer_per_block, residual=False,\n                 depthwise=False, attn='', norm_layer=BatchNormAct2d, act_layer=nn.ReLU, drop_path=None):\n        super(OsaBlock, self).__init__()\n        self.residual = residual\n        self.depthwise = depthwise\n        conv_kwargs = dict(norm_layer=norm_layer, act_layer=act_layer)\n        next_in_chs = in_chs\n        if self.depthwise and next_in_chs != mid_chs:\n            assert not residual",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "OsaStage",
        "kind": 6,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "class OsaStage(nn.Module):\n    def __init__(self, in_chs, mid_chs, out_chs, block_per_stage, layer_per_block, downsample=True,\n                 residual=True, depthwise=False, attn='ese', norm_layer=BatchNormAct2d, act_layer=nn.ReLU,\n                 drop_path_rates=None):\n        super(OsaStage, self).__init__()\n        if downsample:\n            self.pool = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n        else:\n            self.pool = None\n        blocks = []",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "VovNet",
        "kind": 6,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "class VovNet(nn.Module):\n    def __init__(self, cfg, in_chans=3, num_classes=1000, global_pool='avg', drop_rate=0., stem_stride=4,\n                 output_stride=32, norm_layer=BatchNormAct2d, act_layer=nn.ReLU, drop_path_rate=0.):\n        \"\"\" VovNet (v2)\n        \"\"\"\n        super(VovNet, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        assert stem_stride in (4, 2)\n        assert output_stride == 32  # FIXME support dilation",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "vovnet39a",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def vovnet39a(pretrained=False, **kwargs):\n    return _create_vovnet('vovnet39a', pretrained=pretrained, **kwargs)\n@register_model\ndef vovnet57a(pretrained=False, **kwargs):\n    return _create_vovnet('vovnet57a', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_slim_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_dw(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "vovnet57a",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def vovnet57a(pretrained=False, **kwargs):\n    return _create_vovnet('vovnet57a', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_slim_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_slim(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet19b_slim_dw",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet19b_slim_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_slim(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet39b(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet19b_dw",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet19b_dw(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_dw', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet19b_slim(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet39b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet57b(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet19b_slim",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet19b_slim(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet19b_slim', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet39b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet57b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet57b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet99b(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet39b",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet39b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet57b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet57b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet99b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet99b', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_vovnet39b(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet57b",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet57b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet57b', pretrained=pretrained, **kwargs)\n@register_model\ndef ese_vovnet99b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet99b', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('eca_vovnet39b', pretrained=pretrained, **kwargs)\n# Experimental Models\n@register_model",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet99b",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet99b(pretrained=False, **kwargs):\n    return _create_vovnet('ese_vovnet99b', pretrained=pretrained, **kwargs)\n@register_model\ndef eca_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('eca_vovnet39b', pretrained=pretrained, **kwargs)\n# Experimental Models\n@register_model\ndef ese_vovnet39b_evos(pretrained=False, **kwargs):\n    def norm_act_fn(num_features, **nkwargs):\n        return create_norm_act('EvoNormSample', num_features, jit=False, **nkwargs)",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "eca_vovnet39b",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def eca_vovnet39b(pretrained=False, **kwargs):\n    return _create_vovnet('eca_vovnet39b', pretrained=pretrained, **kwargs)\n# Experimental Models\n@register_model\ndef ese_vovnet39b_evos(pretrained=False, **kwargs):\n    def norm_act_fn(num_features, **nkwargs):\n        return create_norm_act('EvoNormSample', num_features, jit=False, **nkwargs)\n    return _create_vovnet('ese_vovnet39b_evos', pretrained=pretrained, norm_layer=norm_act_fn, **kwargs)\n@register_model\ndef ese_vovnet99b_iabn(pretrained=False, **kwargs):",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet39b_evos",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet39b_evos(pretrained=False, **kwargs):\n    def norm_act_fn(num_features, **nkwargs):\n        return create_norm_act('EvoNormSample', num_features, jit=False, **nkwargs)\n    return _create_vovnet('ese_vovnet39b_evos', pretrained=pretrained, norm_layer=norm_act_fn, **kwargs)\n@register_model\ndef ese_vovnet99b_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_vovnet(\n        'ese_vovnet99b_iabn', pretrained=pretrained, norm_layer=norm_layer, act_layer=nn.LeakyReLU, **kwargs)",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "ese_vovnet99b_iabn",
        "kind": 2,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "def ese_vovnet99b_iabn(pretrained=False, **kwargs):\n    norm_layer = get_norm_act_layer('iabn')\n    return _create_vovnet(\n        'ese_vovnet99b_iabn', pretrained=pretrained, norm_layer=norm_layer, act_layer=nn.LeakyReLU, **kwargs)",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs",
        "kind": 5,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "model_cfgs = dict(\n    vovnet39a=dict(\n        stem_chs=[64, 64, 128],\n        stage_conv_chs=[128, 160, 192, 224],\n        stage_out_chs=[256, 512, 768, 1024],\n        layer_per_block=5,\n        block_per_stage=[1, 1, 2, 2],\n        residual=False,\n        depthwise=False,\n        attn='',",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs['ese_vovnet39b_evos']",
        "kind": 5,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "model_cfgs['ese_vovnet39b_evos'] = model_cfgs['ese_vovnet39b']\nmodel_cfgs['ese_vovnet99b_iabn'] = model_cfgs['ese_vovnet99b']\ndef _cfg(url=''):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.0.conv', 'classifier': 'head.fc',\n    }\ndefault_cfgs = dict(",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "model_cfgs['ese_vovnet99b_iabn']",
        "kind": 5,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "model_cfgs['ese_vovnet99b_iabn'] = model_cfgs['ese_vovnet99b']\ndef _cfg(url=''):\n    return {\n        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n        'crop_pct': 0.875, 'interpolation': 'bicubic',\n        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n        'first_conv': 'stem.0.conv', 'classifier': 'head.fc',\n    }\ndefault_cfgs = dict(\n    vovnet39a=_cfg(url=''),",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.vovnet",
        "description": "timm.models.vovnet",
        "peekOfCode": "default_cfgs = dict(\n    vovnet39a=_cfg(url=''),\n    vovnet57a=_cfg(url=''),\n    ese_vovnet19b_slim_dw=_cfg(url=''),\n    ese_vovnet19b_dw=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth'),\n    ese_vovnet19b_slim=_cfg(url=''),\n    ese_vovnet39b=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet39b-f912fe73.pth'),\n    ese_vovnet57b=_cfg(url=''),",
        "detail": "timm.models.vovnet",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1):\n        super(SeparableConv2d, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=False)\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pointwise(x)\n        return x",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, reps, strides=1, start_with_relu=True, grow_first=True):\n        super(Block, self).__init__()\n        if out_channels != in_channels or strides != 1:\n            self.skip = nn.Conv2d(in_channels, out_channels, 1, stride=strides, bias=False)\n            self.skipbn = nn.BatchNorm2d(out_channels)\n        else:\n            self.skip = None\n        rep = []\n        for i in range(reps):",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "Xception",
        "kind": 6,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "class Xception(nn.Module):\n    \"\"\"\n    Xception optimized for the ImageNet dataset, as specified in\n    https://arxiv.org/pdf/1610.02357.pdf\n    \"\"\"\n    def __init__(self, num_classes=1000, in_chans=3, drop_rate=0., global_pool='avg'):\n        \"\"\" Constructor\n        Args:\n            num_classes: number of classes\n        \"\"\"",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "xception",
        "kind": 2,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "def xception(pretrained=False, **kwargs):\n    return _xception('xception', pretrained=pretrained, **kwargs)",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 5,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                  std=[0.5, 0.5, 0.5])\nThe resize parameter of the validation transform should be 333, and make sure to center crop at 299x299\n\"\"\"\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .helpers import build_model_with_cfg\nfrom .layers import create_classifier\nfrom .registry import register_model\n__all__ = ['Xception']",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "__all__ = ['Xception']\ndefault_cfgs = {\n    'xception': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth',\n        'input_size': (3, 299, 299),\n        'pool_size': (10, 10),\n        'crop_pct': 0.8975,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.xception",
        "description": "timm.models.xception",
        "peekOfCode": "default_cfgs = {\n    'xception': {\n        'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth',\n        'input_size': (3, 299, 299),\n        'pool_size': (10, 10),\n        'crop_pct': 0.8975,\n        'interpolation': 'bicubic',\n        'mean': (0.5, 0.5, 0.5),\n        'std': (0.5, 0.5, 0.5),\n        'num_classes': 1000,",
        "detail": "timm.models.xception",
        "documentation": {}
    },
    {
        "label": "SeparableConv2d",
        "kind": 6,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "class SeparableConv2d(nn.Module):\n    def __init__(\n            self, inplanes, planes, kernel_size=3, stride=1, dilation=1, padding='',\n            act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d):\n        super(SeparableConv2d, self).__init__()\n        self.kernel_size = kernel_size\n        self.dilation = dilation\n        # depthwise convolution\n        self.conv_dw = create_conv2d(\n            inplanes, inplanes, kernel_size, stride=stride,",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "XceptionModule",
        "kind": 6,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "class XceptionModule(nn.Module):\n    def __init__(\n            self, in_chs, out_chs, stride=1, dilation=1, pad_type='',\n            start_with_relu=True, no_skip=False, act_layer=nn.ReLU, norm_layer=None):\n        super(XceptionModule, self).__init__()\n        out_chs = to_3tuple(out_chs)\n        self.in_channels = in_chs\n        self.out_channels = out_chs[-1]\n        self.no_skip = no_skip\n        if not no_skip and (self.out_channels != self.in_channels or stride != 1):",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "XceptionAligned",
        "kind": 6,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "class XceptionAligned(nn.Module):\n    \"\"\"Modified Aligned Xception\n    \"\"\"\n    def __init__(self, block_cfg, num_classes=1000, in_chans=3, output_stride=32,\n                 act_layer=nn.ReLU, norm_layer=nn.BatchNorm2d, drop_rate=0., global_pool='avg'):\n        super(XceptionAligned, self).__init__()\n        self.num_classes = num_classes\n        self.drop_rate = drop_rate\n        assert output_stride in (8, 16, 32)\n        layer_args = dict(act_layer=act_layer, norm_layer=norm_layer)",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "xception41",
        "kind": 2,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "def xception41(pretrained=False, **kwargs):\n    \"\"\" Modified Aligned Xception-41\n    \"\"\"\n    block_cfg = [\n        # entry flow\n        dict(in_chs=64, out_chs=128, stride=2),\n        dict(in_chs=128, out_chs=256, stride=2),\n        dict(in_chs=256, out_chs=728, stride=2),\n        # middle flow\n        *([dict(in_chs=728, out_chs=728, stride=1)] * 8),",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "xception65",
        "kind": 2,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "def xception65(pretrained=False, **kwargs):\n    \"\"\" Modified Aligned Xception-65\n    \"\"\"\n    block_cfg = [\n        # entry flow\n        dict(in_chs=64, out_chs=128, stride=2),\n        dict(in_chs=128, out_chs=256, stride=2),\n        dict(in_chs=256, out_chs=728, stride=2),\n        # middle flow\n        *([dict(in_chs=728, out_chs=728, stride=1)] * 16),",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "xception71",
        "kind": 2,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "def xception71(pretrained=False, **kwargs):\n    \"\"\" Modified Aligned Xception-71\n    \"\"\"\n    block_cfg = [\n        # entry flow\n        dict(in_chs=64, out_chs=128, stride=2),\n        dict(in_chs=128, out_chs=256, stride=1),\n        dict(in_chs=256, out_chs=256, stride=2),\n        dict(in_chs=256, out_chs=728, stride=1),\n        dict(in_chs=728, out_chs=728, stride=2),",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "__all__ = ['XceptionAligned']\ndef _cfg(url='', **kwargs):\n    return {\n        'url': url,\n        'num_classes': 1000, 'input_size': (3, 299, 299), 'pool_size': (10, 10),\n        'crop_pct': 0.903, 'interpolation': 'bicubic',\n        'mean': IMAGENET_INCEPTION_MEAN, 'std': IMAGENET_INCEPTION_STD,\n        'first_conv': 'stem.0.conv', 'classifier': 'head.fc',\n        **kwargs\n    }",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.xception_aligned",
        "description": "timm.models.xception_aligned",
        "peekOfCode": "default_cfgs = dict(\n    xception41=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_41-e6439c97.pth'),\n    xception65=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_65-c9ae96e8.pth'),\n    xception71=_cfg(\n        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_xception_71-8eec7df1.pth'),\n)\nclass SeparableConv2d(nn.Module):\n    def __init__(",
        "detail": "timm.models.xception_aligned",
        "documentation": {}
    },
    {
        "label": "PositionalEncodingFourier",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class PositionalEncodingFourier(nn.Module):\n    \"\"\"\n    Positional encoding relying on a fourier kernel matching the one used in the \"Attention is all of Need\" paper.\n    Based on the official XCiT code\n        - https://github.com/facebookresearch/xcit/blob/master/xcit.py\n    \"\"\"\n    def __init__(self, hidden_dim=32, dim=768, temperature=10000):\n        super().__init__()\n        self.token_projection = nn.Conv2d(hidden_dim * 2, dim, kernel_size=1)\n        self.scale = 2 * math.pi",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "ConvPatchEmbed",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class ConvPatchEmbed(nn.Module):\n    \"\"\"Image to Patch Embedding using multiple convolutional layers\"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, act_layer=nn.GELU):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        num_patches = (img_size[1] // patch_size) * (img_size[0] // patch_size)\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = num_patches\n        if patch_size == 16:",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "LPI",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class LPI(nn.Module):\n    \"\"\"\n    Local Patch Interaction module that allows explicit communication between tokens in 3x3 windows to augment the\n    implicit communication performed by the block diagonal scatter attention. Implemented using 2 layers of separable\n    3x3 convolutions with GeLU and BatchNorm2d\n    \"\"\"\n    def __init__(self, in_features, out_features=None, act_layer=nn.GELU, kernel_size=3):\n        super().__init__()\n        out_features = out_features or in_features\n        padding = kernel_size // 2",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "ClassAttentionBlock",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class ClassAttentionBlock(nn.Module):\n    \"\"\"Class Attention Layer as in CaiT https://arxiv.org/abs/2103.17239\"\"\"\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, eta=1., tokens_norm=False):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = ClassAttn(\n            dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        self.norm2 = norm_layer(dim)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "XCA",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class XCA(nn.Module):\n    \"\"\" Cross-Covariance Attention (XCA)\n    Operation where the channels are updated using a weighted sum. The weights are obtained from the (softmax\n    normalized) Cross-covariance matrix (Q^T \\\\cdot K \\\\in d_h \\\\times d_h)\n    \"\"\"\n    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1))\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "XCABlock",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class XCABlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, eta=1.):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = XCA(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        self.norm3 = norm_layer(dim)\n        self.local_mp = LPI(in_features=dim, act_layer=act_layer)\n        self.norm2 = norm_layer(dim)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "XCiT",
        "kind": 6,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "class XCiT(nn.Module):\n    \"\"\"\n    Based on timm and DeiT code bases\n    https://github.com/rwightman/pytorch-image-models/tree/master/timm\n    https://github.com/facebookresearch/deit/\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n                 num_heads=12, mlp_ratio=4., qkv_bias=True, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,\n                 act_layer=None, norm_layer=None, cls_attn_layers=2, use_pos_embed=True, eta=1., tokens_norm=False):\n        \"\"\"",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "conv3x3",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution + batch norm\"\"\"\n    return torch.nn.Sequential(\n        nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False),\n        nn.BatchNorm2d(out_planes)\n    )\nclass ConvPatchEmbed(nn.Module):\n    \"\"\"Image to Patch Embedding using multiple convolutional layers\"\"\"\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, act_layer=nn.GELU):\n        super().__init__()",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "checkpoint_filter_fn",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def checkpoint_filter_fn(state_dict, model):\n    if 'model' in state_dict:\n        state_dict = state_dict['model']\n    # For consistency with timm's transformer models while being compatible with official weights source we rename\n    # pos_embeder to pos_embed. Also account for use_pos_embed == False\n    use_pos_embed = getattr(model, 'pos_embed', None) is not None\n    pos_embed_keys = [k for k in state_dict if k.startswith('pos_embed')]\n    for k in pos_embed_keys:\n        if use_pos_embed:\n            state_dict[k.replace('pos_embeder.', 'pos_embed.')] = state_dict.pop(k)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_nano_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_nano_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, img_size=384, **kwargs)\n    model = _create_xcit('xcit_nano_12_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, img_size=384, **kwargs)\n    model = _create_xcit('xcit_nano_12_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p16_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p16_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p16_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p16_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p16_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p16_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=16, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p16_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n# Patch size 8x8 models\n@register_model\ndef xcit_nano_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_nano_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_nano_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_nano_12_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_nano_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=128, depth=12, num_heads=4, eta=1.0, tokens_norm=False, **kwargs)\n    model = _create_xcit('xcit_nano_12_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_12_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=12, num_heads=4, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_12_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_12_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_12_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=12, num_heads=8, eta=1.0, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_12_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_tiny_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_tiny_24_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_tiny_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=192, depth=24, num_heads=4, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_tiny_24_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_small_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_small_24_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_small_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=384, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_small_24_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_medium_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_medium_24_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_medium_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=512, depth=24, num_heads=8, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_medium_24_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_224', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p8_224",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p8_224(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_224', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_224_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p8_224_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p8_224_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_224_dist', pretrained=pretrained, **model_kwargs)\n    return model\n@register_model\ndef xcit_large_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_384_dist', pretrained=pretrained, **model_kwargs)",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "xcit_large_24_p8_384_dist",
        "kind": 2,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "def xcit_large_24_p8_384_dist(pretrained=False, **kwargs):\n    model_kwargs = dict(\n        patch_size=8, embed_dim=768, depth=24, num_heads=16, eta=1e-5, tokens_norm=True, **kwargs)\n    model = _create_xcit('xcit_large_24_p8_384_dist', pretrained=pretrained, **model_kwargs)\n    return model",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "kind": 5,
        "importPath": "timm.models.xcit",
        "description": "timm.models.xcit",
        "peekOfCode": "default_cfgs = {\n    # Patch size 16\n    'xcit_nano_12_p16_224': _cfg(url='https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224.pth'),  \n    'xcit_nano_12_p16_224_dist': _cfg(url='https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224_dist.pth'),\n    'xcit_nano_12_p16_384_dist': _cfg(\n        url='https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_384_dist.pth', input_size=(3, 384, 384)),\n    'xcit_tiny_12_p16_224': _cfg(url='https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224.pth'),\n    'xcit_tiny_12_p16_224_dist': _cfg(url='https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224_dist.pth'),\n    'xcit_tiny_12_p16_384_dist': _cfg(\n        url='https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_384_dist.pth', input_size=(3, 384, 384)),",
        "detail": "timm.models.xcit",
        "documentation": {}
    },
    {
        "label": "AdaBelief",
        "kind": 6,
        "importPath": "timm.optim.adabelief",
        "description": "timm.optim.adabelief",
        "peekOfCode": "class AdaBelief(Optimizer):\n    r\"\"\"Implements AdaBelief algorithm. Modified from Adam in PyTorch\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-16)",
        "detail": "timm.optim.adabelief",
        "documentation": {}
    },
    {
        "label": "Adafactor",
        "kind": 6,
        "importPath": "timm.optim.adafactor",
        "description": "timm.optim.adafactor",
        "peekOfCode": "class Adafactor(torch.optim.Optimizer):\n    \"\"\"Implements Adafactor algorithm.\n    This implementation is based on: `Adafactor: Adaptive Learning Rates with Sublinear Memory Cost`\n    (see https://arxiv.org/abs/1804.04235)\n    Note that this optimizer internally adjusts the learning rate depending on the\n    *scale_parameter*, *relative_step* and *warmup_init* options.\n    To use a manual (external) learning rate schedule you should set `scale_parameter=False` and\n    `relative_step=False`.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining parameter groups",
        "detail": "timm.optim.adafactor",
        "documentation": {}
    },
    {
        "label": "Adahessian",
        "kind": 6,
        "importPath": "timm.optim.adahessian",
        "description": "timm.optim.adahessian",
        "peekOfCode": "class Adahessian(torch.optim.Optimizer):\n    \"\"\"\n    Implements the AdaHessian algorithm from \"ADAHESSIAN: An Adaptive Second OrderOptimizer for Machine Learning\"\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining parameter groups\n        lr (float, optional): learning rate (default: 0.1)\n        betas ((float, float), optional): coefficients used for computing running averages of gradient and the\n            squared hessian trace (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0.0)",
        "detail": "timm.optim.adahessian",
        "documentation": {}
    },
    {
        "label": "AdamP",
        "kind": 6,
        "importPath": "timm.optim.adamp",
        "description": "timm.optim.adamp",
        "peekOfCode": "class AdamP(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0, delta=0.1, wd_ratio=0.1, nesterov=False):\n        defaults = dict(\n            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n            delta=delta, wd_ratio=wd_ratio, nesterov=nesterov)\n        super(AdamP, self).__init__(params, defaults)\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None",
        "detail": "timm.optim.adamp",
        "documentation": {}
    },
    {
        "label": "projection",
        "kind": 2,
        "importPath": "timm.optim.adamp",
        "description": "timm.optim.adamp",
        "peekOfCode": "def projection(p, grad, perturb, delta: float, wd_ratio: float, eps: float):\n    wd = 1.\n    expand_size = (-1,) + (1,) * (len(p.shape) - 1)\n    for view_func in [_channel_view, _layer_view]:\n        param_view = view_func(p)\n        grad_view = view_func(grad)\n        cosine_sim = F.cosine_similarity(grad_view, param_view, dim=1, eps=eps).abs_()\n        # FIXME this is a problem for PyTorch XLA\n        if cosine_sim.max() < delta / math.sqrt(param_view.size(1)):\n            p_n = p / param_view.norm(p=2, dim=1).add_(eps).reshape(expand_size)",
        "detail": "timm.optim.adamp",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "kind": 6,
        "importPath": "timm.optim.adamw",
        "description": "timm.optim.adamw",
        "peekOfCode": "class AdamW(Optimizer):\n    r\"\"\"Implements AdamW algorithm.\n    The original Adam algorithm was proposed in `Adam: A Method for Stochastic Optimization`_.\n    The AdamW variant was proposed in `Decoupled Weight Decay Regularization`_.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))",
        "detail": "timm.optim.adamw",
        "documentation": {}
    },
    {
        "label": "Lamb",
        "kind": 6,
        "importPath": "timm.optim.lamb",
        "description": "timm.optim.lamb",
        "peekOfCode": "class Lamb(Optimizer):\n    \"\"\"Implements a pure pytorch variant of FuseLAMB (NvLamb variant) optimizer from apex.optimizers.FusedLAMB\n    reference: https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/Transformer-XL/pytorch/lamb.py\n    LAMB was proposed in `Large Batch Optimization for Deep Learning: Training BERT in 76 minutes`_.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n        lr (float, optional): learning rate. (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its norm. (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve",
        "detail": "timm.optim.lamb",
        "documentation": {}
    },
    {
        "label": "Lars",
        "kind": 6,
        "importPath": "timm.optim.lars",
        "description": "timm.optim.lars",
        "peekOfCode": "class Lars(Optimizer):\n    \"\"\" LARS for PyTorch\n    Paper: `Large batch training of Convolutional Networks` - https://arxiv.org/pdf/1708.03888.pdf\n    Args:\n        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n        lr (float, optional): learning rate (default: 1.0).\n        momentum (float, optional): momentum factor (default: 0)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        dampening (float, optional): dampening for momentum (default: 0)\n        nesterov (bool, optional): enables Nesterov momentum (default: False)",
        "detail": "timm.optim.lars",
        "documentation": {}
    },
    {
        "label": "Lookahead",
        "kind": 6,
        "importPath": "timm.optim.lookahead",
        "description": "timm.optim.lookahead",
        "peekOfCode": "class Lookahead(Optimizer):\n    def __init__(self, base_optimizer, alpha=0.5, k=6):\n        # NOTE super().__init__() not called on purpose\n        if not 0.0 <= alpha <= 1.0:\n            raise ValueError(f'Invalid slow update rate: {alpha}')\n        if not 1 <= k:\n            raise ValueError(f'Invalid lookahead steps: {k}')\n        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n        self._base_optimizer = base_optimizer\n        self.param_groups = base_optimizer.param_groups",
        "detail": "timm.optim.lookahead",
        "documentation": {}
    },
    {
        "label": "MADGRAD",
        "kind": 6,
        "importPath": "timm.optim.madgrad",
        "description": "timm.optim.madgrad",
        "peekOfCode": "class MADGRAD(torch.optim.Optimizer):\n    \"\"\"\n    MADGRAD_: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic\n    Optimization.\n    .. _MADGRAD: https://arxiv.org/abs/2101.11075\n    MADGRAD is a general purpose optimizer that can be used in place of SGD or\n    Adam may converge faster and generalize better. Currently GPU-only.\n    Typically, the same learning rate schedule that is used for SGD or Adam may\n    be used. The overall learning rate is not comparable to either method and\n    should be determined by a hyper-parameter sweep.",
        "detail": "timm.optim.madgrad",
        "documentation": {}
    },
    {
        "label": "Nadam",
        "kind": 6,
        "importPath": "timm.optim.nadam",
        "description": "timm.optim.nadam",
        "peekOfCode": "class Nadam(Optimizer):\n    \"\"\"Implements Nadam algorithm (a variant of Adam based on Nesterov momentum).\n    It has been proposed in `Incorporating Nesterov Momentum into Adam`__.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 2e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square\n        eps (float, optional): term added to the denominator to improve",
        "detail": "timm.optim.nadam",
        "documentation": {}
    },
    {
        "label": "NvNovoGrad",
        "kind": 6,
        "importPath": "timm.optim.nvnovograd",
        "description": "timm.optim.nvnovograd",
        "peekOfCode": "class NvNovoGrad(Optimizer):\n    \"\"\"\n    Implements Novograd algorithm.\n    Args:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.95, 0.98))\n        eps (float, optional): term added to the denominator to improve",
        "detail": "timm.optim.nvnovograd",
        "documentation": {}
    },
    {
        "label": "add_weight_decay",
        "kind": 2,
        "importPath": "timm.optim.optim_factory",
        "description": "timm.optim.optim_factory",
        "peekOfCode": "def add_weight_decay(model, weight_decay=1e-5, skip_list=()):\n    decay = []\n    no_decay = []\n    for name, param in model.named_parameters():\n        if not param.requires_grad:\n            continue  # frozen weights\n        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n            no_decay.append(param)\n        else:\n            decay.append(param)",
        "detail": "timm.optim.optim_factory",
        "documentation": {}
    },
    {
        "label": "optimizer_kwargs",
        "kind": 2,
        "importPath": "timm.optim.optim_factory",
        "description": "timm.optim.optim_factory",
        "peekOfCode": "def optimizer_kwargs(cfg):\n    \"\"\" cfg/argparse to kwargs helper\n    Convert optimizer args in argparse args or cfg like object to keyword args for updated create fn.\n    \"\"\"\n    kwargs = dict(\n        opt=cfg.opt,\n        lr=cfg.lr,\n        weight_decay=cfg.weight_decay,\n        momentum=cfg.momentum)\n    if getattr(cfg, 'opt_eps', None) is not None:",
        "detail": "timm.optim.optim_factory",
        "documentation": {}
    },
    {
        "label": "create_optimizer",
        "kind": 2,
        "importPath": "timm.optim.optim_factory",
        "description": "timm.optim.optim_factory",
        "peekOfCode": "def create_optimizer(args, model, filter_bias_and_bn=True):\n    \"\"\" Legacy optimizer factory for backwards compatibility.\n    NOTE: Use create_optimizer_v2 for new code.\n    \"\"\"\n    return create_optimizer_v2(\n        model,\n        **optimizer_kwargs(cfg=args),\n        filter_bias_and_bn=filter_bias_and_bn,\n    )\ndef create_optimizer_v2(",
        "detail": "timm.optim.optim_factory",
        "documentation": {}
    },
    {
        "label": "create_optimizer_v2",
        "kind": 2,
        "importPath": "timm.optim.optim_factory",
        "description": "timm.optim.optim_factory",
        "peekOfCode": "def create_optimizer_v2(\n        model_or_params,\n        opt: str = 'sgd',\n        lr: Optional[float] = None,\n        weight_decay: float = 0.,\n        momentum: float = 0.9,\n        filter_bias_and_bn: bool = True,\n        **kwargs):\n    \"\"\" Create an optimizer.\n    TODO currently the model is passed in and all parameters are selected for optimization.",
        "detail": "timm.optim.optim_factory",
        "documentation": {}
    },
    {
        "label": "RAdam",
        "kind": 6,
        "importPath": "timm.optim.radam",
        "description": "timm.optim.radam",
        "peekOfCode": "class RAdam(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        defaults = dict(\n            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n            buffer=[[None, None, None] for _ in range(10)])\n        super(RAdam, self).__init__(params, defaults)\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n    @torch.no_grad()\n    def step(self, closure=None):",
        "detail": "timm.optim.radam",
        "documentation": {}
    },
    {
        "label": "RMSpropTF",
        "kind": 6,
        "importPath": "timm.optim.rmsprop_tf",
        "description": "timm.optim.rmsprop_tf",
        "peekOfCode": "class RMSpropTF(Optimizer):\n    \"\"\"Implements RMSprop algorithm (TensorFlow style epsilon)\n    NOTE: This is a direct cut-and-paste of PyTorch RMSprop with eps applied before sqrt\n    and a few other modifications to closer match Tensorflow for matching hyper-params.\n    Noteworthy changes include:\n    1. Epsilon applied inside square-root\n    2. square_avg initialized to ones\n    3. LR scaling of update accumulated in momentum buffer\n    Proposed by G. Hinton in his\n    `course <http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_.",
        "detail": "timm.optim.rmsprop_tf",
        "documentation": {}
    },
    {
        "label": "SGDP",
        "kind": 6,
        "importPath": "timm.optim.sgdp",
        "description": "timm.optim.sgdp",
        "peekOfCode": "class SGDP(Optimizer):\n    def __init__(self, params, lr=required, momentum=0, dampening=0,\n                 weight_decay=0, nesterov=False, eps=1e-8, delta=0.1, wd_ratio=0.1):\n        defaults = dict(\n            lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay,\n            nesterov=nesterov, eps=eps, delta=delta, wd_ratio=wd_ratio)\n        super(SGDP, self).__init__(params, defaults)\n    @torch.no_grad()\n    def step(self, closure=None):\n        loss = None",
        "detail": "timm.optim.sgdp",
        "documentation": {}
    },
    {
        "label": "CosineLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.cosine_lr",
        "description": "timm.scheduler.cosine_lr",
        "peekOfCode": "class CosineLRScheduler(Scheduler):\n    \"\"\"\n    Cosine decay with restarts.\n    This is described in the paper https://arxiv.org/abs/1608.03983.\n    Inspiration from\n    https://github.com/allenai/allennlp/blob/master/allennlp/training/learning_rate_schedulers/cosine.py\n    k-decay option based on `k-decay: A New Method For Learning Rate Schedule` - https://arxiv.org/abs/2004.05909\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,",
        "detail": "timm.scheduler.cosine_lr",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.scheduler.cosine_lr",
        "description": "timm.scheduler.cosine_lr",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass CosineLRScheduler(Scheduler):\n    \"\"\"\n    Cosine decay with restarts.\n    This is described in the paper https://arxiv.org/abs/1608.03983.\n    Inspiration from\n    https://github.com/allenai/allennlp/blob/master/allennlp/training/learning_rate_schedulers/cosine.py\n    k-decay option based on `k-decay: A New Method For Learning Rate Schedule` - https://arxiv.org/abs/2004.05909\n    \"\"\"\n    def __init__(self,",
        "detail": "timm.scheduler.cosine_lr",
        "documentation": {}
    },
    {
        "label": "MultiStepLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.multistep_lr",
        "description": "timm.scheduler.multistep_lr",
        "peekOfCode": "class MultiStepLRScheduler(Scheduler):\n    \"\"\"\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 decay_t: List[int],\n                 decay_rate: float = 1.,\n                 warmup_t=0,\n                 warmup_lr_init=0,\n                 t_in_epochs=True,",
        "detail": "timm.scheduler.multistep_lr",
        "documentation": {}
    },
    {
        "label": "PlateauLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.plateau_lr",
        "description": "timm.scheduler.plateau_lr",
        "peekOfCode": "class PlateauLRScheduler(Scheduler):\n    \"\"\"Decay the LR by a factor every time the validation loss plateaus.\"\"\"\n    def __init__(self,\n                 optimizer,\n                 decay_rate=0.1,\n                 patience_t=10,\n                 verbose=True,\n                 threshold=1e-4,\n                 cooldown_t=0,\n                 warmup_t=0,",
        "detail": "timm.scheduler.plateau_lr",
        "documentation": {}
    },
    {
        "label": "PolyLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.poly_lr",
        "description": "timm.scheduler.poly_lr",
        "peekOfCode": "class PolyLRScheduler(Scheduler):\n    \"\"\" Polynomial LR Scheduler w/ warmup, noise, and k-decay\n    k-decay option based on `k-decay: A New Method For Learning Rate Schedule` - https://arxiv.org/abs/2004.05909\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 t_initial: int,\n                 power: float = 0.5,\n                 lr_min: float = 0.,\n                 cycle_mul: float = 1.,",
        "detail": "timm.scheduler.poly_lr",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.scheduler.poly_lr",
        "description": "timm.scheduler.poly_lr",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass PolyLRScheduler(Scheduler):\n    \"\"\" Polynomial LR Scheduler w/ warmup, noise, and k-decay\n    k-decay option based on `k-decay: A New Method For Learning Rate Schedule` - https://arxiv.org/abs/2004.05909\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 t_initial: int,\n                 power: float = 0.5,\n                 lr_min: float = 0.,",
        "detail": "timm.scheduler.poly_lr",
        "documentation": {}
    },
    {
        "label": "Scheduler",
        "kind": 6,
        "importPath": "timm.scheduler.scheduler",
        "description": "timm.scheduler.scheduler",
        "peekOfCode": "class Scheduler:\n    \"\"\" Parameter Scheduler Base Class\n    A scheduler base class that can be used to schedule any optimizer parameter groups.\n    Unlike the builtin PyTorch schedulers, this is intended to be consistently called\n    * At the END of each epoch, before incrementing the epoch count, to calculate next epoch's value\n    * At the END of each optimizer update, after incrementing the update count, to calculate next update's value\n    The schedulers built on this should try to remain as stateless as possible (for simplicity).\n    This family of schedulers is attempting to avoid the confusion of the meaning of 'last_epoch'\n    and -1 values for special behaviour. All epoch and update counts must be tracked in the training\n    code and explicitly passed in to the schedulers on the corresponding step or step_update call.",
        "detail": "timm.scheduler.scheduler",
        "documentation": {}
    },
    {
        "label": "create_scheduler",
        "kind": 2,
        "importPath": "timm.scheduler.scheduler_factory",
        "description": "timm.scheduler.scheduler_factory",
        "peekOfCode": "def create_scheduler(args, optimizer):\n    num_epochs = args.epochs\n    if getattr(args, 'lr_noise', None) is not None:\n        lr_noise = getattr(args, 'lr_noise')\n        if isinstance(lr_noise, (list, tuple)):\n            noise_range = [n * num_epochs for n in lr_noise]\n            if len(noise_range) == 1:\n                noise_range = noise_range[0]\n        else:\n            noise_range = lr_noise * num_epochs",
        "detail": "timm.scheduler.scheduler_factory",
        "documentation": {}
    },
    {
        "label": "StepLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.step_lr",
        "description": "timm.scheduler.step_lr",
        "peekOfCode": "class StepLRScheduler(Scheduler):\n    \"\"\"\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 decay_t: float,\n                 decay_rate: float = 1.,\n                 warmup_t=0,\n                 warmup_lr_init=0,\n                 t_in_epochs=True,",
        "detail": "timm.scheduler.step_lr",
        "documentation": {}
    },
    {
        "label": "TanhLRScheduler",
        "kind": 6,
        "importPath": "timm.scheduler.tanh_lr",
        "description": "timm.scheduler.tanh_lr",
        "peekOfCode": "class TanhLRScheduler(Scheduler):\n    \"\"\"\n    Hyberbolic-Tangent decay with restarts.\n    This is described in the paper https://arxiv.org/abs/1806.01593\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 t_initial: int,\n                 lb: float = -7.,\n                 ub: float = 3.,",
        "detail": "timm.scheduler.tanh_lr",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.scheduler.tanh_lr",
        "description": "timm.scheduler.tanh_lr",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass TanhLRScheduler(Scheduler):\n    \"\"\"\n    Hyberbolic-Tangent decay with restarts.\n    This is described in the paper https://arxiv.org/abs/1806.01593\n    \"\"\"\n    def __init__(self,\n                 optimizer: torch.optim.Optimizer,\n                 t_initial: int,\n                 lb: float = -7.,",
        "detail": "timm.scheduler.tanh_lr",
        "documentation": {}
    },
    {
        "label": "unitwise_norm",
        "kind": 2,
        "importPath": "timm.utils.agc",
        "description": "timm.utils.agc",
        "peekOfCode": "def unitwise_norm(x, norm_type=2.0):\n    if x.ndim <= 1:\n        return x.norm(norm_type)\n    else:\n        # works for nn.ConvNd and nn,Linear where output dim is first in the kernel/weight tensor\n        # might need special cases for other weights (possibly MHA) where this may not be true\n        return x.norm(norm_type, dim=tuple(range(1, x.ndim)), keepdim=True)\ndef adaptive_clip_grad(parameters, clip_factor=0.01, eps=1e-3, norm_type=2.0):\n    if isinstance(parameters, torch.Tensor):\n        parameters = [parameters]",
        "detail": "timm.utils.agc",
        "documentation": {}
    },
    {
        "label": "adaptive_clip_grad",
        "kind": 2,
        "importPath": "timm.utils.agc",
        "description": "timm.utils.agc",
        "peekOfCode": "def adaptive_clip_grad(parameters, clip_factor=0.01, eps=1e-3, norm_type=2.0):\n    if isinstance(parameters, torch.Tensor):\n        parameters = [parameters]\n    for p in parameters:\n        if p.grad is None:\n            continue\n        p_data = p.detach()\n        g_data = p.grad.detach()\n        max_norm = unitwise_norm(p_data, norm_type=norm_type).clamp_(min=eps).mul_(clip_factor)\n        grad_norm = unitwise_norm(g_data, norm_type=norm_type)",
        "detail": "timm.utils.agc",
        "documentation": {}
    },
    {
        "label": "CheckpointSaver",
        "kind": 6,
        "importPath": "timm.utils.checkpoint_saver",
        "description": "timm.utils.checkpoint_saver",
        "peekOfCode": "class CheckpointSaver:\n    def __init__(\n            self,\n            model,\n            optimizer,\n            args=None,\n            model_ema=None,\n            amp_scaler=None,\n            checkpoint_prefix='checkpoint',\n            recovery_prefix='recovery',",
        "detail": "timm.utils.checkpoint_saver",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.utils.checkpoint_saver",
        "description": "timm.utils.checkpoint_saver",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass CheckpointSaver:\n    def __init__(\n            self,\n            model,\n            optimizer,\n            args=None,\n            model_ema=None,\n            amp_scaler=None,\n            checkpoint_prefix='checkpoint',",
        "detail": "timm.utils.checkpoint_saver",
        "documentation": {}
    },
    {
        "label": "dispatch_clip_grad",
        "kind": 2,
        "importPath": "timm.utils.clip_grad",
        "description": "timm.utils.clip_grad",
        "peekOfCode": "def dispatch_clip_grad(parameters, value: float, mode: str = 'norm', norm_type: float = 2.0):\n    \"\"\" Dispatch to gradient clipping method\n    Args:\n        parameters (Iterable): model parameters to clip\n        value (float): clipping value/factor/norm, mode dependant\n        mode (str): clipping mode, one of 'norm', 'value', 'agc'\n        norm_type (float): p-norm, default 2.0\n    \"\"\"\n    if mode == 'norm':\n        torch.nn.utils.clip_grad_norm_(parameters, value, norm_type=norm_type)",
        "detail": "timm.utils.clip_grad",
        "documentation": {}
    },
    {
        "label": "ApexScaler",
        "kind": 6,
        "importPath": "timm.utils.cuda",
        "description": "timm.utils.cuda",
        "peekOfCode": "class ApexScaler:\n    state_dict_key = \"amp\"\n    def __call__(self, loss, optimizer, clip_grad=None, clip_mode='norm', parameters=None, create_graph=False):\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward(create_graph=create_graph)\n        if clip_grad is not None:\n            dispatch_clip_grad(amp.master_params(optimizer), clip_grad, mode=clip_mode)\n        optimizer.step()\n    def state_dict(self):\n        if 'state_dict' in amp.__dict__:",
        "detail": "timm.utils.cuda",
        "documentation": {}
    },
    {
        "label": "NativeScaler",
        "kind": 6,
        "importPath": "timm.utils.cuda",
        "description": "timm.utils.cuda",
        "peekOfCode": "class NativeScaler:\n    state_dict_key = \"amp_scaler\"\n    def __init__(self):\n        self._scaler = torch.cuda.amp.GradScaler()\n    def __call__(self, loss, optimizer, clip_grad=None, clip_mode='norm', parameters=None, create_graph=False):\n        self._scaler.scale(loss).backward(create_graph=create_graph)\n        if clip_grad is not None:\n            assert parameters is not None\n            self._scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n            dispatch_clip_grad(parameters, clip_grad, mode=clip_mode)",
        "detail": "timm.utils.cuda",
        "documentation": {}
    },
    {
        "label": "reduce_tensor",
        "kind": 2,
        "importPath": "timm.utils.distributed",
        "description": "timm.utils.distributed",
        "peekOfCode": "def reduce_tensor(tensor, n):\n    rt = tensor.clone()\n    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n    rt /= n\n    return rt\ndef distribute_bn(model, world_size, reduce=False):\n    # ensure every node has the same running bn stats\n    for bn_name, bn_buf in unwrap_model(model).named_buffers(recurse=True):\n        if ('running_mean' in bn_name) or ('running_var' in bn_name):\n            if reduce:",
        "detail": "timm.utils.distributed",
        "documentation": {}
    },
    {
        "label": "distribute_bn",
        "kind": 2,
        "importPath": "timm.utils.distributed",
        "description": "timm.utils.distributed",
        "peekOfCode": "def distribute_bn(model, world_size, reduce=False):\n    # ensure every node has the same running bn stats\n    for bn_name, bn_buf in unwrap_model(model).named_buffers(recurse=True):\n        if ('running_mean' in bn_name) or ('running_var' in bn_name):\n            if reduce:\n                # average bn stats across whole group\n                torch.distributed.all_reduce(bn_buf, op=dist.ReduceOp.SUM)\n                bn_buf /= float(world_size)\n            else:\n                # broadcast bn stats from rank 0 to whole group",
        "detail": "timm.utils.distributed",
        "documentation": {}
    },
    {
        "label": "set_jit_legacy",
        "kind": 2,
        "importPath": "timm.utils.jit",
        "description": "timm.utils.jit",
        "peekOfCode": "def set_jit_legacy():\n    \"\"\" Set JIT executor to legacy w/ support for op fusion\n    This is hopefully a temporary need in 1.5/1.5.1/1.6 to restore performance due to changes\n    in the JIT exectutor. These API are not supported so could change.\n    \"\"\"\n    #\n    assert hasattr(torch._C, '_jit_set_profiling_executor'), \"Old JIT behavior doesn't exist!\"\n    torch._C._jit_set_profiling_executor(False)\n    torch._C._jit_set_profiling_mode(False)\n    torch._C._jit_override_can_fuse_on_gpu(True)",
        "detail": "timm.utils.jit",
        "documentation": {}
    },
    {
        "label": "set_jit_fuser",
        "kind": 2,
        "importPath": "timm.utils.jit",
        "description": "timm.utils.jit",
        "peekOfCode": "def set_jit_fuser(fuser):\n    if fuser == \"te\":\n        # default fuser should be == 'te'\n        torch._C._jit_set_profiling_executor(True)\n        torch._C._jit_set_profiling_mode(True)\n        torch._C._jit_override_can_fuse_on_cpu(False)\n        torch._C._jit_override_can_fuse_on_gpu(True)\n        torch._C._jit_set_texpr_fuser_enabled(True)\n    elif fuser == \"old\" or fuser == \"legacy\":\n        torch._C._jit_set_profiling_executor(False)",
        "detail": "timm.utils.jit",
        "documentation": {}
    },
    {
        "label": "FormatterNoInfo",
        "kind": 6,
        "importPath": "timm.utils.log",
        "description": "timm.utils.log",
        "peekOfCode": "class FormatterNoInfo(logging.Formatter):\n    def __init__(self, fmt='%(levelname)s: %(message)s'):\n        logging.Formatter.__init__(self, fmt)\n    def format(self, record):\n        if record.levelno == logging.INFO:\n            return str(record.getMessage())\n        return logging.Formatter.format(self, record)\ndef setup_default_logging(default_level=logging.INFO, log_path=''):\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(FormatterNoInfo())",
        "detail": "timm.utils.log",
        "documentation": {}
    },
    {
        "label": "setup_default_logging",
        "kind": 2,
        "importPath": "timm.utils.log",
        "description": "timm.utils.log",
        "peekOfCode": "def setup_default_logging(default_level=logging.INFO, log_path=''):\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(FormatterNoInfo())\n    logging.root.addHandler(console_handler)\n    logging.root.setLevel(default_level)\n    if log_path:\n        file_handler = logging.handlers.RotatingFileHandler(log_path, maxBytes=(1024 ** 2 * 2), backupCount=3)\n        file_formatter = logging.Formatter(\"%(asctime)s - %(name)20s: [%(levelname)8s] - %(message)s\")\n        file_handler.setFormatter(file_formatter)\n        logging.root.addHandler(file_handler)",
        "detail": "timm.utils.log",
        "documentation": {}
    },
    {
        "label": "AverageMeter",
        "kind": 6,
        "importPath": "timm.utils.metrics",
        "description": "timm.utils.metrics",
        "peekOfCode": "class AverageMeter:\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    def update(self, val, n=1):",
        "detail": "timm.utils.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 2,
        "importPath": "timm.utils.metrics",
        "description": "timm.utils.metrics",
        "peekOfCode": "def accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    maxk = min(max(topk), output.size()[1])\n    batch_size = target.size(0)\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n    return [correct[:min(k, maxk)].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]",
        "detail": "timm.utils.metrics",
        "documentation": {}
    },
    {
        "label": "natural_key",
        "kind": 2,
        "importPath": "timm.utils.misc",
        "description": "timm.utils.misc",
        "peekOfCode": "def natural_key(string_):\n    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_.lower())]\ndef add_bool_arg(parser, name, default=False, help=''):\n    dest_name = name.replace('-', '_')\n    group = parser.add_mutually_exclusive_group(required=False)\n    group.add_argument('--' + name, dest=dest_name, action='store_true', help=help)\n    group.add_argument('--no-' + name, dest=dest_name, action='store_false', help=help)\n    parser.set_defaults(**{dest_name: default})",
        "detail": "timm.utils.misc",
        "documentation": {}
    },
    {
        "label": "add_bool_arg",
        "kind": 2,
        "importPath": "timm.utils.misc",
        "description": "timm.utils.misc",
        "peekOfCode": "def add_bool_arg(parser, name, default=False, help=''):\n    dest_name = name.replace('-', '_')\n    group = parser.add_mutually_exclusive_group(required=False)\n    group.add_argument('--' + name, dest=dest_name, action='store_true', help=help)\n    group.add_argument('--no-' + name, dest=dest_name, action='store_false', help=help)\n    parser.set_defaults(**{dest_name: default})",
        "detail": "timm.utils.misc",
        "documentation": {}
    },
    {
        "label": "ActivationStatsHook",
        "kind": 6,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "class ActivationStatsHook:\n    \"\"\"Iterates through each of `model`'s modules and matches modules using unix pattern \n    matching based on `hook_fn_locs` and registers `hook_fn` to the module if there is \n    a match. \n    Arguments:\n        model (nn.Module): model from which we will extract the activation stats\n        hook_fn_locs (List[str]): List of `hook_fn` locations based on Unix type string \n            matching with the name of model's modules. \n        hook_fns (List[Callable]): List of hook functions to be registered at every\n            module in `layer_names`.",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "unwrap_model",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def unwrap_model(model):\n    if isinstance(model, ModelEma):\n        return unwrap_model(model.ema)\n    else:\n        return model.module if hasattr(model, 'module') else model\ndef get_state_dict(model, unwrap_fn=unwrap_model):\n    return unwrap_fn(model).state_dict()\ndef avg_sq_ch_mean(model, input, output):\n    \"\"\" calculate average channel square mean of output activations\n    \"\"\"",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "get_state_dict",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def get_state_dict(model, unwrap_fn=unwrap_model):\n    return unwrap_fn(model).state_dict()\ndef avg_sq_ch_mean(model, input, output):\n    \"\"\" calculate average channel square mean of output activations\n    \"\"\"\n    return torch.mean(output.mean(axis=[0, 2, 3]) ** 2).item()\ndef avg_ch_var(model, input, output):\n    \"\"\" calculate average channel variance of output activations\n    \"\"\"\n    return torch.mean(output.var(axis=[0, 2, 3])).item()",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "avg_sq_ch_mean",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def avg_sq_ch_mean(model, input, output):\n    \"\"\" calculate average channel square mean of output activations\n    \"\"\"\n    return torch.mean(output.mean(axis=[0, 2, 3]) ** 2).item()\ndef avg_ch_var(model, input, output):\n    \"\"\" calculate average channel variance of output activations\n    \"\"\"\n    return torch.mean(output.var(axis=[0, 2, 3])).item()\ndef avg_ch_var_residual(model, input, output):\n    \"\"\" calculate average channel variance of output activations",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "avg_ch_var",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def avg_ch_var(model, input, output):\n    \"\"\" calculate average channel variance of output activations\n    \"\"\"\n    return torch.mean(output.var(axis=[0, 2, 3])).item()\ndef avg_ch_var_residual(model, input, output):\n    \"\"\" calculate average channel variance of output activations\n    \"\"\"\n    return torch.mean(output.var(axis=[0, 2, 3])).item()\nclass ActivationStatsHook:\n    \"\"\"Iterates through each of `model`'s modules and matches modules using unix pattern ",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "avg_ch_var_residual",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def avg_ch_var_residual(model, input, output):\n    \"\"\" calculate average channel variance of output activations\n    \"\"\"\n    return torch.mean(output.var(axis=[0, 2, 3])).item()\nclass ActivationStatsHook:\n    \"\"\"Iterates through each of `model`'s modules and matches modules using unix pattern \n    matching based on `hook_fn_locs` and registers `hook_fn` to the module if there is \n    a match. \n    Arguments:\n        model (nn.Module): model from which we will extract the activation stats",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "extract_spp_stats",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def extract_spp_stats(\n        model,\n        hook_fn_locs,\n        hook_fns,\n        input_shape=[8, 3, 224, 224]):\n    \"\"\"Extract average square channel mean and variance of activations during \n    forward pass to plot Signal Propogation Plots (SPP).\n    Paper: https://arxiv.org/abs/2101.08692\n    Example Usage: https://gist.github.com/amaarora/6e56942fcb46e67ba203f3009b30d950\n    \"\"\"",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "freeze_batch_norm_2d",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def freeze_batch_norm_2d(module):\n    \"\"\"\n    Converts all `BatchNorm2d` and `SyncBatchNorm` layers of provided module into `FrozenBatchNorm2d`. If `module` is\n    itself an instance of either `BatchNorm2d` or `SyncBatchNorm`, it is converted into `FrozenBatchNorm2d` and\n    returned. Otherwise, the module is walked recursively and submodules are converted in place.\n    Args:\n        module (torch.nn.Module): Any PyTorch module.\n    Returns:\n        torch.nn.Module: Resulting module\n    Inspired by https://github.com/pytorch/pytorch/blob/a5895f85be0f10212791145bfedc0261d364f103/torch/nn/modules/batchnorm.py#L762",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "unfreeze_batch_norm_2d",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def unfreeze_batch_norm_2d(module):\n    \"\"\"\n    Converts all `FrozenBatchNorm2d` layers of provided module into `BatchNorm2d`. If `module` is itself and instance\n    of `FrozenBatchNorm2d`, it is converted into `BatchNorm2d` and returned. Otherwise, the module is walked\n    recursively and submodules are converted in place.\n    Args:\n        module (torch.nn.Module): Any PyTorch module.\n    Returns:\n        torch.nn.Module: Resulting module\n    Inspired by https://github.com/pytorch/pytorch/blob/a5895f85be0f10212791145bfedc0261d364f103/torch/nn/modules/batchnorm.py#L762",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "freeze",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def freeze(root_module, submodules=[], include_bn_running_stats=True):\n    \"\"\"\n    Freeze parameters of the specified modules and those of all their hierarchical descendants. This is done in place.\n    Args:\n        root_module (nn.Module): Root module relative to which `submodules` are referenced.\n        submodules (list[str]): List of modules for which the parameters will be frozen. They are to be provided as\n            named modules relative to the root module (accessible via `root_module.named_modules()`). An empty list\n            means that the whole root module will be frozen. Defaults to `[]`.\n        include_bn_running_stats (bool): Whether to also freeze the running statistics of `BatchNorm2d` and\n            `SyncBatchNorm` layers. These will be converted to `FrozenBatchNorm2d` in place. Hint: During fine tuning,",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "unfreeze",
        "kind": 2,
        "importPath": "timm.utils.model",
        "description": "timm.utils.model",
        "peekOfCode": "def unfreeze(root_module, submodules=[], include_bn_running_stats=True):\n    \"\"\"\n    Unfreeze parameters of the specified modules and those of all their hierarchical descendants. This is done in place.\n    Args:\n        root_module (nn.Module): Root module relative to which `submodules` are referenced.\n        submodules (list[str]): List of submodules for which the parameters will be (un)frozen. They are to be provided\n            as named modules relative to the root module (accessible via `root_module.named_modules()`). An empty\n            list means that the whole root module will be unfrozen. Defaults to `[]`.\n        include_bn_running_stats (bool): Whether to also unfreeze the running statistics of `FrozenBatchNorm2d` layers.\n            These will be converted to `BatchNorm2d` in place. Defaults to `True`.",
        "detail": "timm.utils.model",
        "documentation": {}
    },
    {
        "label": "ModelEma",
        "kind": 6,
        "importPath": "timm.utils.model_ema",
        "description": "timm.utils.model_ema",
        "peekOfCode": "class ModelEma:\n    \"\"\" Model Exponential Moving Average (DEPRECATED)\n    Keep a moving average of everything in the model state_dict (parameters and buffers).\n    This version is deprecated, it does not work with scripted models. Will be removed eventually.\n    This is intended to allow functionality like\n    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    A smoothed version of the weights is necessary for some training schemes to perform well.\n    E.g. Google's hyper-params for training MNASNet, MobileNet-V3, EfficientNet, etc that use\n    RMSprop with a short 2.4-3 epoch decay period and slow LR decay rate of .96-.99 requires EMA\n    smoothing of weights to match results. Pay attention to the decay constant you are using",
        "detail": "timm.utils.model_ema",
        "documentation": {}
    },
    {
        "label": "ModelEmaV2",
        "kind": 6,
        "importPath": "timm.utils.model_ema",
        "description": "timm.utils.model_ema",
        "peekOfCode": "class ModelEmaV2(nn.Module):\n    \"\"\" Model Exponential Moving Average V2\n    Keep a moving average of everything in the model state_dict (parameters and buffers).\n    V2 of this module is simpler, it does not match params/buffers based on name but simply\n    iterates in order. It works with torchscript (JIT of full model).\n    This is intended to allow functionality like\n    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    A smoothed version of the weights is necessary for some training schemes to perform well.\n    E.g. Google's hyper-params for training MNASNet, MobileNet-V3, EfficientNet, etc that use\n    RMSprop with a short 2.4-3 epoch decay period and slow LR decay rate of .96-.99 requires EMA",
        "detail": "timm.utils.model_ema",
        "documentation": {}
    },
    {
        "label": "_logger",
        "kind": 5,
        "importPath": "timm.utils.model_ema",
        "description": "timm.utils.model_ema",
        "peekOfCode": "_logger = logging.getLogger(__name__)\nclass ModelEma:\n    \"\"\" Model Exponential Moving Average (DEPRECATED)\n    Keep a moving average of everything in the model state_dict (parameters and buffers).\n    This version is deprecated, it does not work with scripted models. Will be removed eventually.\n    This is intended to allow functionality like\n    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    A smoothed version of the weights is necessary for some training schemes to perform well.\n    E.g. Google's hyper-params for training MNASNet, MobileNet-V3, EfficientNet, etc that use\n    RMSprop with a short 2.4-3 epoch decay period and slow LR decay rate of .96-.99 requires EMA",
        "detail": "timm.utils.model_ema",
        "documentation": {}
    },
    {
        "label": "random_seed",
        "kind": 2,
        "importPath": "timm.utils.random",
        "description": "timm.utils.random",
        "peekOfCode": "def random_seed(seed=42, rank=0):\n    torch.manual_seed(seed + rank)\n    np.random.seed(seed + rank)\n    random.seed(seed + rank)",
        "detail": "timm.utils.random",
        "documentation": {}
    },
    {
        "label": "get_outdir",
        "kind": 2,
        "importPath": "timm.utils.summary",
        "description": "timm.utils.summary",
        "peekOfCode": "def get_outdir(path, *paths, inc=False):\n    outdir = os.path.join(path, *paths)\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n    elif inc:\n        count = 1\n        outdir_inc = outdir + '-' + str(count)\n        while os.path.exists(outdir_inc):\n            count = count + 1\n            outdir_inc = outdir + '-' + str(count)",
        "detail": "timm.utils.summary",
        "documentation": {}
    },
    {
        "label": "update_summary",
        "kind": 2,
        "importPath": "timm.utils.summary",
        "description": "timm.utils.summary",
        "peekOfCode": "def update_summary(epoch, train_metrics, eval_metrics, filename, write_header=False, log_wandb=False):\n    rowd = OrderedDict(epoch=epoch)\n    rowd.update([('train_' + k, v) for k, v in train_metrics.items()])\n    rowd.update([('eval_' + k, v) for k, v in eval_metrics.items()])\n    if log_wandb:\n        wandb.log(rowd)\n    with open(filename, mode='a') as cf:\n        dw = csv.DictWriter(cf, fieldnames=rowd.keys())\n        if write_header:  # first iteration (epoch == 1 can't be used)\n            dw.writeheader()",
        "detail": "timm.utils.summary",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "timm.version",
        "description": "timm.version",
        "peekOfCode": "__version__ = '0.5.5'",
        "detail": "timm.version",
        "documentation": {}
    },
    {
        "label": "RandCrop",
        "kind": 6,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "class RandCrop(object):\n    def __init__(self, patch_size):\n        self.patch_size = patch_size\n    def __call__(self, sample):\n        # r_img : C x H x W (numpy)\n        d_img = sample['d_img_org']\n        d_name = sample['d_name']\n        c, h, w = d_img.shape\n        new_h = self.patch_size\n        new_w = self.patch_size",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "kind": 6,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "class Normalize(object):\n    def __init__(self, mean, var):\n        self.mean = mean\n        self.var = var\n    def __call__(self, sample):\n        # r_img: C x H x W (numpy)\n        d_img = sample['d_img_org']\n        d_name = sample['d_name']\n        d_img = (d_img - self.mean) / self.var\n        sample = {'d_img_org': d_img, 'd_name': d_name}",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "RandHorizontalFlip",
        "kind": 6,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "class RandHorizontalFlip(object):\n    def __init__(self):\n        pass\n    def __call__(self, sample):\n        d_img = sample['d_img_org']\n        d_name = sample['d_name']\n        prob_lr = np.random.random()\n        # np.fliplr needs HxWxC\n        if prob_lr > 0.5:\n            d_img = np.fliplr(d_img).copy()",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "class ToTensor(object):\n    def __init__(self):\n        pass\n    def __call__(self, sample):\n        d_img = sample['d_img_org']\n        d_name = sample['d_name']\n        d_img = torch.from_numpy(d_img).type(torch.FloatTensor)\n        sample = {\n            'd_img_org': d_img,\n            'd_name': d_name",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "sort_file",
        "kind": 2,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "def sort_file(file_path):\n    f2 = open(file_path, \"r\")\n    lines = f2.readlines()\n    ret = []\n    for line in lines:\n        line = line[:-1]\n        ret.append(line)\n    ret.sort()\n    with open('./output.txt', 'w') as f:\n        for i in ret:",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "five_point_crop",
        "kind": 2,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "def five_point_crop(idx, d_img, config):\n    new_h = config.crop_size\n    new_w = config.crop_size\n    b, c, h, w = d_img.shape\n    if idx == 0:\n        top = 0\n        left = 0\n    elif idx == 1:\n        top = 0\n        left = w - new_w",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "random_crop",
        "kind": 2,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "def random_crop(d_img, config):\n    b, c, h, w = d_img.shape\n    top = np.random.randint(0, h - config.crop_size)\n    left = np.random.randint(0, w - config.crop_size)\n    d_img_org = crop_image(top, left, config.crop_size, img=d_img)\n    return d_img_org\ndef crop_image(top, left, patch_size, img=None):\n    tmp_img = img[:, :, top:top + patch_size, left:left + patch_size]\n    return tmp_img\nclass RandCrop(object):",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "crop_image",
        "kind": 2,
        "importPath": "utils.inference_process",
        "description": "utils.inference_process",
        "peekOfCode": "def crop_image(top, left, patch_size, img=None):\n    tmp_img = img[:, :, top:top + patch_size, left:left + patch_size]\n    return tmp_img\nclass RandCrop(object):\n    def __init__(self, patch_size):\n        self.patch_size = patch_size\n    def __call__(self, sample):\n        # r_img : C x H x W (numpy)\n        d_img = sample['d_img_org']\n        d_name = sample['d_name']",
        "detail": "utils.inference_process",
        "documentation": {}
    },
    {
        "label": "RandCrop",
        "kind": 6,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "class RandCrop(object):\n    def __init__(self, patch_size):\n        self.patch_size = patch_size\n    def __call__(self, sample):\n        # r_img : C x H x W (numpy)\n        d_img = sample['d_img_org']\n        score = sample['score']\n        c, h, w = d_img.shape\n        new_h = self.patch_size\n        new_w = self.patch_size",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "kind": 6,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "class Normalize(object):\n    def __init__(self, mean, var):\n        self.mean = mean\n        self.var = var\n    def __call__(self, sample):\n        # r_img: C x H x W (numpy)\n        d_img = sample['d_img_org']\n        score = sample['score']\n        d_img = (d_img - self.mean) / self.var\n        sample = {'d_img_org': d_img, 'score': score}",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "RandHorizontalFlip",
        "kind": 6,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "class RandHorizontalFlip(object):\n    def __init__(self, prob_aug):\n        self.prob_aug = prob_aug\n    def __call__(self, sample):\n        d_img = sample['d_img_org']\n        score = sample['score']\n        p_aug = np.array([self.prob_aug, 1 - self.prob_aug])\n        prob_lr = np.random.choice([1, 0], p=p_aug.ravel())\n        if prob_lr > 0.5:\n            d_img = np.fliplr(d_img).copy()",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "RandRotation",
        "kind": 6,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "class RandRotation(object):\n    def __init__(self, prob_aug=0.5):\n        self.prob_aug = prob_aug\n        self.aug_count = 0\n    def __call__(self, sample):\n        d_img = sample['d_img_org']\n        score = sample['score']\n        p_aug = np.array([self.prob_aug, 1 - self.prob_aug])\n        prob_lr = np.random.choice([1, 0], p=p_aug.ravel())\n        if prob_lr > 0.5:",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "class ToTensor(object):\n    def __init__(self):\n        pass\n    def __call__(self, sample):\n        d_img = sample['d_img_org']\n        score = sample['score']\n        d_img = torch.from_numpy(d_img).type(torch.FloatTensor)\n        score = torch.from_numpy(score).type(torch.FloatTensor)\n        sample = {\n            'd_img_org': d_img,",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "random_crop",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def random_crop(d_img, config):\n    b, c, h, w = d_img.shape\n    top = np.random.randint(0, h - config.crop_size)\n    left = np.random.randint(0, w - config.crop_size)\n    d_img_org = crop_image(top, left, config.crop_size, img=d_img)\n    return d_img_org\ndef crop_image(top, left, patch_size, img=None):\n    tmp_img = img[:, :, top:top + patch_size, left:left + patch_size]\n    return tmp_img\ndef five_point_crop(idx, d_img, config):",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "crop_image",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def crop_image(top, left, patch_size, img=None):\n    tmp_img = img[:, :, top:top + patch_size, left:left + patch_size]\n    return tmp_img\ndef five_point_crop(idx, d_img, config):\n    new_h = config.crop_size\n    new_w = config.crop_size\n    b, c, h, w = d_img.shape\n    if idx == 0:\n        top = 0\n        left = 0",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "five_point_crop",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def five_point_crop(idx, d_img, config):\n    new_h = config.crop_size\n    new_w = config.crop_size\n    b, c, h, w = d_img.shape\n    if idx == 0:\n        top = 0\n        left = 0\n    elif idx == 1:\n        top = 0\n        left = w - new_w",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_koniq10k",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def split_dataset_koniq10k(txt_file_name, split_seed=20):\n    np.random.seed(split_seed)\n    object_data = []\n    with open(txt_file_name, 'r') as listFile:\n        for line in listFile:\n            dis, score = line.split()\n            dis = dis\n            if dis not in object_data:\n                object_data.append(dis)\n    np.random.shuffle(object_data)",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_kadid10k",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def split_dataset_kadid10k(txt_file_name, split_seed=20):\n    np.random.seed(split_seed)\n    object_data = []\n    with open(txt_file_name, 'r') as listFile:\n        for line in listFile:\n            dis, score = line.split()\n            dis = dis[:-1]\n            if dis[1:3] not in object_data:\n                object_data.append(dis[1:3])\n    np.random.shuffle(object_data)",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_tid2013",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def split_dataset_tid2013(txt_file_name, split_seed=20):\n    np.random.seed(split_seed)\n    object_data = []\n    with open(txt_file_name, 'r') as listFile:\n        for line in listFile:\n            score, dis = line.split()\n            if dis[1:3] not in object_data:\n                object_data.append(dis[1:3])\n    np.random.shuffle(object_data)\n    np.random.seed(20)",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_live",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def split_dataset_live(txt_file_name, split_seed=20):\n    np.random.seed(split_seed)\n    object_data = []\n    with open(txt_file_name, 'r') as listFile:\n        for line in listFile:\n            i1, i2, ref, dis, score, h, w = line.split()\n            if ref[8:] not in object_data:\n                object_data.append(ref[8:])\n    np.random.shuffle(object_data)\n    np.random.seed(20)",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "split_dataset_csiq",
        "kind": 2,
        "importPath": "utils.process",
        "description": "utils.process",
        "peekOfCode": "def split_dataset_csiq(txt_file_name, split_seed=20):\n    np.random.seed(split_seed)\n    object_data = []\n    with open(txt_file_name, 'r') as listFile:\n        for line in listFile:\n            dis, score= line.split()\n            dis_name, dis_type, idx_img, _ = dis.split(\".\")\n            if dis_name not in object_data:\n                object_data.append(dis_name)\n    np.random.shuffle(object_data)",
        "detail": "utils.process",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "class Config(dict): \n    __getattr__ = dict.__getitem__\n    __setattr__ = dict.__setitem__\n    @classmethod\n    def load(cls, file):\n        with open(file, 'r') as f:\n            config = json.loads(f.read())\n            return Config(config)",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "kind": 2,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "def setup_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\ndef eval_epoch(config, net, test_loader):",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "eval_epoch",
        "kind": 2,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "def eval_epoch(config, net, test_loader):\n    with torch.no_grad():\n        net.eval()\n        name_list = []\n        pred_list = []\n        with open(config.valid_path + '/output.txt', 'w') as f:\n            for data in tqdm(test_loader):\n                pred = 0\n                for i in range(config.num_avg_val):\n                    x_d = data['d_img_org'].cuda()",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "inference",
        "description": "inference",
        "peekOfCode": "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\ndef setup_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "Image",
        "kind": 6,
        "importPath": "predict_one_image",
        "description": "predict_one_image",
        "peekOfCode": "class Image(torch.utils.data.Dataset):\n    def __init__(self, image_path, transform, num_crops=20):\n        super(Image, self).__init__()\n        self.img_name = image_path.split('/')[-1]\n        self.img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        self.img = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB)\n        self.img = np.array(self.img).astype('float32') / 255\n        self.img = np.transpose(self.img, (2, 0, 1))\n        self.transform = transform\n        c, h, w = self.img.shape",
        "detail": "predict_one_image",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "kind": 2,
        "importPath": "predict_one_image",
        "description": "predict_one_image",
        "peekOfCode": "def setup_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\nclass Image(torch.utils.data.Dataset):",
        "detail": "predict_one_image",
        "documentation": {}
    },
    {
        "label": "os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "predict_one_image",
        "description": "predict_one_image",
        "peekOfCode": "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\ndef setup_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True",
        "detail": "predict_one_image",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "kind": 2,
        "importPath": "train_maniqa",
        "description": "train_maniqa",
        "peekOfCode": "def setup_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\ndef set_logging(config):",
        "detail": "train_maniqa",
        "documentation": {}
    },
    {
        "label": "set_logging",
        "kind": 2,
        "importPath": "train_maniqa",
        "description": "train_maniqa",
        "peekOfCode": "def set_logging(config):\n    if not os.path.exists(config.log_path): \n        os.makedirs(config.log_path)\n    filename = os.path.join(config.log_path, config.log_file)\n    logging.basicConfig(\n        level=logging.INFO,\n        filename=filename,\n        filemode='w',\n        format='[%(asctime)s %(levelname)-8s] %(message)s',\n        datefmt='%Y%m%d %H:%M:%S'",
        "detail": "train_maniqa",
        "documentation": {}
    },
    {
        "label": "train_epoch",
        "kind": 2,
        "importPath": "train_maniqa",
        "description": "train_maniqa",
        "peekOfCode": "def train_epoch(epoch, net, criterion, optimizer, scheduler, train_loader, device):\n    losses = []\n    net.train()\n    # save data for one epoch\n    pred_epoch = []\n    labels_epoch = []\n    for data in tqdm(train_loader):\n        x_d = data['d_img_org'].to(device)\n        labels = data['score']\n        labels = torch.squeeze(labels.type(torch.FloatTensor)).to(device)  ",
        "detail": "train_maniqa",
        "documentation": {}
    },
    {
        "label": "eval_epoch",
        "kind": 2,
        "importPath": "train_maniqa",
        "description": "train_maniqa",
        "peekOfCode": "def eval_epoch(config, epoch, net, criterion, test_loader, device):\n    with torch.no_grad():\n        losses = []\n        net.eval()\n        # save data for one epoch\n        pred_epoch = []\n        labels_epoch = []\n        for data in tqdm(test_loader):\n            pred = 0\n            for i in range(config.num_avg_val):",
        "detail": "train_maniqa",
        "documentation": {}
    }
]